<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>PicoScenes学习日志</title>
    <link href="/2025/05/30/research/picoscenes_use_instruction/"/>
    <url>/2025/05/30/research/picoscenes_use_instruction/</url>
    
    <content type="html"><![CDATA[<h1 id="PicoScenes——使用指南"><a href="#PicoScenes——使用指南" class="headerlink" title="PicoScenes——使用指南"></a>PicoScenes——使用指南</h1><p>Description：这是一篇快速上手的PicoScenes食用指南，我将从打开、查看配置、配置、以及抓包入手，对完整使用PicoScenes的流程进行一个快速的上手介绍;</p><h2 id="指定位置打开终端"><a href="#指定位置打开终端" class="headerlink" title="指定位置打开终端"></a>指定位置打开终端</h2><p>在你想要保存CSI得文件夹位置，右键空白位置，选择在终端中打开，之后就会在你想要的位置开启终端，并帮你cd到打开时的文件夹位置。</p><h2 id="查看信道配置"><a href="#查看信道配置" class="headerlink" title="查看信道配置"></a>查看信道配置</h2><p>第一步：先查看网卡的物理ID：</p><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/e19de6014f384fedfc52c1c78f7191ef.png" alt="array_status"></p><p>第二步：查看到物理ID后先将网卡配置为监听模式，这时候默认配置即可；</p><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/5f28ef35aeb55e65f49f36906c6d89cd.png" alt="prepare"></p><p>这里是给了一个配置，但是不影响，可以直接去掉双引号中的内容</p><p>第三步：查看监听模式下的网卡支持什么配置，包括信道以及带宽信息；</p><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/8eba8c837ec696a9c2d5c739a45bbf06.png" alt="array_eval"></p><p><code>-h</code> 查看支持的指令，我们选择框起来的指令：<br><code>array_eval phyid iw PHY info</code> 将phyid改成你的网卡即可；</p><p>第四步：查看支持的信道以及带宽；</p><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/f76f2165d0e2c66f68fdfd52640d4181.png" alt="Band"></p><p>可以看到，当前支持HT20以及HT40;</p><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/fb9c4ff0cd53dbc38b9ee8f6d09bb29a.png" alt="Band"></p><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/8bc9cf5c47f4cea7dcab830440c8d384.png" alt="Band"></p><p>以上便是支持的信道中心频率了，由此我们便可以重新对网卡的监听信道进行配置</p><h2 id="对PicoScenes进行配置"><a href="#对PicoScenes进行配置" class="headerlink" title="对PicoScenes进行配置"></a>对PicoScenes进行配置</h2><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/5f28ef35aeb55e65f49f36906c6d89cd.png" alt="prepare"></p><p>重新使用该指令 <code>array_prepare_for_picoscenes phyid</code> 后面用双引号加上你需要的配置，这里我们设置为中心频率为5240MHz以及带宽为40MHz，注意40MHz带宽设置为 <code>HT40+</code> ；</p><h2 id="使用PicoScenes进行抓包并且保存"><a href="#使用PicoScenes进行抓包并且保存" class="headerlink" title="使用PicoScenes进行抓包并且保存"></a>使用PicoScenes进行抓包并且保存</h2><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/de616e970c83e30d82a204d4d8bc12e2.png" alt="Band"></p><p>只需要调用该指令，便可以实现CSI的抓取</p><p><code>PicoScenes&quot;-d debug -i 3 --mode logger --plot&quot;</code> 注意要修改为对应的phyid</p><h2 id="终止PicoScenes抓包"><a href="#终止PicoScenes抓包" class="headerlink" title="终止PicoScenes抓包"></a>终止PicoScenes抓包</h2><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/15813146a5b431a40489f9fa8abe75eb.png" alt="Band"></p><p>只需要ctrl+C便可以终止抓包，此时抓取的CSI便会出现在你打开终端时的文件夹中。如果是在桌面中打开的终端，则会保存到文件的一级目录里。</p><h2 id="使用中出现的现象："><a href="#使用中出现的现象：" class="headerlink" title="使用中出现的现象："></a>使用中出现的现象：</h2><p>当你配置完信道并开始抓取CSI时，有可能会出现没有plot的图像，或者plot图像更新很慢的问题，这是因为当前的信道WiFi活动比较弱，或者没有AP在这个信道中活动，是正常现象。</p><h1 id="PicoScenes监听与重启后的抓包来源"><a href="#PicoScenes监听与重启后的抓包来源" class="headerlink" title="PicoScenes监听与重启后的抓包来源"></a>PicoScenes监听与重启后的抓包来源</h1><p>已知，PicoScenes有内置的指令可以开启监听模式，在监听模式下可以抓取环境中WIFI的CSI，这一点可以通过观察802.11.ac的MAC帧头结构得到：</p><blockquote><p>开启监听模式后的源地址（5200HT20）<br><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/25053005.png" alt="Mon"></p></blockquote><p>可以观察到多个不同的地址；</p><p>监听模式下可以接收到环境中的CSI</p><p>开启监听指令: array_prepare_for_picoscenes PhyPath（网卡的id）   </p><blockquote><p>重启电脑后的源地址（2422-40BW）<br><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/25053002.png" alt="Non-Mon"></p></blockquote><p>只有一个源地址的CSI，重启可以关闭监听模式；   </p><blockquote><p>开启监听模式（2422-20BW）<br><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/25053001.png" alt="Mon-2422"></p></blockquote><blockquote><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/25053004.png" alt="Mon-2422"></p></blockquote><p>不同的源地址的CSI；   </p><blockquote><p>使用airmon-ng工具手动关闭mon并且重启（2422-40BW）<br><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/25053002.png" alt="Mon-2422"></p></blockquote><p>只有一个源地址的CSI，重启可以关闭监听模式；   </p>]]></content>
    
    
    <categories>
      
      <category>Tools</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>CSI</tag>
      
      <tag>5G</tag>
      
      <tag>Positioning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Fisher——Fisher投影分类</title>
    <link href="/2025/05/29/study/Fisher/"/>
    <url>/2025/05/29/study/Fisher/</url>
    
    <content type="html"><![CDATA[<h1 id="Fisher投影加速分类"><a href="#Fisher投影加速分类" class="headerlink" title="Fisher投影加速分类"></a>Fisher投影加速分类</h1><h2 id="线性判别分析（LDA）详解：从理论到代码实现"><a href="#线性判别分析（LDA）详解：从理论到代码实现" class="headerlink" title="线性判别分析（LDA）详解：从理论到代码实现"></a>线性判别分析（LDA）详解：从理论到代码实现</h2><h3 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h3><p>线性判别分析（Linear Discriminant Analysis, LDA）是一种经典的监督学习降维与分类方法。其核心思想是通过最大化类间散度、最小化类内散度，将高维数据投影到低维空间并实现高效分类。本文以鸢尾花数据集为例，详解LDA的数学原理，并逐行解析代码实现。</p><h3 id="二、LDA的核心原理"><a href="#二、LDA的核心原理" class="headerlink" title="二、LDA的核心原理"></a>二、LDA的核心原理</h3><h4 id="1-核心目标"><a href="#1-核心目标" class="headerlink" title="1. 核心目标"></a>1. 核心目标</h4><p>LDA的目标是找到一个最优投影方向 $ W $，使得以下准则成立：</p><ul><li>类内散度最小：同一类样本在投影后的空间尽可能紧凑。</li><li>类间散度最大：不同类样本在投影后的空间尽可能分离。</li></ul><p>数学表达式为：</p><p>$$<br>J(W) &#x3D; \frac{W^T S_B W}{W^T S_W W}<br>$$</p><p>其中：</p><ul><li>$ S_W $：类内散度矩阵（Within-class Scatter Matrix）</li><li>$ S_B $：类间散度矩阵（Between-class Scatter Matrix）</li></ul><h4 id="2-数学推导"><a href="#2-数学推导" class="headerlink" title="2. 数学推导"></a>2. 数学推导</h4><h4 id="1-类均值向量"><a href="#1-类均值向量" class="headerlink" title="(1) 类均值向量"></a>(1) 类均值向量</h4><p>对每个类别 $ c $，计算其特征均值向量 $ \mu_c $：</p><p>$$<br>\mu_c &#x3D; \frac{1}{N_c} \sum_{x \in C_c} x<br>$$</p><p>其中 $ N_c $ 是类别 $ c $ 的样本数。</p><h4 id="2-类内散度矩阵-S-W"><a href="#2-类内散度矩阵-S-W" class="headerlink" title="(2) 类内散度矩阵 $ S_W $"></a>(2) 类内散度矩阵 $ S_W $</h4><p>衡量同一类样本的离散程度：</p><p>$$<br>S_W &#x3D; \sum_{c} \sum_{x \in C_c} (x - \mu_c)(x - \mu_c)^T<br>$$</p><h4 id="3-类间散度矩阵-S-B"><a href="#3-类间散度矩阵-S-B" class="headerlink" title="(3) 类间散度矩阵 $ S_B $"></a>(3) 类间散度矩阵 $ S_B $</h4><p>衡量不同类中心之间的距离：</p><p>$$<br>S_B &#x3D; \sum_{c} N_c (\mu_c - \mu)(\mu_c - \mu)^T<br>$$</p><p>其中 $ \mu $ 是全局均值向量。</p><h4 id="4-投影矩阵计算"><a href="#4-投影矩阵计算" class="headerlink" title="(4) 投影矩阵计算"></a>(4) 投影矩阵计算</h4><p>通过广义特征值问题求解最优投影方向：</p><p>$$<br>S_W^{-1} S_B w &#x3D; \lambda w<br>$$</p><p>选择最大特征值对应的特征向量 $ w $ 作为投影方向。</p><h3 id="三、代码详解与实现"><a href="#三、代码详解与实现" class="headerlink" title="三、代码详解与实现"></a>三、代码详解与实现</h3><h4 id="1-数据准备与预处理"><a href="#1-数据准备与预处理" class="headerlink" title="1. 数据准备与预处理"></a>1. 数据准备与预处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br>iris = load_iris()<br>X = iris.data[y != <span class="hljs-number">2</span>]  <span class="hljs-comment"># 筛选前两类（0和1）</span><br>y = y[y != <span class="hljs-number">2</span>]<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>)<br></code></pre></td></tr></table></figure><ul><li>功能：加载鸢尾花数据集并筛选前两类，构造二分类任务。</li><li>原理：LDA适用于多分类，但二分类更简单直观。</li></ul><h4 id="2-类均值计算"><a href="#2-类均值计算" class="headerlink" title="2. 类均值计算"></a>2. 类均值计算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">class_means</span>(<span class="hljs-params">X, y</span>):<br>    classes = np.unique(y)<br>    means = [np.mean(X[y == c], axis=<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> classes]<br>    <span class="hljs-keyword">return</span> np.array(means)<br></code></pre></td></tr></table></figure><ul><li>功能：计算每个类别的均值向量。</li><li>数学对应：实现公式 $ \mu_c $ 的计算。</li></ul><h4 id="3-类内散度矩阵"><a href="#3-类内散度矩阵" class="headerlink" title="3. 类内散度矩阵"></a>3. 类内散度矩阵</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">within_class_scatter</span>(<span class="hljs-params">X, y</span>):<br>    means = class_means(X, y)<br>    num_features = X.shape[<span class="hljs-number">1</span>]<br>    S_w = np.zeros((num_features, num_features))<br>    <span class="hljs-keyword">for</span> c, mean <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(np.unique(y), means):<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X[y == c]:<br>            x = x.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>            mean = mean.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>            S_w += (x - mean).dot((x - mean).T)<br>    <span class="hljs-keyword">return</span> S_w<br></code></pre></td></tr></table></figure><ul><li>功能：计算类内散度矩阵 $ S_W $。</li><li>关键点：通过外积累加每个样本与类均值的偏差。</li></ul><h4 id="4-类间散度矩阵"><a href="#4-类间散度矩阵" class="headerlink" title="4. 类间散度矩阵"></a>4. 类间散度矩阵</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">between_class_scatter</span>(<span class="hljs-params">X, y</span>):<br>    means = class_means(X, y)<br>    mean1, mean2 = means[<span class="hljs-number">0</span>].reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), means[<span class="hljs-number">1</span>].reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> (mean1 - mean2).dot((mean1 - mean2).T)<br></code></pre></td></tr></table></figure><ul><li>功能：计算类间散度矩阵 $ S_B $。</li><li>局限性：仅适用于二分类，多分类需扩展。</li></ul><h4 id="5-投影矩阵求解"><a href="#5-投影矩阵求解" class="headerlink" title="5. 投影矩阵求解"></a>5. 投影矩阵求解</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">projection_matrix</span>(<span class="hljs-params">X, y</span>):<br>    S_w = within_class_scatter(X, y)<br>    S_b = between_class_scatter(X, y)<br>    eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_w).dot(S_b))<br>    <span class="hljs-keyword">return</span> eig_vecs[:, np.argsort(eig_vals)[::-<span class="hljs-number">1</span>][:<span class="hljs-number">1</span>]]<br></code></pre></td></tr></table></figure><ul><li>功能：求解广义特征值问题，取最大特征值对应的特征向量作为投影方向。</li><li>数学对应：求解 $ S_W^{-1} S_B $ 的最大特征值对应的特征向量。</li></ul><h4 id="6-数据投影与分类"><a href="#6-数据投影与分类" class="headerlink" title="6. 数据投影与分类"></a>6. 数据投影与分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">W = projection_matrix(X_train, y_train)<br>X_train_lda = X_train.dot(W)  <span class="hljs-comment"># 降维后的训练数据</span><br>X_test_lda = X_test.dot(W)    <span class="hljs-comment"># 降维后的测试数据</span><br><br><span class="hljs-comment"># 计算阈值并分类</span><br>threshold = (X_train_lda[y_train == <span class="hljs-number">0</span>].mean() + X_train_lda[y_train == <span class="hljs-number">1</span>].mean()) / <span class="hljs-number">2</span><br>y_pred = (X_test_lda &gt;= threshold).astype(<span class="hljs-built_in">int</span>)<br></code></pre></td></tr></table></figure><ul><li>决策规则：使用两类均值的中点作为阈值进行分类。</li></ul><h3 id="四、实验结果与可视化"><a href="#四、实验结果与可视化" class="headerlink" title="四、实验结果与可视化"></a>四、实验结果与可视化</h3><h4 id="1-可视化设计"><a href="#1-可视化设计" class="headerlink" title="1. 可视化设计"></a>1. 可视化设计</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">fig, (ax1, ax2, ax3) = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, figsize=(<span class="hljs-number">18</span>, <span class="hljs-number">6</span>))<br><span class="hljs-comment"># 绘制训练集、测试集及合并结果</span><br><span class="hljs-keyword">for</span> ax, X_lda, y_true, title <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>([ax1, ax2, ax3], <br>                                   [X_train_lda, X_test_lda, X_train_lda], <br>                                   [y_train, y_test, y_train], <br>                                   [<span class="hljs-string">&quot;Train&quot;</span>, <span class="hljs-string">&quot;Test&quot;</span>, <span class="hljs-string">&quot;Combined&quot;</span>]):<br>    <span class="hljs-keyword">for</span> cls, color <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(np.unique(y), [<span class="hljs-string">&#x27;r&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>]):<br>        ax.scatter(X_lda[y_true == cls], np.zeros(np.<span class="hljs-built_in">sum</span>(y_true == cls)), <br>                   c=color, label=<span class="hljs-string">f&#x27;Class <span class="hljs-subst">&#123;cls&#125;</span>&#x27;</span>)<br>    ax.axvline(x=threshold, c=<span class="hljs-string">&#x27;g&#x27;</span>, linestyle=<span class="hljs-string">&#x27;--&#x27;</span>)<br>    ax.set_title(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;title&#125;</span> (Acc: <span class="hljs-subst">&#123;accuracy_score(y_true, y_pred):<span class="hljs-number">.2</span>%&#125;</span>)&quot;</span>)<br>plt.legend()<br>plt.show()<br></code></pre></td></tr></table></figure><ul><li>图形说明：<ul><li>横轴：投影后的特征值；纵轴：辅助可视化（固定为0）。</li><li>绿色虚线：分类阈值。</li><li>颜色区分类别，散点分布反映分离效果。</li></ul></li></ul><h4 id="2-输出示例"><a href="#2-输出示例" class="headerlink" title="2. 输出示例"></a>2. 输出示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">Train Accuracy: <span class="hljs-number">0.9875</span><br>Test Accuracy: <span class="hljs-number">1.0</span><br></code></pre></td></tr></table></figure><ul><li>结果分析：在鸢尾花二分类任务中，LDA通常能达到95%以上的准确率。</li></ul><h3 id="四、关键问题与改进建议"><a href="#四、关键问题与改进建议" class="headerlink" title="四、关键问题与改进建议"></a>四、关键问题与改进建议</h3><h4 id="1-类间散度矩阵的改进"><a href="#1-类间散度矩阵的改进" class="headerlink" title="1. 类间散度矩阵的改进"></a>1. 类间散度矩阵的改进</h4><ul><li>当前实现：仅使用两类均值差的外积，未考虑样本数比例。</li><li>改进建议：</li></ul><p>对于二分类问题，正确的 $ S_B $ 应为：</p><p>$$<br>S_B &#x3D; \frac{n_1 n_2}{n} (\mu_1 - \mu_2)(\mu_1 - \mu_2)^T<br>$$</p><h4 id="2-特征值问题的稳定性"><a href="#2-特征值问题的稳定性" class="headerlink" title="2. 特征值问题的稳定性"></a>2. 特征值问题的稳定性</h4><ul><li>潜在问题：若 $ S_W $ 奇异（如高维小样本），求逆会导致数值不稳定。</li><li>改进建议：添加正则化项 $ \lambda I $ 到 $ S_W $。</li></ul><h4 id="3-阈值选择的优化"><a href="#3-阈值选择的优化" class="headerlink" title="3. 阈值选择的优化"></a>3. 阈值选择的优化</h4><ul><li>当前方法：固定阈值为均值中点。</li><li>改进建议：通过交叉验证选择最优阈值。</li></ul><h3 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h3><ul><li>核心贡献：本文从数学公式到代码实现，完整解析了LDA的原理与应用。</li><li>代码特点：基于NumPy实现，无需依赖 sklearn.discriminant_analysis.LinearDiscriminantAnalysis，适合理解底层机制。</li><li>扩展方向：可推广到多分类任务，结合非线性核函数处理复杂分布。</li></ul><p>完整的工程请见<img src="https://github.com/" alt="Github"></p>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SVM——Python代码实现以及解析</title>
    <link href="/2025/05/29/study/SVM/"/>
    <url>/2025/05/29/study/SVM/</url>
    
    <content type="html"><![CDATA[<h2 id="支持向量机-SVM-原理详解与代码解析"><a href="#支持向量机-SVM-原理详解与代码解析" class="headerlink" title="支持向量机(SVM)原理详解与代码解析"></a>支持向量机(SVM)原理详解与代码解析</h2><h3 id="一、SVM算法原理详解"><a href="#一、SVM算法原理详解" class="headerlink" title="一、SVM算法原理详解"></a>一、SVM算法原理详解</h3><h4 id="1-核心思想"><a href="#1-核心思想" class="headerlink" title="1. 核心思想"></a>1. 核心思想</h4><p>支持向量机通过最大化分类间隔实现最优分类，其数学本质是求解一个凸二次优化问题。核心思想包括：</p><ul><li>最大间隔原则：寻找使类别间距离最大的分类超平面</li><li>支持向量：决定分类边界的关键样本点</li><li>核技巧：通过核函数将低维不可分数据映射到高维空间</li></ul><h4 id="2-数学基础"><a href="#2-数学基础" class="headerlink" title="2. 数学基础"></a>2. 数学基础</h4><h4 id="1-线性可分情况"><a href="#1-线性可分情况" class="headerlink" title="(1) 线性可分情况"></a>(1) 线性可分情况</h4><p>$$<br>\min_{w,b} \frac{1}{2}||w||^2 \quad \text{s.t.} \quad y_i(w^T x_i + b) \geq 1<br>$$</p><ul><li>$ w $：超平面法向量</li><li>$ b $：偏置项</li><li>$ y_i \in {-1,1} $：类别标签</li></ul><h4 id="2-非线性情况（使用核函数）"><a href="#2-非线性情况（使用核函数）" class="headerlink" title="(2) 非线性情况（使用核函数）"></a>(2) 非线性情况（使用核函数）</h4><p>$$<br>K(x_i,x_j) &#x3D; \phi(x_i)^T\phi(x_j)<br>$$</p><p>常用核函数：</p><ul><li>线性核：$ K(x,y) &#x3D; x^Ty $</li><li>多项式核：$ K(x,y) &#x3D; (x^Ty + c)^d $</li><li>RBF核：$ K(x,y) &#x3D; e^{-\gamma ||x-y||^2} $</li></ul><h4 id="3-正则化参数C"><a href="#3-正则化参数C" class="headerlink" title="(3) 正则化参数C"></a>(3) 正则化参数C</h4><p>$$<br>\min_{w,b,\xi} \frac{1}{2}||w||^2 + C\sum_{i&#x3D;1}^n \xi_i<br>$$</p><ul><li>$ C $：控制误分类惩罚强度</li><li>$ \xi_i $：松弛变量，允许一定程度的误分类</li></ul><h3 id="二、代码逐句解析"><a href="#二、代码逐句解析" class="headerlink" title="二、代码逐句解析"></a>二、代码逐句解析</h3><h4 id="1-数据预处理阶段"><a href="#1-数据预处理阶段" class="headerlink" title="1. 数据预处理阶段"></a>1. 数据预处理阶段</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">Iris_label</span>(<span class="hljs-params">s</span>):<br>    it = &#123;<span class="hljs-string">b&#x27;Iris-setosa&#x27;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">b&#x27;Iris-versicolor&#x27;</span>:<span class="hljs-number">1</span>, <span class="hljs-string">b&#x27;Iris-virginica&#x27;</span>:<span class="hljs-number">2</span>&#125;<br>    <span class="hljs-keyword">return</span> it[s]<br></code></pre></td></tr></table></figure><ul><li>功能：将原始文本标签转换为数字编码</li><li>原理：机器学习模型需要数值输入，将类别标签转换为0-1编码</li><li>改进建议：使用LabelEncoder更通用的标签编码方式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">df = pd.read_csv(<span class="hljs-string">&#x27;iris.txt&#x27;</span>, header=<span class="hljs-literal">None</span>)<br>df[<span class="hljs-number">4</span>] = df[<span class="hljs-number">4</span>].<span class="hljs-built_in">map</span>(&#123;<span class="hljs-string">&#x27;Iris-setosa&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;Iris-versicolor&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;Iris-virginica&#x27;</span>: <span class="hljs-number">2</span>&#125;)<br>data = df.values<br></code></pre></td></tr></table></figure><ul><li>功能：读取数据并转换标签</li><li>关键点：使用pandas进行数据清洗，替代np.loadtxt更灵活</li><li>注意：原始数据集包含5列（4个特征+1个标签），索引0-4，因此不存在列越界问题</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">x, y = np.split(data, (<span class="hljs-number">4</span>,), axis=<span class="hljs-number">1</span>)<br>x = x[:, :<span class="hljs-number">2</span>]<br>y = y.ravel()<br></code></pre></td></tr></table></figure><ul><li>功能：特征与标签分离</li><li>原理：np.split按列分割数据，x[:, :2]选择前两个特征用于可视化</li><li>注意：ravel()确保标签为1D数组，符合scikit-learn输入要求</li></ul><h4 id="2-数据集划分"><a href="#2-数据集划分" class="headerlink" title="2. 数据集划分"></a>2. 数据集划分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><ul><li>功能：按7:3划分训练集和测试集</li><li>原理：train_test_split内部执行数据打乱和分割</li><li>参数说明：<ul><li>test_size&#x3D;0.3：测试集占比30%</li><li>random_state&#x3D;1：确保结果可复现</li></ul></li></ul><h4 id="3-SVM模型构建"><a href="#3-SVM模型构建" class="headerlink" title="3. SVM模型构建"></a>3. SVM模型构建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model = svm.SVC(C=<span class="hljs-number">2</span>, kernel=<span class="hljs-string">&#x27;rbf&#x27;</span>, gamma=<span class="hljs-number">10</span>, decision_function_shape=<span class="hljs-string">&#x27;ovo&#x27;</span>)<br></code></pre></td></tr></table></figure><ul><li>参数详解：<ul><li>C&#x3D;2：正则化参数，值越大对误分类的惩罚越强</li><li>kernel&#x3D;’rbf’：使用径向基函数(RBF)作为核函数</li><li>gamma&#x3D;10：核函数系数，值越大模型复杂度越高</li><li>decision_function_shape&#x3D;’ovo’：采用一对一的多分类策略</li></ul></li></ul><h4 id="4-模型训练"><a href="#4-模型训练" class="headerlink" title="4. 模型训练"></a>4. 模型训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model.fit(x_train, y_train.ravel())<br></code></pre></td></tr></table></figure><ul><li>功能：训练SVM模型</li><li>原理：内部调用SMO算法求解优化问题</li><li>数学对应：优化目标是最大化分类间隔同时最小化分类误差</li></ul><h4 id="5-模型评估"><a href="#5-模型评估" class="headerlink" title="5. 模型评估"></a>5. 模型评估</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">train_score = model.score(x_train, y_train)<br>test_score = model.score(x_test, y_test)<br></code></pre></td></tr></table></figure><ul><li>功能：计算分类准确率</li><li>原理：准确率公式 $ Accuracy &#x3D; \frac{TP+TN}{TP+FP+TN+FN} $</li><li>训练集准确率：98.57%; 测试集准确率：95.56%</li></ul><h3 id="三、关键概念与代码对应关系"><a href="#三、关键概念与代码对应关系" class="headerlink" title="三、关键概念与代码对应关系"></a>三、关键概念与代码对应关系</h3><table><thead><tr><th align="left">代码实现</th><th align="left">数学原理</th></tr></thead><tbody><tr><td align="left"><code>kernel=&#39;rbf&#39;</code></td><td align="left">核技巧 $ K(x,y) &#x3D; e^{-\gamma} $</td></tr><tr><td align="left"><code>C=2</code></td><td align="left">正则化参数 $ \min \frac{1}{2} $</td></tr><tr><td align="left"><code>gamma=10</code></td><td align="left">核函数参数 $ \gamma $ 控制模型复杂度</td></tr><tr><td align="left"><code>decision\_function\_shape=&#39;ovo&#39;</code></td><td align="left">一对一多分类策略</td></tr><tr><td align="left"><code>train\_test\_split(...)</code></td><td align="left">数据集划分保证泛化性</td></tr></tbody></table><h3 id="四、模型可视化实现（补充）"><a href="#四、模型可视化实现（补充）" class="headerlink" title="四、模型可视化实现（补充）"></a>四、模型可视化实现（补充）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_decision_regions</span>(<span class="hljs-params">X, y, classifier</span>):<br>    <span class="hljs-keyword">from</span> matplotlib.colors <span class="hljs-keyword">import</span> ListedColormap<br>    X1, X2 = np.meshgrid(np.arange(X[:,<span class="hljs-number">0</span>].<span class="hljs-built_in">min</span>()-<span class="hljs-number">1</span>, X[:,<span class="hljs-number">0</span>].<span class="hljs-built_in">max</span>()+<span class="hljs-number">1</span>, <span class="hljs-number">0.02</span>),<br>                           np.arange(X[:,<span class="hljs-number">1</span>].<span class="hljs-built_in">min</span>()-<span class="hljs-number">1</span>, X[:,<span class="hljs-number">1</span>].<span class="hljs-built_in">max</span>()+<span class="hljs-number">1</span>, <span class="hljs-number">0.02</span>))<br>    Z = classifier.predict(np.c_[X1.ravel(), X2.ravel()])<br>    Z = Z.reshape(X1.shape)<br>    plt.contourf(X1, X2, Z, alpha=<span class="hljs-number">0.4</span>, cmap=ListedColormap([<span class="hljs-string">&#x27;lightcoral&#x27;</span>,<span class="hljs-string">&#x27;lightblue&#x27;</span>,<span class="hljs-string">&#x27;lightgreen&#x27;</span>]))<br>    plt.scatter(X[y==<span class="hljs-number">0</span>,<span class="hljs-number">0</span>], X[y==<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], c=<span class="hljs-string">&#x27;red&#x27;</span>, label=<span class="hljs-string">&#x27;Setosa&#x27;</span>)<br>    plt.scatter(X[y==<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], X[y==<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], c=<span class="hljs-string">&#x27;blue&#x27;</span>, label=<span class="hljs-string">&#x27;Versicolor&#x27;</span>)<br>    plt.scatter(X[y==<span class="hljs-number">2</span>,<span class="hljs-number">0</span>], X[y==<span class="hljs-number">2</span>,<span class="hljs-number">1</span>], c=<span class="hljs-string">&#x27;green&#x27;</span>, label=<span class="hljs-string">&#x27;Virginica&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;SVM Result&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;Sepal Length&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;Sepal Width&#x27;</span>)<br>    plt.legend()<br>    plt.show()<br><br>plot_decision_regions(x_test, y_test, model)<br></code></pre></td></tr></table></figure><ul><li>功能：绘制决策边界</li><li>原理：<ol><li>生成网格点作为测试点</li><li>对每个点进行预测</li><li>将预测结果可视化为背景颜色</li></ol></li><li>可视化要素：<ul><li>背景色：表示模型的决策区域</li><li>散点：实际测试集样本分布</li><li>标题：显示模型名称</li></ul></li></ul><h3 id="五、参数调优建议"><a href="#五、参数调优建议" class="headerlink" title="五、参数调优建议"></a>五、参数调优建议</h3><ol><li>核函数选择：<ul><li>线性可分数据使用linear核</li><li>非线性数据使用rbf核（默认）</li><li>多项式核适用于特定场景</li></ul></li><li>参数调优： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<br>param_grid = &#123;<span class="hljs-string">&#x27;C&#x27;</span>: [<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">10</span>], <span class="hljs-string">&#x27;gamma&#x27;</span>: [<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">10</span>]&#125;<br>grid = GridSearchCV(svm.SVC(), param_grid, cv=<span class="hljs-number">5</span>)<br>grid.fit(x_train, y_train)<br></code></pre></td></tr></table></figure></li><li>多分类策略：<ul><li>decision_function_shape&#x3D;’ovo’：一对一（适合小数据集）</li><li>decision_function_shape&#x3D;’ovr’：一对多（适合大数据集）</li></ul></li></ol><h3 id="六、完整工作流程图"><a href="#六、完整工作流程图" class="headerlink" title="六、完整工作流程图"></a>六、完整工作流程图</h3><figure class="highlight plaintext"><figcaption><span>text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plain">数据预处理 → 特征选择 → 模型初始化 → 参数调优 → 模型训练 → 可视化 → 性能评估<br></code></pre></td></tr></table></figure><h3 id="七、注意事项"><a href="#七、注意事项" class="headerlink" title="七、注意事项"></a>七、注意事项</h3><ol><li>特征标准化： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br>sc = StandardScaler()<br>x_train = sc.fit_transform(x_train)<br></code></pre></td></tr></table></figure><ul><li>原因：SVM对特征尺度敏感</li><li>方法：Z-score标准化</li></ul></li><li>特征选择：<ul><li>仅使用前两个特征会损失部分信息</li><li>建议使用PCA降维代替人工选择</li></ul></li><li>过拟合预防：<ul><li>当gamma过大时可能导致过拟合</li><li>可通过交叉验证选择最优参数</li></ul></li></ol><h3 id="八、扩展应用"><a href="#八、扩展应用" class="headerlink" title="八、扩展应用"></a>八、扩展应用</h3><ol><li>多分类问题：<ul><li>鸢尾花有3个类别</li><li>SVM原生支持多分类（非二分类扩展）</li></ul></li><li>非线性分类：<ul><li>RBF核处理非线性可分问题</li><li>决策边界可以是非线性的</li></ul></li><li>软间隔：<ul><li>C&#x3D;2允许部分样本位于间隔带内</li><li>平衡分类精度和泛化能力</li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于CIFAR数据集实现的图像分类</title>
    <link href="/2025/05/29/study/%E5%9F%BA%E4%BA%8ECIFAR%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"/>
    <url>/2025/05/29/study/%E5%9F%BA%E4%BA%8ECIFAR%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h2 id="CIFAR-10数据集介绍"><a href="#CIFAR-10数据集介绍" class="headerlink" title="CIFAR-10数据集介绍"></a>CIFAR-10数据集介绍</h2><p>CIFAR10包含有一共60000张32x32的彩色图像，这些图片中一共有10类不同的事物，每一类有6000张样本。这些图片按照5:1的比例随机分为训练集以及测试集。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/25060103.png" alt="CIFAR-10"></p><p>下面将在这个开源的数据集上实现图像的分类，目前计划通过ResNet-18模型实现上述的分类功能；</p><h2 id="Python代码实现以及详解"><a href="#Python代码实现以及详解" class="headerlink" title="Python代码实现以及详解"></a>Python代码实现以及详解</h2><h3 id="导入必要的库以及依赖"><a href="#导入必要的库以及依赖" class="headerlink" title="导入必要的库以及依赖"></a>导入必要的库以及依赖</h3><p>我们这里使用Pytorch框架实现模型的训练以及结果的预测；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn <br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm <br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms <br><span class="hljs-keyword">import</span> torchvision <br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br></code></pre></td></tr></table></figure><p>导入 <code>tdqm</code> 库将训练的过程可视化，该库能够将训练的进度以进度条的形式显示出来；由于我们要实现的是图片的识别分类功能，这里选择导入 <code>torchvision</code> 库并使用预训练的模型参数提高训练的正确率以及速度；</p><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">transform = transforms.Compose([ <br>    transforms.ToTensor(), <br>    transforms.Normalize((<span class="hljs-number">0.4914</span>, <span class="hljs-number">0.4822</span>, <span class="hljs-number">0.4465</span>), (<span class="hljs-number">0.2023</span>, <span class="hljs-number">0.1994</span>, <span class="hljs-number">0.2010</span>)), <br>    <span class="hljs-comment"># CIFAR-10 数据集的均值和标准差 </span><br>]) <br><br>batch_size = <span class="hljs-number">32</span><br><br>train_set = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./CIFAR&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform)  <span class="hljs-comment">#root根据实际进行修改 </span><br>train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>) <br> <br>val_dataset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./CIFAR&#x27;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transform)  <span class="hljs-comment">#root根据实际进行修改 </span><br>val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>) <br><br></code></pre></td></tr></table></figure><p>首先我们先定义了一个图片变换结构，作用是将图片，向量矩阵转换为Pytorch中定义的一个全新的数据结构——张量（Tensor）；之后根据该数据集的标准差对所有张量标准化归一化；</p><p>之后定义了训练集数据以及验证集数据的加载器，能够设置一定的 <code>batch\_size</code> 每一次取数据进行训练或者验证的时候取一整个 <code>batch</code> ，提高训练的速度；同时还能够设置是否随机选择样本，以及线程数量；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>) <br><span class="hljs-built_in">print</span>(device)<br></code></pre></td></tr></table></figure><p>定义设备，如果当前支持CUDA则使用CUDA作为训练的设备，否则为CPU；CUDA的训练速度要比CPU的训练速度快，而且训练的效果会更好一些；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">net = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 加载预训练的模型参数</span><br>num_ftrs = net.fc.in_features                       <span class="hljs-comment"># 全连接层的特征</span><br><span class="hljs-comment"># 修改全连接层的输出维度为10 </span><br>net.fc = nn.Linear(num_ftrs, <span class="hljs-number">10</span>)                    <span class="hljs-comment"># 人为修改连接层的输出</span><br>net = net.to(device)<br></code></pre></td></tr></table></figure><p>这里我们使用 <code>ResNet-18</code> 模型进行训练以及识别，为了加快训练的速度以及提高训练的准确率，选择导入Pytorch中预训练的模型参数；由于该数据集中只有10个类别，网络只需要10个输出，因此我们单独对网络的最后一层进行修改，将全连接层的输出修改为10；最后将模型导入到设备在。</p><p>注意：CUDA与CPU不互通，模型以及数据到需要在同一个设备中；</p><p>Net的结构如下：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/25060104.png" alt="ResNet-18"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">criterion = nn.CrossEntropyLoss() <br>optimizer = torch.optim.AdamW(lr=<span class="hljs-number">0.0001</span>, params=net.parameters()) <br>epochs = <span class="hljs-number">10</span><br></code></pre></td></tr></table></figure><p>定义比较常见的两个函数作为赏罚函数，损失函数为<strong>交叉损失</strong>，优化函数定义为<strong>AdamW函数</strong>，想详细了解可以去参考一下文章：</p><p><a href="https://arxiv.org/abs/1711.05101">[1711.05101] Decoupled Weight Decay Regularization</a></p><p>训练轮数为10轮，训练轮数的选取比较有讲究，如果训练次数过少则模型的性能没有到最优；如果训练次数过多，则又会导致<strong>过拟合</strong>，训练效果下降。因此通常选择一个适中的次数，或者对每次训练的准确率进行判断，发现如果准确率的优化减缓时，意味着当前模型接近收敛，便提前结束训练并保存模型参数；</p><hr><p>下面是训练代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs): <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;--------------------Epoch: <span class="hljs-subst">&#123;epoch&#125;</span>--------------------\n&#x27;</span>) <br>     <br>    <span class="hljs-comment"># 训练阶段 </span><br>    net.train() <br>    running_loss = <span class="hljs-number">0.0</span> <br>    correct_train = <span class="hljs-number">0</span> <br>    total_train = <span class="hljs-number">0</span> <br>    <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> tqdm(train_loader): <br>        inputs = inputs.to(device) <br>        labels = labels.to(device) <br> <br>        optimizer.zero_grad()   <span class="hljs-comment"># 清空梯度</span><br>        outputs = net(inputs)   <span class="hljs-comment"># 预测输出</span><br>        loss = criterion(outputs, labels) <br>        loss.backward()         <span class="hljs-comment"># 梯度下降</span><br>        optimizer.step()        <span class="hljs-comment"># 优化</span><br> <br>        running_loss += loss.item() <br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>) <br>        total_train += labels.size(<span class="hljs-number">0</span>) <br>        correct_train += (predicted == labels).<span class="hljs-built_in">sum</span>().item() <br>        train_loss = running_loss / <span class="hljs-built_in">len</span>(train_loader) <br><br>    train_acc = correct_train / total_train <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练损失：&#123;:.4f&#125;，训练准确率：&#123;:.4f&#125;%&#x27;</span>.<span class="hljs-built_in">format</span>(train_loss, train_acc * <span class="hljs-number">100</span>)) <br> <br>    <span class="hljs-comment"># 验证阶段 </span><br>    net.<span class="hljs-built_in">eval</span>() <br>    correct_val = <span class="hljs-number">0</span> <br>    total_val = <span class="hljs-number">0</span> <br>    val_loss = <span class="hljs-number">0.0</span> <br>    <span class="hljs-comment"># 不更新梯度</span><br>    <span class="hljs-keyword">with</span> torch.no_grad(): <br>        <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> tqdm(val_loader): <br>            inputs = inputs.to(device) <br>         <br>            labels = labels.to(device) <br> <br>            outputs = net(inputs) <br>            loss = criterion(outputs, labels) <br>            val_loss += loss.item() <br>            _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>) <br>            total_val += labels.size(<span class="hljs-number">0</span>) <br>            correct_val += (predicted == labels).<span class="hljs-built_in">sum</span>().item() <br> <br>    val_loss /= <span class="hljs-built_in">len</span>(val_loader) <br>    val_acc = correct_val / total_val <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;验证损失：&#123;:.4f&#125;，验证准确率：&#123;:.4f&#125;%&#x27;</span>.<span class="hljs-built_in">format</span>(val_loss, val_acc * <span class="hljs-number">100</span>)) <br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/25060101.png" alt="CIFAR-10"></p><p>以上就是输出的结果。</p><h2 id="在CIFAR-100上实现图像的识别分类"><a href="#在CIFAR-100上实现图像的识别分类" class="headerlink" title="在CIFAR-100上实现图像的识别分类"></a>在CIFAR-100上实现图像的识别分类</h2><p>CIFAR-100，同CIFAR-10一样，不同的是该数据集包含有100种不同的实物，要对100个样本类别进行区分，对应的数据量也水涨船高；</p><p>理论上两者的模型都差不多，但是ResNet-18对100个任务的区分效率低、效果差，因此我们这里尝试使用MobileNet_v2模型对CIFAR-100数据集进行训练，在损失函数以及优化函数的配置上略有不同：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义损失函数和优化器</span><br>criterion = nn.CrossEntropyLoss()<br><span class="hljs-comment"># 使用不同的学习率</span><br>optimizer = torch.optim.AdamW([<br>    &#123;<span class="hljs-string">&#x27;params&#x27;</span>: model.features.parameters(), <span class="hljs-string">&#x27;lr&#x27;</span>: <span class="hljs-number">1e-4</span>&#125;,    <span class="hljs-comment"># 特征提取层使用较小的学习率</span><br>    &#123;<span class="hljs-string">&#x27;params&#x27;</span>: model.classifier.parameters(), <span class="hljs-string">&#x27;lr&#x27;</span>: <span class="hljs-number">1e-3</span>&#125;   <span class="hljs-comment"># 分类层使用较大的学习率</span><br>])<br><br><span class="hljs-comment"># 学习率调度器</span><br>scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="hljs-string">&#x27;min&#x27;</span>, factor=<span class="hljs-number">0.1</span>, patience=<span class="hljs-number">2</span>)<br><br>epochs = <span class="hljs-number">20</span>  <span class="hljs-comment"># 增加训练轮数</span><br></code></pre></td></tr></table></figure><p>损失函数仍然使用交叉损失函数，但是我们在不同的阶段使用不同的学习率，在特征提取阶段使用小的学习率，分类时使用大的学习率。分类的损失直接与模型的表现有关，因此较高的学习率可以更快的收敛；</p><p>使用**分层学习率（layer-wise learning rate decay）**的策略，它的好处包括：</p><ol><li><strong>保留预训练特征</strong>：较小的学习率用于 <code>features</code>，可保持预训练模型学到的通用特征。</li><li><strong>快速适应新任务</strong>：较大的学习率用于 <code>classifier</code>，有利于快速适应 CIFAR-100 新任务。</li><li><strong>训练更稳定、收敛更快</strong>：尤其在轻量网络中，更能体现训练灵活性。</li></ol><hr><p>下面是训练代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python">best_val_acc = <span class="hljs-number">0.0</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;\nEpoch <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;epochs&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span> * <span class="hljs-number">30</span>)<br>    <br>    <span class="hljs-comment"># 训练阶段</span><br>    model.train()<br>    running_loss = <span class="hljs-number">0.0</span><br>    correct_train = <span class="hljs-number">0</span><br>    total_train = <span class="hljs-number">0</span><br>    <br>    <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> tqdm(train_loader, desc=<span class="hljs-string">&#x27;Training&#x27;</span>):<br>        inputs = inputs.to(device)<br>        labels = labels.to(device)<br>        <br>        optimizer.zero_grad()<br>        outputs = model(inputs)<br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br>        <br>        running_loss += loss.item()<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total_train += labels.size(<span class="hljs-number">0</span>)<br>        correct_train += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br>    <br>    train_loss = running_loss / <span class="hljs-built_in">len</span>(train_loader)<br>    train_acc = correct_train / total_train<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Train Loss: <span class="hljs-subst">&#123;train_loss:<span class="hljs-number">.4</span>f&#125;</span> | Train Acc: <span class="hljs-subst">&#123;train_acc*<span class="hljs-number">100</span>:<span class="hljs-number">.2</span>f&#125;</span>%&#x27;</span>)<br>    <br>    <span class="hljs-comment"># 验证阶段</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    val_loss = <span class="hljs-number">0.0</span><br>    correct_val = <span class="hljs-number">0</span><br>    total_val = <span class="hljs-number">0</span><br>    <br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> tqdm(val_loader, desc=<span class="hljs-string">&#x27;Validation&#x27;</span>):<br>            inputs = inputs.to(device)<br>            labels = labels.to(device)<br>            <br>            outputs = model(inputs)<br>            loss = criterion(outputs, labels)<br>            val_loss += loss.item()<br>            <br>            _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>            total_val += labels.size(<span class="hljs-number">0</span>)<br>            correct_val += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br>    <br>    val_loss = val_loss / <span class="hljs-built_in">len</span>(val_loader)<br>    val_acc = correct_val / total_val<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Val Loss: <span class="hljs-subst">&#123;val_loss:<span class="hljs-number">.4</span>f&#125;</span> | Val Acc: <span class="hljs-subst">&#123;val_acc*<span class="hljs-number">100</span>:<span class="hljs-number">.2</span>f&#125;</span>%&#x27;</span>)<br>    <br>    <span class="hljs-comment"># 更新学习率</span><br>    scheduler.step(val_loss)<br>    <br>    <span class="hljs-comment"># 保存最佳模型</span><br>    <span class="hljs-keyword">if</span> val_acc &gt; best_val_acc:<br>        best_val_acc = val_acc<br>        torch.save(model.state_dict(), <span class="hljs-string">&#x27;best_mobilenetv2_cifar100.pth&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Best validation accuracy: <span class="hljs-subst">&#123;best_val_acc*<span class="hljs-number">100</span>:<span class="hljs-number">.2</span>f&#125;</span>%&#x27;</span>)<br><br></code></pre></td></tr></table></figure><p>输出如下：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/25060102.png" alt="CIFAR-10"></p><h2 id="✅-MobileNetV2-相对于-ResNet-18-的优势与适用场景"><a href="#✅-MobileNetV2-相对于-ResNet-18-的优势与适用场景" class="headerlink" title="✅ MobileNetV2 相对于 ResNet-18 的优势与适用场景"></a>✅ MobileNetV2 相对于 ResNet-18 的优势与适用场景</h2><table><thead><tr><th align="left">方面</th><th align="left">ResNet-18</th><th align="left">MobileNetV2</th><th align="left">对比与解释</th></tr></thead><tbody><tr><td align="left"><strong>模型大小</strong></td><td align="left">约 44.6M 参数</td><td align="left">约 3.5M 参数</td><td align="left">MobileNetV2 轻量很多，适合部署在资源受限设备（如嵌入式、手机端）。</td></tr><tr><td align="left"><strong>计算效率</strong></td><td align="left">中等</td><td align="left">更快（低 FLOPs）</td><td align="left">MobileNetV2 使用 <strong>深度可分离卷积</strong>，大大降低计算复杂度。</td></tr><tr><td align="left"><strong>推理速度</strong></td><td align="left">中</td><td align="left">更快</td><td align="left">推理延迟更低，尤其在 CPU 或边缘设备上。</td></tr><tr><td align="left"><strong>准确率（ImageNet）</strong></td><td align="left">Top-1: ~69.8%</td><td align="left">Top-1: ~71.8%</td><td align="left">MobileNetV2 有更优的参数效率。微调后在 CIFAR-100 上表现差距不大。</td></tr><tr><td align="left"><strong>结构深度</strong></td><td align="left">ResNet 残差结构</td><td align="left">Inverted Residual + Linear Bottleneck</td><td align="left">MobileNetV2 更现代、结构紧凑，有利于特征传递与训练。</td></tr><tr><td align="left"><strong>训练稳定性</strong></td><td align="left">非常稳定</td><td align="left">稍敏感于学习率、调度器</td><td align="left">MobileNetV2 结构浅，过大学习率容易震荡，但你设置了合理的 <code>lr</code> 和 <code>scheduler</code>，可以很好控制。</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于贝叶斯决策的分类器</title>
    <link href="/2025/05/24/study/Bayes/"/>
    <url>/2025/05/24/study/Bayes/</url>
    
    <content type="html"><![CDATA[<h1 id="最小错误率贝叶斯决策分类器实战：代码解析与理论详解"><a href="#最小错误率贝叶斯决策分类器实战：代码解析与理论详解" class="headerlink" title="最小错误率贝叶斯决策分类器实战：代码解析与理论详解"></a>最小错误率贝叶斯决策分类器实战：代码解析与理论详解</h1><h2 id="一、背景与应用场景"><a href="#一、背景与应用场景" class="headerlink" title="一、背景与应用场景"></a>一、背景与应用场景</h2><p>贝叶斯决策分类器是一种基于**贝叶斯定理**的统计分类方法，其核心思想是通过最大化后验概率来最小化分类错误率。该方法广泛应用于医学诊断、金融风控等场景，尤其适合特征分布符合正态分布的小规模数据集。本文以鸢尾花（Iris）数据集为例，详解如何实现一个基于贝叶斯决策的分类器 。  </p><h2 id="二、核心代码解析"><a href="#二、核心代码解析" class="headerlink" title="二、核心代码解析"></a>二、核心代码解析</h2><h2 id="1-数据准备与划分"><a href="#1-数据准备与划分" class="headerlink" title="1. 数据准备与划分"></a>1. 数据准备与划分</h2><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-type">X</span>, y = datasets.load_iris().<span class="hljs-class"><span class="hljs-keyword">data</span>, datasets.load_iris().target</span><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：加载鸢尾花数据集，包含4个特征（花萼&#x2F;花瓣长度和宽度）和3个类别（Setosa, Versicolor, Virginica）。   </li><li><strong>理论基础</strong>：数据集需满足<strong>独立同分布</strong>假设，即样本间相互独立且特征分布一致 。</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">X_train, X_test, y_train, y_test = train_test_split(X, y, <span class="hljs-attribute">test_size</span>=0.3, <span class="hljs-attribute">random_state</span>=42)<br><br></code></pre></td></tr></table></figure><ul><li><strong>作用</strong>：按7:3比例划分训练集和测试集，<code>random\_state</code>确保实验可复现 。</li></ul><hr><h3 id="2-先验概率与类别条件概率估计"><a href="#2-先验概率与类别条件概率估计" class="headerlink" title="2. 先验概率与类别条件概率估计"></a>2. 先验概率与类别条件概率估计</h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">class_counts</span> = np.bincount(y_train)<br><span class="hljs-attr">priors</span> = class_counts / len(y_train)<br><br></code></pre></td></tr></table></figure><ul><li><strong>原理</strong>：先验概率 $ P(Y) $ 反映类别在训练集中的分布比例。例如，若某类别占30%样本，则 $ P(Y&#x3D;\text{class}) &#x3D; 0.3 $ 。</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros">class_conditional_probs = []<br><span class="hljs-keyword">for</span> class_idx <span class="hljs-keyword">in</span> range(3):<br>    class_data = X_train[y_train == class_idx]<br>    class_mean = np.mean(class_data, <span class="hljs-attribute">axis</span>=0)<br>    class_cov = np.cov(class_data, <span class="hljs-attribute">rowvar</span>=<span class="hljs-literal">False</span>)<br>    class_conditional_probs.append(multivariate_normal(<span class="hljs-attribute">mean</span>=class_mean, <span class="hljs-attribute">cov</span>=class_cov))<br><br></code></pre></td></tr></table></figure><ul><li><strong>关键步骤</strong>：   <ol><li><strong>类别条件概率建模</strong>：假设每个类别的特征服从多元正态分布，通过均值向量（<code>class\_mean</code>）和协方差矩阵（<code>class\_cov</code>）描述分布特性。   </li><li><strong>参数估计</strong>：使用最大似然估计（MLE）计算均值和协方差矩阵，这是参数化方法的核心 。</li></ol></li></ul><hr><h3 id="3-贝叶斯决策分类器实现"><a href="#3-贝叶斯决策分类器实现" class="headerlink" title="3. 贝叶斯决策分类器实现"></a>3. 贝叶斯决策分类器实现</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MinimumErrorRateBayesianDecision</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">classify</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, features</span>):<br>        posterior_probs = [<span class="hljs-variable language_">self</span>.priors[i] * prob.pdf(features) <span class="hljs-keyword">for</span> i, prob <span class="hljs-keyword">in</span> enumerate(<span class="hljs-variable language_">self</span>.class_conditional_probs)]<br>        <span class="hljs-keyword">return</span> np.argmax(posterior_probs)<br><br></code></pre></td></tr></table></figure><ul><li><strong>决策逻辑</strong>：   <ul><li><strong>后验概率计算</strong>：根据贝叶斯公式 $ P(Y|X) \propto P(Y) \cdot P(X|Y) $，计算每个类别的后验概率。   </li><li><strong>最小错误率决策</strong>：选择后验概率最大的类别作为预测结果，此决策规则理论上最小化分类错误率 。</li></ul></li></ul><hr><h3 id="4-模型评估"><a href="#4-模型评估" class="headerlink" title="4. 模型评估"></a>4. 模型评估</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs stylus">correct_predictions = <span class="hljs-number">0</span><br>class_correct_predictions = <span class="hljs-selector-attr">[0]</span>*<span class="hljs-number">3</span><br>class_total_samples = <span class="hljs-selector-attr">[0]</span>*<span class="hljs-number">3</span><br><br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(X_test)):<br>    predicted_class = classifier<span class="hljs-selector-class">.classify</span>(X_test<span class="hljs-selector-attr">[i]</span>)<br>    class_total_samples<span class="hljs-selector-attr">[y_test[i]</span>] += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> predicted_class == y_test<span class="hljs-selector-attr">[i]</span>:<br>        correct_predictions += <span class="hljs-number">1</span><br>        class_correct_predictions<span class="hljs-selector-attr">[y_test[i]</span>] += <span class="hljs-number">1</span><br><br>accuracy = correct_predictions / <span class="hljs-built_in">len</span>(X_test)<br><br></code></pre></td></tr></table></figure><ul><li><strong>评估指标</strong>：计算整体准确率和类别级别的准确率，验证分类器性能 。</li></ul><hr><h2 id="三、数学原理详解"><a href="#三、数学原理详解" class="headerlink" title="三、数学原理详解"></a>三、数学原理详解</h2><h3 id="1-贝叶斯定理"><a href="#1-贝叶斯定理" class="headerlink" title="1. 贝叶斯定理"></a>1. 贝叶斯定理</h3><p>贝叶斯公式定义为：<br>$$<br>P(Y|X) &#x3D; \frac{P(X|Y) \cdot P(Y)}{P(X)}<br>$$   </p><ul><li><strong>先验概率</strong> $ P(Y) $：类别在训练集中的分布比例。   </li><li><strong>似然</strong> $ P(X|Y) $：类别条件概率密度，通过多元正态分布建模。   </li><li><strong>证据</strong> $ P(X) $：常数项（对所有类别相同），不影响比较后验概率大小 。</li></ul><h3 id="2-多元正态分布假设"><a href="#2-多元正态分布假设" class="headerlink" title="2. 多元正态分布假设"></a>2. 多元正态分布假设</h3><p>假设特征向量 $ X \sim \mathcal{N}(\mu, \Sigma) $，其概率密度函数为：<br>$$<br>f(X) &#x3D; \frac{1}{\sqrt{(2\pi)^k |\Sigma|}} \exp\left( -\frac{1}{2}(X-\mu)^T \Sigma^{-1}(X-\mu) \right)<br>$$   </p><ul><li><strong>均值向量</strong> $ \mu $：反映特征的集中趋势。   </li><li><strong>协方差矩阵</strong> $ \Sigma $：描述特征间的相关性 。</li></ul><h3 id="3-决策边界"><a href="#3-决策边界" class="headerlink" title="3. 决策边界"></a>3. 决策边界</h3><h2 id="当两类的后验概率相等时，即：-P-Y-1-cdot-P-X-Y-1-P-Y-2-cdot-P-X-Y-2-此时对应的超平面即为决策边界，用于划分不同类别的样本空间-。"><a href="#当两类的后验概率相等时，即：-P-Y-1-cdot-P-X-Y-1-P-Y-2-cdot-P-X-Y-2-此时对应的超平面即为决策边界，用于划分不同类别的样本空间-。" class="headerlink" title="当两类的后验概率相等时，即：$$P(Y_1) \cdot P(X|Y_1) &#x3D; P(Y_2) \cdot P(X|Y_2)$$此时对应的超平面即为决策边界，用于划分不同类别的样本空间 。   "></a>当两类的后验概率相等时，即：<br>$$<br>P(Y_1) \cdot P(X|Y_1) &#x3D; P(Y_2) \cdot P(X|Y_2)<br>$$<br>此时对应的超平面即为决策边界，用于划分不同类别的样本空间 。   </h2><h2 id="四、实验结果与分析"><a href="#四、实验结果与分析" class="headerlink" title="四、实验结果与分析"></a>四、实验结果与分析</h2><h3 id="1-分类准确率"><a href="#1-分类准确率" class="headerlink" title="1. 分类准确率"></a>1. 分类准确率</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 输出示例（实际运行结果可能不同）</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Setosa准确率: 1.0&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Versicolor准确率: 0.93&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;整体准确率: 0.95&quot;</span>)<br><br></code></pre></td></tr></table></figure><ul><li><strong>结果分析</strong>：模型在测试集上表现优异，尤其对Setosa类别实现完美分类，表明正态分布假设在该数据集上成立 。</li></ul><h3 id="2-可视化决策边界"><a href="#2-可视化决策边界" class="headerlink" title="2. 可视化决策边界"></a>2. 可视化决策边界</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import matplotlib<span class="hljs-selector-class">.pyplot</span> as plt<br>plt<span class="hljs-selector-class">.scatter</span>(X_test<span class="hljs-selector-attr">[:, 0]</span>, X_test<span class="hljs-selector-attr">[:, 1]</span>, c=y_test, cmap=<span class="hljs-string">&#x27;viridis&#x27;</span>)<br>plt<span class="hljs-selector-class">.xlabel</span>(<span class="hljs-string">&quot;Sepal Length&quot;</span>)<br>plt<span class="hljs-selector-class">.ylabel</span>(<span class="hljs-string">&quot;Sepal Width&quot;</span>)<br>plt<span class="hljs-selector-class">.title</span>(<span class="hljs-string">&quot;Bayesian Decision Boundary&quot;</span>)<br>plt<span class="hljs-selector-class">.colorbar</span>(label=<span class="hljs-string">&quot;Class&quot;</span>)<br>plt<span class="hljs-selector-class">.show</span>()<br><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_02.png" alt="Agglomerative Clustering"><br><em>图2：基于贝叶斯决策的分类边界可视化（示例）</em>   </p><hr><h2 id="五、总结与扩展"><a href="#五、总结与扩展" class="headerlink" title="五、总结与扩展"></a>五、总结与扩展</h2><h3 id="1-优势与局限性"><a href="#1-优势与局限性" class="headerlink" title="1. 优势与局限性"></a>1. 优势与局限性</h3><ul><li><strong>优势</strong>：   <ul><li>理论基础扎实，适用于小规模数据。   </li><li>通过参数估计可解释性强 。</li></ul></li><li><strong>局限性</strong>：   <ul><li>依赖正态分布假设，若实际数据分布偏离较大可能导致性能下降。   </li><li>协方差矩阵可能因样本不足而奇异，需正则化处理 。</li></ul></li></ul><h3 id="2-改进方向"><a href="#2-改进方向" class="headerlink" title="2. 改进方向"></a>2. 改进方向</h3><ul><li><strong>非参数化方法</strong>：使用核密度估计替代正态分布假设。   </li><li><strong>正则化技术</strong>：在协方差矩阵中加入微小扰动（如 <code>class\_cov += 1e-6 \* np.eye(dim)</code>）防止奇异 。</li></ul><blockquote><p>完整代码仓库：[GitHub链接]   </p></blockquote><h1 id="🎃-朴素贝叶斯实现决策分类"><a href="#🎃-朴素贝叶斯实现决策分类" class="headerlink" title="🎃 朴素贝叶斯实现决策分类"></a>🎃 朴素贝叶斯实现决策分类</h1><h3 id="1-导入库"><a href="#1-导入库" class="headerlink" title="1. 导入库"></a>1. 导入库</h3><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_classification <br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt <br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><br></code></pre></td></tr></table></figure><ul><li><strong>作用</strong>：导入所需的库。   <ul><li><code>make\_classification</code>：用于生成合成的分类数据集 。   </li><li><code>matplotlib.pyplot</code>：用于可视化结果。   </li><li><code>numpy</code>：进行数值计算。</li></ul></li></ul><hr><h3 id="2-定义高斯概率密度函数"><a href="#2-定义高斯概率密度函数" class="headerlink" title="2. 定义高斯概率密度函数"></a>2. 定义高斯概率密度函数</h3><figure class="highlight gml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gml">def gaussian_pdf(<span class="hljs-variable language_">x</span>, <span class="hljs-built_in">mean</span>, std_dev): <br>    <span class="hljs-keyword">return</span> (<span class="hljs-number">1</span> / (np.<span class="hljs-built_in">sqrt</span>(<span class="hljs-number">2</span> * np.<span class="hljs-symbol">pi</span>) * std_dev)) * np.<span class="hljs-built_in">exp</span>(<span class="hljs-number">-0.5</span> * ((<span class="hljs-variable language_">x</span> - <span class="hljs-built_in">mean</span>) / std_dev)**<span class="hljs-number">2</span>) <br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：计算单个特征值在高斯分布下的概率密度。   </li><li><strong>公式解释</strong>：</li></ul><p>高斯分布（正态分布）的概率密度函数公式为：<br>$$<br>f(x) &#x3D; \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}}<br>$$<br>其中 <code>mean</code> 是均值 $ \mu $，<code>std\_dev</code> 是标准差 $ \sigma $。   </p><ul><li><strong>应用场景</strong>：在朴素贝叶斯分类器中，假设每个特征在给定类别下服从高斯分布。</li></ul><hr><h3 id="3-自定义数据集划分函数"><a href="#3-自定义数据集划分函数" class="headerlink" title="3. 自定义数据集划分函数"></a>3. 自定义数据集划分函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_test_split</span>(<span class="hljs-params">X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-literal">None</span></span>): <br>    <span class="hljs-keyword">if</span> random_state <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>: <br>        np.random.seed(random_state)    <br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：将数据集划分为训练集和测试集。   </li><li><strong>参数说明</strong>：   <ul><li><code>X</code>：特征数据。   </li><li><code>y</code>：目标标签。   </li><li><code>test\_size</code>：测试集比例（默认 20%）。   </li><li><code>random\_state</code>：随机种子，确保结果可复现 。</li></ul></li><li><strong>实现逻辑</strong>：   <ul><li>使用 <code>np.random.permutation</code> 打乱数据索引。   </li><li>按比例划分测试集和训练集。</li></ul></li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">m</span> = X.shape[<span class="hljs-number">0</span>]                              <span class="hljs-comment"># 获取数据集的大小 </span><br><span class="hljs-attr">permutation</span> = np.random.permutation(m)      <span class="hljs-comment"># 随机生成打乱的数组 对应为打乱的索引</span><br><span class="hljs-attr">test_size</span> = int(m * test_size)              <span class="hljs-comment"># 计算测试集的大小 </span><br><span class="hljs-attr">test_indices</span> = permutation[:test_size]      <span class="hljs-comment"># 取test_size个打乱的索引</span><br><span class="hljs-attr">train_indices</span> = permutation[test_size:]     <span class="hljs-comment"># 取后面所有索引作为训练集    </span><br><br></code></pre></td></tr></table></figure><ul><li><strong>关键步骤</strong>：   <ul><li><code>X.shape[0]</code>：获取样本总数。   </li><li><code>permutation</code>：生成随机索引。   </li><li><code>test\_indices</code>：前 <code>test\_size</code> 个索引作为测试集。   </li><li><code>train\_indices</code>：剩余索引作为训练集。</li></ul></li></ul><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs inform7">X_train = X<span class="hljs-comment">[train_indices]</span> <br>X_test = X<span class="hljs-comment">[test_indices]</span> <br>y_train = y<span class="hljs-comment">[train_indices]</span> <br>y_test = y<span class="hljs-comment">[test_indices]</span> <br> <br>return X_train, X_test, y_train, y_test <br><br></code></pre></td></tr></table></figure><ul><li><strong>输出</strong>：返回划分后的训练集和测试集。</li></ul><hr><h3 id="4-贝叶斯分类器的预测函数"><a href="#4-贝叶斯分类器的预测函数" class="headerlink" title="4. 贝叶斯分类器的预测函数"></a>4. 贝叶斯分类器的预测函数</h3><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs scss">def <span class="hljs-built_in">predict_bayes</span>(x, means, variances, priors): <br>    posteriors = [] <br>    for i in <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(means)): <br>        likelihood = np.<span class="hljs-built_in">prod</span>(<span class="hljs-built_in">gaussian_pdf</span>(x, means[i], np.<span class="hljs-built_in">sqrt</span>(variances[i])))      <br>        posterior = likelihood * priors[i]                                          <br>        posteriors.<span class="hljs-built_in">append</span>(posterior)                                                <br>    return np.<span class="hljs-built_in">argmax</span>(posteriors) <br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：基于朴素贝叶斯算法预测样本类别。   </li><li><strong>步骤解析</strong>：   <ol><li><strong>似然计算</strong>：对每个特征计算高斯概率密度，并通过 <code>np.prod</code> 连乘得到联合概率（假设特征条件独立）。   </li><li><strong>后验概率</strong>：似然乘以先验概率 <code>priors[i]</code>。   </li><li><strong>分类决策</strong>：选择后验概率最大的类别作为预测结果（<code>np.argmax</code>）。</li></ol></li></ul><hr><h3 id="5-生成合成数据集"><a href="#5-生成合成数据集" class="headerlink" title="5. 生成合成数据集"></a>5. 生成合成数据集</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">X, y = make_classification(<span class="hljs-attribute">n_samples</span>=1500, <span class="hljs-attribute">n_features</span>=2, <br>                            <span class="hljs-attribute">n_informative</span>=2, <span class="hljs-attribute">n_redundant</span>=0,  <br>                            <span class="hljs-attribute">n_clusters_per_class</span>=1, <span class="hljs-attribute">random_state</span>=6) <br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：生成一个二维二分类数据集。   </li><li><strong>参数解释</strong>：   <ul><li><code>n\_samples=1500</code>：生成 1500 个样本。   </li><li><code>n\_features=2</code>：每个样本有 2 个特征（x1, x2）。   </li><li><code>n\_informative=2</code>：两个特征均为信息性特征（用于分类）。   </li><li><code>n\_redundant=0</code>：无冗余特征。   </li><li><code>n\_clusters\_per\_class=1</code>：每个类别有 1 个聚类中心。   </li><li><code>random\_state=6</code>：确保数据生成可复现 。</li></ul></li></ul><hr><h3 id="6-数据集划分"><a href="#6-数据集划分" class="headerlink" title="6. 数据集划分"></a>6. 数据集划分</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">X_train, X_test, y_train, y_test = train_test_split(X, y, <span class="hljs-attribute">test_size</span>=0.2, <span class="hljs-attribute">random_state</span>=2)<br><br></code></pre></td></tr></table></figure><ul><li><strong>作用</strong>：将数据集按 80%&#x2F;20% 划分为训练集和测试集。</li></ul><hr><h3 id="7-计算类别均值和方差"><a href="#7-计算类别均值和方差" class="headerlink" title="7. 计算类别均值和方差"></a>7. 计算类别均值和方差</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs maxima">unique_classes = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">unique</span>(y_train) <br><br>means = []          <br>variances = []      <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> unique_classes: <br>    X_train_class_i = X_train[y_train == i]                 <br>    mean_class_i = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">mean</span>(X_train_class_i, axis=<span class="hljs-number">0</span>)         <br>    variance_class_i = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">var</span>(X_train_class_i, axis=<span class="hljs-number">0</span>)     <br>    means.<span class="hljs-built_in">append</span>(mean_class_i) <br>    variances.<span class="hljs-built_in">append</span>(variance_class_i) <br> <br>means = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>(means) <br>variances = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>(variances) <br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：对每个类别计算特征的均值和方差。   </li><li><strong>关键点</strong>：   <ul><li><code>np.unique(y\_train)</code>：获取训练集中所有类别标签。   </li><li><code>X\_train[y\_train == i]</code>：筛选当前类别的样本。   </li><li><code>np.mean</code> 和 <code>np.var</code>：计算均值和方差。</li></ul></li></ul><hr><h3 id="8-计算先验概率"><a href="#8-计算先验概率" class="headerlink" title="8. 计算先验概率"></a>8. 计算先验概率</h3><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">priors</span> <span class="hljs-operator">=</span> [np.mean(y_train <span class="hljs-operator">=</span><span class="hljs-operator">=</span> i) for i in np.unique(y_train)] <br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：计算每个类别的先验概率 $ P(Y) $。   </li><li><strong>实现原理</strong>：</li></ul><h2 id="对于布尔数组-y-train-i，np-mean-返回-True（即类别-i-的样本）的比例。"><a href="#对于布尔数组-y-train-i，np-mean-返回-True（即类别-i-的样本）的比例。" class="headerlink" title="对于布尔数组 y\_train == i，np.mean 返回 True（即类别 i 的样本）的比例。   "></a>对于布尔数组 <code>y\_train == i</code>，<code>np.mean</code> 返回 <code>True</code>（即类别 i 的样本）的比例。   </h2><h3 id="9-预测与评估"><a href="#9-预测与评估" class="headerlink" title="9. 预测与评估"></a>9. 预测与评估</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">y_pred = <span class="hljs-selector-attr">[predict_bayes(x, means, variances, priors) for x in X_test]</span> <br>correct = np<span class="hljs-selector-class">.sum</span>(y_pred == y_test) / <span class="hljs-built_in">len</span>(y_test)                            <br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;Accuracy: &#123;:.2f&#125;%&quot;</span>.format(correct * <span class="hljs-number">100</span>)</span></span>) <br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：   <ul><li>对测试集逐样本预测类别。   </li><li>计算准确率：预测正确的样本数占总样本数的比例。</li></ul></li></ul><hr><h3 id="10-可视化结果"><a href="#10-可视化结果" class="headerlink" title="10. 可视化结果"></a>10. 可视化结果</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs stylus">plt<span class="hljs-selector-class">.figure</span>(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>))<br>scatter_true = plt<span class="hljs-selector-class">.scatter</span>(X_test<span class="hljs-selector-attr">[:, 0]</span>, X_test<span class="hljs-selector-attr">[:, 1]</span>, c=y_test,  <br>                           s=<span class="hljs-number">30</span>, cmap=<span class="hljs-string">&#x27;coolwarm&#x27;</span>,label=<span class="hljs-string">&#x27;True class&#x27;</span>) <br>scatter_pred = plt<span class="hljs-selector-class">.scatter</span>(X_test<span class="hljs-selector-attr">[:, 0]</span>, X_test<span class="hljs-selector-attr">[:, 1]</span>, s=<span class="hljs-number">30</span>,  <br>                           facecolors=<span class="hljs-string">&#x27;none&#x27;</span>,  <br>                           edgecolors=np<span class="hljs-selector-class">.array</span>(<span class="hljs-selector-attr">[<span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>]</span>)<span class="hljs-selector-attr">[y_pred]</span>, <br>                           <span class="hljs-selector-tag">label</span> = <span class="hljs-string">&#x27;Predicted class&#x27;</span>) <br>plt<span class="hljs-selector-class">.legend</span>(handles=<span class="hljs-selector-attr">[scatter_true, scatter_pred]</span>) <br>plt<span class="hljs-selector-class">.show</span>()<br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：可视化测试集的真实标签和预测结果。   </li><li><strong>图形说明</strong>：   <ul><li><code>c=y\_test</code>：颜色表示真实类别（红&#x2F;蓝）。   </li><li><code>edgecolors=np.array([&#39;b&#39;, &#39;r&#39;])[y\_pred]</code>：边缘颜色表示预测类别。   </li><li><code>facecolors=&#39;none&#39;</code>：仅显示边缘，便于对比预测与真实标签。</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_03.png" alt="Accuracy&#x3D;95%"> </p><hr><h3 id="关键知识点总结"><a href="#关键知识点总结" class="headerlink" title="关键知识点总结"></a>关键知识点总结</h3><ol><li><strong>朴素贝叶斯假设</strong>：特征之间条件独立，通过连乘计算联合概率 。   </li><li><strong>高斯分布建模</strong>：假设每个特征在给定类别下服从正态分布。   </li><li><strong>先验概率估计</strong>：通过训练集中类别的频率计算 $ P(Y) $。   </li><li><strong>决策规则</strong>：最大化后验概率 $ P(Y|X) \propto P(X|Y)P(Y) $。</li></ol><hr><h1 id="核函数估计概率密度函数的朴素贝叶斯"><a href="#核函数估计概率密度函数的朴素贝叶斯" class="headerlink" title="核函数估计概率密度函数的朴素贝叶斯"></a>核函数估计概率密度函数的朴素贝叶斯</h1><h3 id="1-predict-bayes-函数：基于损失矩阵的贝叶斯决策"><a href="#1-predict-bayes-函数：基于损失矩阵的贝叶斯决策" class="headerlink" title="1. predict_bayes 函数：基于损失矩阵的贝叶斯决策"></a>1. predict_bayes 函数：基于损失矩阵的贝叶斯决策</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_bayes</span>(<span class="hljs-params">x, parzen_estimations, priors, loss_matrix</span>): <br>    expected_losses = []                                        <span class="hljs-comment"># 初始化期望损失列表 </span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(parzen_estimations)): <br>        expected_loss = <span class="hljs-number">0</span>                                       <span class="hljs-comment"># 初始化期望损失 </span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(parzen_estimations)): <br>            posterior = priors[i] * parzen_estimations[i]       <span class="hljs-comment"># 计算后验概率     </span><br>            expected_loss += loss_matrix[i][j] * posterior      <span class="hljs-comment"># 计算期望损失 </span><br>        expected_losses.append(expected_loss)                   <span class="hljs-comment"># 将期望损失添加到列表中 </span><br>    <span class="hljs-keyword">return</span> np.argmin(expected_losses, axis=<span class="hljs-number">0</span>)                   <span class="hljs-comment"># 返回期望损失最小的类别作为预测结果</span><br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：根据<strong>期望损失最小化</strong>原则，将输入样本 <code>x</code> 分类到某个类别。   </li><li><strong>关键步骤解析</strong>：   <ol><li><strong>后验概率计算</strong>：    <figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">posterior</span> <span class="hljs-operator">=</span> priors[i] * parzen_estimations[i]<br><br></code></pre></td></tr></table></figure><ul><li><strong>公式</strong>：</li></ul></li></ol><ul><li><strong>理论依据</strong>：贝叶斯定理 $ P(Y|X) &#x3D; \frac{P(Y) \cdot P(X|Y)}{P(X)} $，分母 $ P(X) $ 对所有类别相同，可忽略 。</li></ul></li></ul><ol><li><strong>期望损失计算</strong>：    <figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">expected_loss += loss_matrix<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span> * posterior<br><br></code></pre></td></tr></table></figure><ul><li><strong>公式</strong>：</li></ul></li></ol><ul><li><strong>理论依据</strong>：贝叶斯决策的目标是最小化<strong>条件风险</strong>（即期望损失），而非单纯最大化后验概率 。</li></ul><ol start="2"><li><strong>决策规则</strong>：    <figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs kotlin"><span class="hljs-keyword">return</span> np.argmin(expected_losses, axis=<span class="hljs-number">0</span>)<br><br></code></pre></td></tr></table></figure><ul><li><strong>解释</strong>：选择期望损失最小的类别 <code>j</code> 作为预测结果，而非直接选择后验概率最大的类别。   </li><li><strong>对比普通贝叶斯</strong>：普通朴素贝叶斯仅比较后验概率（即损失矩阵为单位矩阵时的情况），而此代码通过自定义 <code>loss\_matrix</code> 实现<strong>风险敏感决策</strong> 。</li></ul></li></ol><hr><h3 id="2-Parzen窗口估计：非参数概率密度估计"><a href="#2-Parzen窗口估计：非参数概率密度估计" class="headerlink" title="2. Parzen窗口估计：非参数概率密度估计"></a>2. Parzen窗口估计：非参数概率密度估计</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell">def parzen_window_estimation(x, <span class="hljs-keyword">data</span>, <span class="hljs-built_in">h</span>=<span class="hljs-number">1</span>, window_func=squ_window): <br>    N, d = data.shape                           <span class="hljs-comment"># 获取数据的数量和维度</span><br>    k_n = window_func(cdist(x, <span class="hljs-keyword">data</span>) / <span class="hljs-built_in">h</span>)       <span class="hljs-comment"># 计算每个样本到x的距离并应用窗口函数限制权重</span><br>    <span class="hljs-keyword">return</span> np.sum(k_n, axis=<span class="hljs-number">1</span>) / (N * <span class="hljs-built_in">h</span>**d)     <span class="hljs-comment"># 返回Parzen窗口估计的结果 shape=[N, ] h是窗大小</span><br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：通过Parzen窗口法估计样本 <code>x</code> 的概率密度。   </li><li><strong>关键步骤解析</strong>：   <ol><li><strong>距离计算</strong>：    <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">cdist</span><span class="hljs-params">(x, data)</span></span> / h<br><br></code></pre></td></tr></table></figure><ul><li><strong>作用</strong>：计算测试样本 <code>x</code> 与所有训练样本 <code>data</code> 的欧氏距离，并除以带宽 <code>h</code> 进行归一化。   </li><li><strong>理论依据</strong>：Parzen窗口是一种非参数密度估计方法，通过核函数（窗口函数）加权邻域内的样本点 。</li></ul></li><li><strong>窗口函数应用</strong>：    <figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-function"><span class="hljs-title">window_func</span>(<span class="hljs-params">...</span>)</span><br><br></code></pre></td></tr></table></figure><ul><li><strong>窗口函数类型</strong>：   <ul><li><strong>方窗</strong>（<code>squ\_window</code>）：仅统计距离在 <code>[-h/2, h/2]</code> 内的样本。   </li><li><strong>正态窗</strong>（<code>nor\_window</code>）：使用高斯分布权重（权重随距离指数衰减）。   </li><li><strong>指数窗</strong>（<code>exp\_window</code>）：权重随距离线性衰减。   </li><li><strong>三角窗</strong>（<code>tri\_window</code>）：权重随距离线性衰减至零。</li></ul></li><li><strong>理论依据</strong>：不同窗口函数对密度估计的平滑性有影响，正态窗适合连续分布，方窗适合离散分布 。</li></ul></li><li><strong>密度估计值</strong>：    <figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lasso">np.<span class="hljs-keyword">sum</span>(<span class="hljs-params">...</span>) / (N * h**d)<br><br></code></pre></td></tr></table></figure><ul><li><strong>公式</strong>：</li></ul></li></ol><ul><li><strong>理论依据</strong>：Parzen窗口通过核密度估计逼近真实分布，无需假设数据服从特定分布 。</li></ul></li></ul><hr><h3 id="3-代码整体流程与贝叶斯决策的关系"><a href="#3-代码整体流程与贝叶斯决策的关系" class="headerlink" title="3. 代码整体流程与贝叶斯决策的关系"></a>3. 代码整体流程与贝叶斯决策的关系</h3><ol><li><strong>训练阶段</strong>：   <ul><li>对每个类别 <code>i</code>，使用训练数据 <code>X\_train[y\_train == i]</code> 计算 Parzen 窗口密度估计 <code>parzen\_estimations[i]</code>。   </li><li>计算每个类别的先验概率 <code>priors[i] = P(Y=i)</code>。</li></ul></li><li><strong>预测阶段</strong>：   <ul><li>对每个测试样本 <code>x</code>：   <ul><li>使用 Parzen 窗口法计算其在每个类别下的概率密度 <code>parzen\_estimations</code>。   </li><li>结合先验概率和损失矩阵，计算每个可能决策的期望损失。   </li><li>选择期望损失最小的类别作为预测结果。</li></ul></li></ul></li><li><strong>与普通朴素贝叶斯的区别</strong>：   <ul><li><strong>普通朴素贝叶斯</strong>：假设特征服从特定分布（如高斯分布），且特征条件独立，直接计算后验概率。   </li><li><strong>本代码实现</strong>：   <ul><li>使用非参数方法（Parzen窗口）估计概率密度，无需假设分布形式。   </li><li>引入损失矩阵，允许自定义误分类代价（如医疗诊断中误诊癌症的代价更高）。</li></ul></li></ul></li></ol><hr><h3 id="4-关键参数的作用"><a href="#4-关键参数的作用" class="headerlink" title="4. 关键参数的作用"></a>4. 关键参数的作用</h3><ul><li>带宽 <code>**h**</code>：   <ul><li><code>h</code> 越大，密度估计越平滑（可能欠拟合），<code>h</code> 越小，密度估计越尖锐（可能过拟合）。</li></ul></li><li><strong>窗口函数</strong>：   <ul><li>方窗（<code>squ\_window</code>）适合离散分布，正态窗（<code>nor\_window</code>）适合连续分布。</li></ul></li><li>损失矩阵 <code>**loss\_matrix**</code>：   <ul><li>单位矩阵（<code>[[0,1],[1,0]]</code>）对应最小错误率决策，非单位矩阵对应最小风险决策 。</li></ul></li></ul><hr><h3 id="5-示例说明"><a href="#5-示例说明" class="headerlink" title="5. 示例说明"></a>5. 示例说明</h3><p>假设 <code>loss\_matrix = [[0, 2], [1, 0]]</code>：   </p><ul><li>将实际类别为 0 的样本误判为 1 的代价是 2，而将实际类别为 1 的样本误判为 0 的代价是 1。   </li><li>分类器会更倾向于避免将类别 0 误判为 1，从而在代价敏感场景下优化决策 。</li></ul><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li><strong>核心思想</strong>：通过非参数密度估计（Parzen窗口）和风险最小化（损失矩阵）实现灵活的贝叶斯决策。   </li><li><strong>适用场景</strong>：   <ul><li>数据分布未知或非高斯分布。   </li><li>不同类别的误分类代价不一致（如医疗、金融风控）。</li></ul></li><li><strong>改进方向</strong>：   <ul><li>使用交叉验证选择最优带宽 <code>h</code>。   </li><li>替换更复杂的核函数（如高斯混合核）。</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_01.png" alt="Accuracy&#x3D;97%"></p><p>➡️ 通过加窗以及损失矩阵补偿错误判断，可以发现对于同一个数据在分类的正确性上有一定的增强；   </p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
      <tag>Python</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MQTT+LuatOS学习日志</title>
    <link href="/2025/05/23/study/How_use_mqtt_in_LuatOS/"/>
    <url>/2025/05/23/study/How_use_mqtt_in_LuatOS/</url>
    
    <content type="html"><![CDATA[<h2 id="MQTT基础概念："><a href="#MQTT基础概念：" class="headerlink" title="MQTT基础概念："></a>MQTT基础概念：</h2><h2 id="MQTT是一种通信架构；MQTT是一个一对多的通信架构，一个服务端（Broker）可以有多个客户端（Client）；"><a href="#MQTT是一种通信架构；MQTT是一个一对多的通信架构，一个服务端（Broker）可以有多个客户端（Client）；" class="headerlink" title="MQTT是一种通信架构；MQTT是一个一对多的通信架构，一个服务端（Broker）可以有多个客户端（Client）；   "></a>MQTT是一种通信架构；<br>MQTT是一个一对多的通信架构，一个服务端（Broker）可以有多个客户端（Client）；   </h2><p>MQTT中有三个概念：   </p><ol><li>主题（Topic）   </li><li>发布（Publish）   </li><li>订阅（Subscribe）</li></ol><p>主题是一种寻址方式，类似于Window的文件夹多级目录<br><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_2.png" alt="Topic"></p><h2 id="例如-factory-line1-machine3-temperature-等等，不同的Topic指向不同的内容以及类别；"><a href="#例如-factory-line1-machine3-temperature-等等，不同的Topic指向不同的内容以及类别；" class="headerlink" title="例如 factory/line1/machine3/temperature 等等，不同的Topic指向不同的内容以及类别；   "></a>例如 <code>factory/line1/machine3/temperature</code> 等等，不同的Topic指向不同的内容以及类别；   </h2><p>客户端Client可以即作为发布的来源也可以订阅发布的内容；<br><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_b.png" alt="Client"></p><h2 id="而Broker作为信息的中转站，接收发布的信息并推送给订阅的用户端；"><a href="#而Broker作为信息的中转站，接收发布的信息并推送给订阅的用户端；" class="headerlink" title="而Broker作为信息的中转站，接收发布的信息并推送给订阅的用户端；   "></a>而Broker作为信息的中转站，接收发布的信息并推送给订阅的用户端；   </h2><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_j.png" alt="Broker"></p><h2 id="发布者无需担心是否将信息发送给了订阅者，准确来说发布者与订阅者之间不是直连的！"><a href="#发布者无需担心是否将信息发送给了订阅者，准确来说发布者与订阅者之间不是直连的！" class="headerlink" title="发布者无需担心是否将信息发送给了订阅者，准确来说发布者与订阅者之间不是直连的！   "></a>发布者无需担心是否将信息发送给了订阅者，准确来说发布者与订阅者之间不是直连的！   </h2><h2 id="LuatOS中MQTT的API"><a href="#LuatOS中MQTT的API" class="headerlink" title="LuatOS中MQTT的API"></a>LuatOS中MQTT的API</h2><h3 id="常量："><a href="#常量：" class="headerlink" title="常量："></a>常量：</h3><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image.png" alt="const"></p><h3 id="订阅主题："><a href="#订阅主题：" class="headerlink" title="订阅主题："></a>订阅主题：</h3><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_z.png" alt="subscribe"></p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Lua"><span class="hljs-comment">-- 订阅单个topic, 且qos=0mqttc:subscribe(&quot;/luatos/123456&quot;, 0)</span><br><span class="hljs-comment">-- 订阅单个topic, 且qos=1mqttc:subscribe(&quot;/luatos/12345678&quot;, 1)</span><br><span class="hljs-comment">-- 订阅多个topic, 且使用不同的qos -&gt; &#123; , &#125;区分不同topic</span><br>mqttc:subscribe(&#123;[<span class="hljs-string">&quot;/luatos/1234567&quot;</span>]=<span class="hljs-number">1</span>,[<span class="hljs-string">&quot;/luatos/12345678&quot;</span>]=<span class="hljs-number">2</span>&#125;)<br></code></pre></td></tr></table></figure><h3 id="创建Client："><a href="#创建Client：" class="headerlink" title="创建Client："></a>创建Client：</h3><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_s.png" alt="Create Client"></p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs Lua"><span class="hljs-comment">-- 普通TCP链接</span><br>mqttc = mqtt.<span class="hljs-built_in">create</span>(<span class="hljs-literal">nil</span>,<span class="hljs-string">&quot;120.55.137.106&quot;</span>, <span class="hljs-number">1884</span>)<br><span class="hljs-comment">-- 普通TCP链接,mqtt接收缓冲区4096</span><br>mqttc = mqtt.<span class="hljs-built_in">create</span>(<span class="hljs-literal">nil</span>,<span class="hljs-string">&quot;120.55.137.106&quot;</span>, <span class="hljs-number">1884</span>, <span class="hljs-literal">nil</span>, &#123;rxSize = <span class="hljs-number">4096</span>&#125;)<br><span class="hljs-comment">-- 加密TCP链接,不验证服务器证书</span><br>mqttc = mqtt.<span class="hljs-built_in">create</span>(<span class="hljs-literal">nil</span>,<span class="hljs-string">&quot;120.55.137.106&quot;</span>, <span class="hljs-number">8883</span>, <span class="hljs-literal">true</span>)<br><span class="hljs-comment">-- 加密TCPTCP链接,单服务器证书验证</span><br>mqttc = mqtt.<span class="hljs-built_in">create</span>(<span class="hljs-literal">nil</span>,<span class="hljs-string">&quot;120.55.137.106&quot;</span>, <span class="hljs-number">8883</span>, &#123;server_cert=<span class="hljs-built_in">io</span>.readFile(<span class="hljs-string">&quot;/luadb/ca.crt&quot;</span>)&#125;)<br><span class="hljs-comment">-- 加密TCPTCP链接,单服务器证书验证, 但可选认证</span><br>mqttc = mqtt.<span class="hljs-built_in">create</span>(<span class="hljs-literal">nil</span>,<span class="hljs-string">&quot;120.55.137.106&quot;</span>, <span class="hljs-number">8883</span>, &#123;server_cert=<span class="hljs-built_in">io</span>.readFile(<span class="hljs-string">&quot;/luadb/ca.crt&quot;</span>), verify=<span class="hljs-number">1</span>&#125;)<br><span class="hljs-comment">-- 加密TCPTCP链接,双向证书验证</span><br>mqttc = mqtt.<span class="hljs-built_in">create</span>(<span class="hljs-literal">nil</span>,<span class="hljs-string">&quot;120.55.137.106&quot;</span>, <span class="hljs-number">8883</span>, &#123;server_cert=<span class="hljs-built_in">io</span>.readFile(<span class="hljs-string">&quot;/luadb/ca.crt&quot;</span>),client_cert=<span class="hljs-built_in">io</span>.readFile(<span class="hljs-string">&quot;/luadb/client.pem&quot;</span>),client_key=<span class="hljs-built_in">io</span>.readFile(<span class="hljs-string">&quot;/luadb/client.key&quot;</span>),client_password=<span class="hljs-string">&quot;123456&quot;</span>,&#125;)<br></code></pre></td></tr></table></figure><p>上述MQTT的通信协议为TCP，官方文档说不支持Websocket！   </p><h3 id="设置登录Client的信息："><a href="#设置登录Client的信息：" class="headerlink" title="设置登录Client的信息："></a>设置登录Client的信息：</h3><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_q.png" alt="auth"></p><h3 id="MQTT服务器连接："><a href="#MQTT服务器连接：" class="headerlink" title="MQTT服务器连接："></a>MQTT服务器连接：</h3><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_1q.png" alt="connect"></p><h3 id="MQTT发布："><a href="#MQTT发布：" class="headerlink" title="MQTT发布："></a>MQTT发布：</h3><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_r.png" alt="publish"></p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Lua"><span class="hljs-comment">--   topic         data</span><br>mqttc:publish(<span class="hljs-string">&quot;/luatos/123456&quot;</span>, <span class="hljs-string">&quot;123&quot;</span>)<br></code></pre></td></tr></table></figure><h3 id="检测状态："><a href="#检测状态：" class="headerlink" title="检测状态："></a>检测状态：</h3><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_m.png" alt="Check State"></p><h2 id="Lua语言的整体框架"><a href="#Lua语言的整体框架" class="headerlink" title="Lua语言的整体框架"></a>Lua语言的整体框架</h2><hr><p>在Lua中，通过调用 <code>require(&quot;sys&quot;)</code> 定义一个实例sys，可以通过这个实例来创建系统任务：<br><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image_h.png" alt="example"><br>可以同时创建多个任务，每个任务之间并行运行，且运行都限制在自己的上下文中，保障不同任务之间不会相互干扰。如果想要让不同的任务之间有先后执行的逻辑可以通过   </p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Lua">sys.publish(<span class="hljs-string">&quot;net_ready&quot;</span>, device_IMEI)<br>sys.waitUntil(<span class="hljs-string">&quot;net_ready&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>这两句代码实现。一个用于发布一条事件，另一个等待该事件的完成，由此得到一个执行的先后顺序；   </p><h2 id="MQTT-Lua语言示例代码："><a href="#MQTT-Lua语言示例代码：" class="headerlink" title="MQTT+Lua语言示例代码："></a>MQTT+Lua语言示例代码：</h2><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Lua"><span class="hljs-comment">-- LuaTools需要PROJECT和VERSION这两个信息</span><br>PROJECT = <span class="hljs-string">&quot;mqttdemo&quot;</span><br>VERSION = <span class="hljs-string">&quot;1.0.0&quot;</span><br></code></pre></td></tr></table></figure><p>.lua文件的开头必须要PROJECT的名称以及VERSION的版本；   </p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs Lua"><span class="hljs-comment">--根据自己的服务器修改以下参数</span><br><span class="hljs-keyword">local</span> mqtt_host = <span class="hljs-string">&quot;lbsmqtt.airm2m.com&quot;</span><br><span class="hljs-keyword">local</span> mqtt_port = <span class="hljs-number">1884</span><br><span class="hljs-keyword">local</span> mqtt_isssl = <span class="hljs-literal">false</span><br><span class="hljs-keyword">local</span> ca_file = <span class="hljs-literal">false</span><br><br><span class="hljs-comment">--必须跟服务器的配置一样</span><br><span class="hljs-keyword">local</span> client_id = <span class="hljs-string">&quot;mqttx_b55c41b7&quot;</span><br><span class="hljs-keyword">local</span> user_name = <span class="hljs-string">&quot;user&quot;</span><br><span class="hljs-keyword">local</span> password = <span class="hljs-string">&quot;password&quot;</span><br><br><span class="hljs-keyword">local</span> pub_topic = <span class="hljs-string">&quot;/luatos/pub/123&quot;</span><span class="hljs-comment">-- .. (mcu.unique_id():toHex())</span><br><span class="hljs-keyword">local</span> sub_topic = <span class="hljs-string">&quot;/luatos/sub/123&quot;</span><span class="hljs-comment">-- .. (mcu.unique_id():toHex())</span><br></code></pre></td></tr></table></figure><p>用户的参数配置：<br>host以及port是自己服务器的参数，isssl表示是否加密连接；   </p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Lua"><span class="hljs-comment">-- 结尾总是这一句</span><br>sys.run()<br><span class="hljs-comment">-- sys.run()之后后面不要加任何语句!!!!!</span><br></code></pre></td></tr></table></figure><h2 id="结束的语句，启动sys并且循环运行任务列表里面的任务。"><a href="#结束的语句，启动sys并且循环运行任务列表里面的任务。" class="headerlink" title="结束的语句，启动sys并且循环运行任务列表里面的任务。   "></a>结束的语句，启动sys并且循环运行任务列表里面的任务。   </h2><p>整体的流程：   </p><ol><li>设置两个系统内部任务，任务一为联网，4G模块提供SIM卡成功联网并且返回设备的IMEI号；   </li><li>设置第二个任务，将设备的IMEI号分配给Client，并且设置发布、订阅的主题，确保独立性；   </li><li>创建mqtt连接（不一定正常连接上），以设备号以及预设置的user name和password配置mqtt，可以设置自动重连；   </li><li>编写mqtt回调函数，在mqtt回调函数中检测事件，当连接上mqtt时将数据打包并且通过publish发给broker；</li></ol><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs Lua">mqttc:on(<span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">(mqtt_client, event, data, payload)</span></span><br><span class="hljs-built_in">log</span>.info(<span class="hljs-string">&quot;mqtt&quot;</span>, <span class="hljs-string">&quot;event&quot;</span>, event) <span class="hljs-comment">-- 可有</span><br><span class="hljs-keyword">if</span> event == <span class="hljs-string">&quot;conack&quot;</span> <span class="hljs-keyword">then</span><br>    <span class="hljs-comment">-- MQTT 连接成功</span><br>    sys.publish(<span class="hljs-string">&quot;mqtt_conack&quot;</span>)<br>    mqtt_client:subscribe(sub_topic)<br><br>   <span class="hljs-comment">-- 采集设备信息</span><br>   <span class="hljs-keyword">local</span> imei = mobile.imei()<br>   <span class="hljs-keyword">local</span> csq = mobile.csq()            <span class="hljs-comment">-- 信号强度</span><br>    <span class="hljs-keyword">local</span> voltage = mobile.getVbatt()   <span class="hljs-comment">-- 电池电压（单位 mV）</span><br><br>   <span class="hljs-comment">-- 构造 JSON 格式的 payload 数据</span><br>    <span class="hljs-keyword">local</span> device_data = json.encode(&#123;<br>        imei = imei,<br>        csq = csq,<br>        voltage = voltage,<br>        timestamp = <span class="hljs-built_in">os</span>.<span class="hljs-built_in">time</span>()<br>   &#125;)<br><br>   <span class="hljs-built_in">log</span>.info(<span class="hljs-string">&quot;mqtt&quot;</span>, <span class="hljs-string">&quot;publish data&quot;</span>, device_data)<br><br>    <span class="hljs-comment">-- 发布数据到 topic（发布一次）</span><br>    mqtt_client:publish(pub_topic, device_data, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment">-- 可选：配置一个上网指示灯亮起</span><br>   gpio.set(<span class="hljs-number">11</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment">-- 设置 GPIO11 为高电平，表示联网成功</span><br><span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span>)<br><br></code></pre></td></tr></table></figure><p>一些Lua语言的细节：   </p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs Lua"><span class="hljs-comment">-- _G -&gt; GLOBAL VALUE</span><br><span class="hljs-built_in">_G</span>.sys = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;sys&quot;</span>)<br><span class="hljs-built_in">_G</span>.sysplus = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;sysplus&quot;</span>)<br><span class="hljs-built_in">_G</span>.mobile = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;mobile&quot;</span>)<br><span class="hljs-built_in">_G</span>.uart = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;uart&quot;</span>)<br><br><span class="hljs-comment">-- uart init</span><br>uart.setup(<br>    uart_id,<br>    uart_baud,<br>    uart_bitwidth,<br>    uart_stopbit<br>)<br><br><span class="hljs-comment">-- system inner tasks</span><br>sys.taskInit(<span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>    <span class="hljs-keyword">local</span> device_id = mobile.imei() <span class="hljs-comment">-- read AIR780EG&#x27;s IMEI</span><br>    <span class="hljs-comment">-- waiting for 4G connected</span><br>    sys.waitUntil(<span class="hljs-string">&quot;IP_READY&quot;</span>)<br><span class="hljs-comment">-- system publish event</span><br>    sys.publish(<span class="hljs-string">&quot;net_ready&quot;</span>, device_id)<br><span class="hljs-keyword">end</span>)<br><br></code></pre></td></tr></table></figure><p>下面是一个完整的脚本，具体的内容如下：   </p><ol><li>任务一：实现联网功能并在联网后发布事件；   </li><li>任务二：等待联网事件，并根据IMEI设置client-id以及发布、订阅主题；之后根据配置创建mqtt连接并尝试连接；在mqtt回调函数中，如果连接上了则通过串口向单片机发送信息，并发布mqtt连接事件；   </li><li>任务三：等待mqtt连接事件，之后开始接收单片传入的数据并且定位数据位置，将数据打包并通过mqtt上传云端；</li></ol><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><code class="hljs Lua">PROJECT = <span class="hljs-string">&quot;AIR780EG_DEMO&quot;</span><br>VERSION = <span class="hljs-string">&quot;1.0.0&quot;</span><br><br><span class="hljs-comment">-- Setup instance</span><br><span class="hljs-built_in">_G</span>.sys = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;sys&quot;</span>)<br><span class="hljs-built_in">_G</span>.sysplus = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;sysplus&quot;</span>)<br><br><span class="hljs-keyword">local</span> wdt = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;wdt&quot;</span>)<br><span class="hljs-keyword">local</span> <span class="hljs-built_in">log</span> = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;log&quot;</span>)<br><span class="hljs-keyword">local</span> uart = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;uart&quot;</span>)<br><span class="hljs-keyword">local</span> mobile = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;mobile&quot;</span>)<br><span class="hljs-keyword">local</span> mqtt = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;mqtt&quot;</span>)    <span class="hljs-comment">-- 加载 mqtt 模块</span><br><span class="hljs-keyword">local</span> rtos = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;rtos&quot;</span>)    <span class="hljs-comment">-- 加载 rtos 模块（用于识别平台）</span><br><span class="hljs-keyword">local</span> pm = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;pm&quot;</span>)        <span class="hljs-comment">-- 加载电源管理模块（用于电源配置）</span><br><br><span class="hljs-keyword">if</span> wdt <span class="hljs-keyword">then</span><br>    <span class="hljs-comment">--添加硬狗防止程序卡死，在支持的设备上启用这个功能</span><br>    wdt.init(<span class="hljs-number">9000</span>)<span class="hljs-comment">--初始化watchdog设置为9s</span><br>    sys.timerLoopStart(wdt.feed, <span class="hljs-number">3000</span>)<span class="hljs-comment">--3s喂一次狗</span><br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">-- uart configuration</span><br><span class="hljs-keyword">local</span> uart_id = <span class="hljs-number">1</span><br><span class="hljs-keyword">local</span> uart_baud = <span class="hljs-number">115200</span><br><span class="hljs-keyword">local</span> uart_bitwidth = <span class="hljs-number">8</span><br><span class="hljs-keyword">local</span> uart_stopbit = <span class="hljs-number">1</span><br>uart.Setup(uart_id, uart_baud, uart_bitwidth, uart_stopbit)<br><br><span class="hljs-comment">-- server configuration</span><br><span class="hljs-keyword">local</span> mqtt_host = <span class="hljs-string">&quot;lbsmqtt.airm2m.com&quot;</span><br><span class="hljs-keyword">local</span> mqtt_port = <span class="hljs-number">1884</span><br><span class="hljs-keyword">local</span> mqtt_isssl = <span class="hljs-literal">false</span><br><span class="hljs-keyword">local</span> ca_file = <span class="hljs-literal">false</span><br><br><span class="hljs-comment">-- mqtt client configuration</span><br><span class="hljs-keyword">local</span> client_id = <span class="hljs-string">&quot;air780eg&quot;</span><br><span class="hljs-keyword">local</span> user_name = <span class="hljs-string">&quot;user&quot;</span><br><span class="hljs-keyword">local</span> password = <span class="hljs-string">&quot;password&quot;</span><br><br><span class="hljs-keyword">local</span> mqttc = <span class="hljs-literal">nil</span><br><span class="hljs-keyword">local</span> publish_topic = <span class="hljs-string">&quot;/air780eg/publish/123&quot;</span><br><span class="hljs-keyword">local</span> subscribe_topic = <span class="hljs-string">&quot;/air780eg/subscribe/123&quot;</span><br><br><span class="hljs-keyword">local</span> IsFirstConnect = <span class="hljs-literal">true</span><br><br><span class="hljs-comment">-- Task list</span><br><br><span class="hljs-comment">-- Air780E的AT固件默认会为开机键防抖, 导致部分用户刷机很麻烦</span><br><span class="hljs-keyword">if</span> rtos.bsp() == <span class="hljs-string">&quot;EC618&quot;</span> <span class="hljs-keyword">and</span> pm <span class="hljs-keyword">and</span> pm.PWK_MODE <span class="hljs-keyword">then</span><br>    pm.power(pm.PWK_MODE, <span class="hljs-literal">false</span>)<br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">-- network connect</span><br>sys.taskInit(<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">()</span></span><br>    <span class="hljs-keyword">local</span> device_IMEI = mobile.imei()   <span class="hljs-comment">-- string </span><br>    sys.waitUntil(<span class="hljs-string">&quot;IP_READY&quot;</span>)<br>    sys.publish(<span class="hljs-string">&quot;net_ready&quot;</span>, device_IMEI)<br><span class="hljs-keyword">end</span>)<br><br><span class="hljs-comment">-- mqtt connect</span><br>sys.taskInit(<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">()</span></span><br>    <span class="hljs-keyword">local</span> ret, IMEI = sys.waitUntil(<span class="hljs-string">&quot;net_ready&quot;</span>)<br>    <span class="hljs-keyword">if</span> ret <span class="hljs-keyword">then</span><br>        <span class="hljs-comment">-- use IMEI to set unique topic</span><br>        client_id = IMEI<br>        publish_topic = client_id .. <span class="hljs-string">&quot;/publish&quot;</span><br>        subscribe_topic = client_id .. <span class="hljs-string">&quot;/subscribe&quot;</span><br>        <span class="hljs-keyword">if</span> IsFirstConnect <span class="hljs-keyword">then</span><br>            <span class="hljs-comment">-- uart transmit logger to MCU</span><br>            uart.<span class="hljs-built_in">write</span>(uart_id, <span class="hljs-string">&quot;IMEI: &quot;</span> .. IMEI .. <span class="hljs-string">&quot;\r\n&quot;</span>)<br>            uart.<span class="hljs-built_in">write</span>(uart_id, <span class="hljs-string">&quot;publish_topic:&quot;</span> .. publish_topic .. <span class="hljs-string">&quot;\r\n&quot;</span>)<br>            uart.<span class="hljs-built_in">write</span>(uart_id, <span class="hljs-string">&quot;subscribe_topic:&quot;</span> .. subscribe_topic .. <span class="hljs-string">&quot;\r\n&quot;</span>)<br>            IsFirstConnect = <span class="hljs-literal">false</span><br>        <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">end</span><br><br>    <span class="hljs-comment">-- create mqtt client</span><br>    mqttc = mqtt.<span class="hljs-built_in">create</span>(mqtt_host, mqtt_port, mqtt_isssl, ca_file)<br>    mqttc:auth(client_id, user_name, password)  <span class="hljs-comment">-- set mqtt user-name and password(should be equal to the server setting)</span><br>    mqttc:autoreconn(<span class="hljs-literal">true</span>, <span class="hljs-number">3000</span>)                <span class="hljs-comment">-- set auto-reconnect</span><br><br>    <span class="hljs-comment">-- define callback function</span><br>    mqttc:on(<span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">(mqtt_client, event, data, payload)</span></span><br>        <span class="hljs-keyword">if</span> event == <span class="hljs-string">&quot;conack&quot;</span> <span class="hljs-keyword">then</span><br>            uart.<span class="hljs-built_in">write</span>(uart_id, <span class="hljs-string">&quot;MQTT Connect\r\n&quot;</span>)<br>            sys.publish(<span class="hljs-string">&quot;mqtt_ready&quot;</span>)<br>        <span class="hljs-keyword">elseif</span> event == <span class="hljs-string">&quot;recv&quot;</span> <span class="hljs-keyword">then</span><br>            <span class="hljs-built_in">log</span>.info(<span class="hljs-string">&quot;mqtt&quot;</span>, <span class="hljs-string">&quot;收到消息&quot;</span>, data, payload)<br>        <span class="hljs-keyword">elseif</span> event == <span class="hljs-string">&quot;sent&quot;</span> <span class="hljs-keyword">then</span><br>            <span class="hljs-built_in">log</span>.info(<span class="hljs-string">&quot;mqtt&quot;</span>, <span class="hljs-string">&quot;发送成功&quot;</span>, data)<br>        <span class="hljs-keyword">elseif</span> event == <span class="hljs-string">&quot;disconnect&quot;</span> <span class="hljs-keyword">then</span><br>            <span class="hljs-built_in">log</span>.warn(<span class="hljs-string">&quot;mqtt&quot;</span>, <span class="hljs-string">&quot;断开连接&quot;</span>)<br>        <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">end</span>)<br><br>    <span class="hljs-comment">-- start to conneect server</span><br>    mqttc:connect()<br><span class="hljs-keyword">end</span>)<br><br><span class="hljs-comment">-- UART 数据接收 + MQTT 上传</span><br>sys.taskInit(<span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>    sys.waitUntil(<span class="hljs-string">&quot;mqtt_ready&quot;</span>)<br><br>    <span class="hljs-built_in">log</span>.info(<span class="hljs-string">&quot;uart&quot;</span>, <span class="hljs-string">&quot;开始监听 UART 数据上传&quot;</span>)<br>    <span class="hljs-keyword">local</span> buffer = <span class="hljs-string">&quot;&quot;</span><br><br>    <span class="hljs-comment">-- uart接收触发中断 从id端口接收len长度的数据</span><br>    uart.on(uart_id, <span class="hljs-string">&quot;receive&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">(id, len)</span></span><br>        <span class="hljs-keyword">local</span> data = uart.<span class="hljs-built_in">read</span>(id, <span class="hljs-built_in">len</span>)<br>        buffer = buffer .. data<br><br>        <span class="hljs-comment">-- 示例：以换行符作为一条完整数据的结束</span><br>        <span class="hljs-keyword">while</span> buffer:<span class="hljs-built_in">find</span>(<span class="hljs-string">&quot;\r\n&quot;</span>) <span class="hljs-keyword">do</span><br>            <span class="hljs-keyword">local</span> packet, remain = buffer:<span class="hljs-built_in">match</span>(<span class="hljs-string">&quot;^(.-)\r\n(.*)$&quot;</span>)<br>            buffer = remain <span class="hljs-keyword">or</span> <span class="hljs-string">&quot;&quot;</span><br><br>            <span class="hljs-comment">-- 打印接收到的串口数据</span><br>            <span class="hljs-built_in">log</span>.info(<span class="hljs-string">&quot;uart&quot;</span>, <span class="hljs-string">&quot;收到数据&quot;</span>, packet)<br>            uart.<span class="hljs-built_in">write</span>(uart_id, <span class="hljs-string">&quot;Receive Finish!\r\n&quot;</span>)<br><br>            <span class="hljs-comment">-- 发布到 MQTT（QoS=0）</span><br>            <span class="hljs-keyword">if</span> mqttc <span class="hljs-keyword">then</span><br>                mqttc:publish(publish_topic, packet, <span class="hljs-number">0</span>)<br>            <span class="hljs-keyword">end</span><br>        <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">end</span>)<br><span class="hljs-keyword">end</span>)<br><br><span class="hljs-comment">--[[</span><br><span class="hljs-comment">    说明：</span><br><span class="hljs-comment">    1. 该代码示例展示了如何使用 UART 接收数据并通过 MQTT 上传。</span><br><span class="hljs-comment">    2. 使用了 sysplus 库来处理系统任务和事件。</span><br><span class="hljs-comment">    3. 使用了 mqtt 库来处理 MQTT 客户端的连接和消息发送。</span><br><span class="hljs-comment">    4. 使用了 log 库来记录日志信息。</span><br><span class="hljs-comment">]]</span><br>sys.run()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Communication</category>
      
      <category>LuatOS learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MQTT</tag>
      
      <tag>Lua</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>聚类分类—算法以及python实现</title>
    <link href="/2025/05/23/study/K_Means/"/>
    <url>/2025/05/23/study/K_Means/</url>
    
    <content type="html"><![CDATA[<h1 id="🧠-使用-Python-实现高效凝聚层次聚类（Agglomerative-Clustering）"><a href="#🧠-使用-Python-实现高效凝聚层次聚类（Agglomerative-Clustering）" class="headerlink" title="🧠 使用 Python 实现高效凝聚层次聚类（Agglomerative Clustering）"></a>🧠 使用 Python 实现高效凝聚层次聚类（Agglomerative Clustering）</h1><h2 id="在本篇博客中，我们将一起探索如何使用-Python-实现一个高效的-凝聚层次聚类（Agglomerative-Hierarchical-Clustering）算法，并支持三种不同的簇间距离度量方式：single-linkage-complete-linkage-和-average-linkage。我们还将通过可视化展示不同方法的效果，并分析其优劣。"><a href="#在本篇博客中，我们将一起探索如何使用-Python-实现一个高效的-凝聚层次聚类（Agglomerative-Hierarchical-Clustering）算法，并支持三种不同的簇间距离度量方式：single-linkage-complete-linkage-和-average-linkage。我们还将通过可视化展示不同方法的效果，并分析其优劣。" class="headerlink" title="在本篇博客中，我们将一起探索如何使用 Python 实现一个高效的 凝聚层次聚类（Agglomerative Hierarchical Clustering）算法，并支持三种不同的簇间距离度量方式：single linkage, complete linkage 和 average linkage。我们还将通过可视化展示不同方法的效果，并分析其优劣。   "></a>在本篇博客中，我们将一起探索如何使用 Python 实现一个高效的 <strong>凝聚层次聚类（Agglomerative Hierarchical Clustering）算法</strong>，并支持三种不同的簇间距离度量方式：<code>single linkage</code>, <code>complete linkage</code> 和 <code>average linkage</code>。我们还将通过可视化展示不同方法的效果，并分析其优劣。   </h2><h2 id="📚-一、什么是凝聚层次聚类？"><a href="#📚-一、什么是凝聚层次聚类？" class="headerlink" title="📚 一、什么是凝聚层次聚类？"></a>📚 一、什么是凝聚层次聚类？</h2><p>凝聚层次聚类是一种 <strong>自底向上的无监督聚类算法</strong>，它的核心思想是：   </p><blockquote><p>每个数据点初始时都是一个独立的簇，然后逐步合并最相似的两个簇，直到达到预设的簇数。   </p></blockquote><h2 id="与-K-Means-不同，它不需要提前指定簇的数量即可构建整个聚类树（dendrogram），因此非常适合探索性数据分析。"><a href="#与-K-Means-不同，它不需要提前指定簇的数量即可构建整个聚类树（dendrogram），因此非常适合探索性数据分析。" class="headerlink" title="与 K-Means 不同，它不需要提前指定簇的数量即可构建整个聚类树（dendrogram），因此非常适合探索性数据分析。   "></a>与 K-Means 不同，它不需要提前指定簇的数量即可构建整个聚类树（dendrogram），因此非常适合探索性数据分析。   </h2><h2 id="⚙️-二、代码概述"><a href="#⚙️-二、代码概述" class="headerlink" title="⚙️ 二、代码概述"></a>⚙️ 二、代码概述</h2><h3 id="🔍-功能亮点："><a href="#🔍-功能亮点：" class="headerlink" title="🔍 功能亮点："></a>🔍 功能亮点：</h3><ul><li>支持三种 <strong>linkage 方法</strong>：   <ul><li><code>&#39;single&#39;</code>: 最短距离法（最近邻）   </li><li><code>&#39;complete&#39;</code>: 最长距离法（最远邻）   </li><li><code>&#39;average&#39;</code>: 平均距离法</li></ul></li><li>使用 <strong>最小堆（heapq）</strong> 加速查找最近簇对   </li><li>对 Iris 数据集进行特征选择后聚类   </li><li>绘制原始标签与不同 linkage 聚类结果对比图</li></ul><hr><h2 id="📦-三、依赖库介绍"><a href="#📦-三、依赖库介绍" class="headerlink" title="📦 三、依赖库介绍"></a>📦 三、依赖库介绍</h2><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> heapq<br><span class="hljs-title">from</span> scipy.spatial.distance <span class="hljs-keyword">import</span> squareform, pdist<br><span class="hljs-title">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br><br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">库</th><th align="left">用途</th></tr></thead><tbody><tr><td align="left"><code>numpy</code></td><td align="left">高效数组操作</td></tr><tr><td align="left"><code>pandas</code></td><td align="left">数据读取与处理</td></tr><tr><td align="left"><code>matplotlib</code></td><td align="left">可视化绘图</td></tr><tr><td align="left"><code>heapq</code></td><td align="left">最小堆实现优先队列</td></tr><tr><td align="left"><code>scipy.spatial.distance</code></td><td align="left">计算成对距离</td></tr></tbody></table><hr><h2 id="📐-四、核心函数详解"><a href="#📐-四、核心函数详解" class="headerlink" title="📐 四、核心函数详解"></a>📐 四、核心函数详解</h2><h3 id="1-簇间距离计算函数"><a href="#1-簇间距离计算函数" class="headerlink" title="1. 簇间距离计算函数"></a>1. 簇间距离计算函数</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs maxima">def cluster_distance(c1, c2, dist_matrix, <span class="hljs-built_in">method</span>=&#x27;single&#x27;):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">method</span> == &#x27;single&#x27;:<br>        <span class="hljs-built_in">return</span> <span class="hljs-built_in">np</span>.<span class="hljs-built_in">min</span>(dist_matrix[<span class="hljs-built_in">np</span>.ix_(c1, c2)])<br>    elif <span class="hljs-built_in">method</span> == &#x27;complete&#x27;:<br>        <span class="hljs-built_in">return</span> <span class="hljs-built_in">np</span>.<span class="hljs-built_in">max</span>(dist_matrix[<span class="hljs-built_in">np</span>.ix_(c1, c2)])<br>    elif <span class="hljs-built_in">method</span> == &#x27;average&#x27;:<br>        <span class="hljs-built_in">return</span> <span class="hljs-built_in">np</span>.<span class="hljs-built_in">mean</span>(dist_matrix[<span class="hljs-built_in">np</span>.ix_(c1, c2)])<br>    <span class="hljs-keyword">else</span>:<br>        raise ValueError(<span class="hljs-string">&quot;Unknown method&quot;</span>)<br><br></code></pre></td></tr></table></figure><ul><li><strong>功能</strong>：根据指定的 <code>linkage</code> 方法计算两个簇之间的距离。   </li><li><strong>使用场景</strong>：   <ul><li><code>&#39;single&#39;</code>: 用于识别链状分布的数据。   </li><li><code>&#39;complete&#39;</code>: 更关注簇内紧密性。   </li><li><code>&#39;average&#39;</code>: 两者折中，适合大多数情况 。</li></ul></li></ul><hr><h3 id="2-初始化距离矩阵"><a href="#2-初始化距离矩阵" class="headerlink" title="2. 初始化距离矩阵"></a>2. 初始化距离矩阵</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">dist_matrix = <span class="hljs-built_in">squareform</span>(<span class="hljs-built_in">pdist</span>(features<span class="hljs-selector-attr">[:, feature_indices]</span>))<br><br></code></pre></td></tr></table></figure><ul><li><code>pdist</code>：计算所有样本两两之间的欧氏距离。   </li><li><code>squareform</code>：将压缩的距离向量转换为 N×N 的距离矩阵 。</li></ul><hr><h3 id="3-初始化每个样本为独立簇"><a href="#3-初始化每个样本为独立簇" class="headerlink" title="3. 初始化每个样本为独立簇"></a>3. 初始化每个样本为独立簇</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">init_clusters = <span class="hljs-selector-attr">[[i]</span> <span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numberOfsamples)]<br><br></code></pre></td></tr></table></figure><ul><li>初始时每个样本是一个簇，用索引表示。</li></ul><hr><h3 id="4-构建最小堆维护簇对距离"><a href="#4-构建最小堆维护簇对距离" class="headerlink" title="4. 构建最小堆维护簇对距离"></a>4. 构建最小堆维护簇对距离</h3><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs oxygene"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(clusters)):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(i+<span class="hljs-number">1</span>, len(clusters)):<br>        dist = cluster_distance(clusters[i], clusters[j], dist_matrix, <span class="hljs-keyword">method</span>)<br>        <span class="hljs-title function_">heapq</span>.<span class="hljs-title function_">heappush</span><span class="hljs-params">(heap, (dist, i, j)</span>)<br><br></code></pre></td></tr></table></figure><ul><li>使用 <code>heapq</code> 构建最小堆，每次取出当前最近的簇对进行合并。   </li><li>时间复杂度从 O(N³) 降低至 O(N² log N) 。</li></ul><hr><h3 id="5-合并簇并更新堆"><a href="#5-合并簇并更新堆" class="headerlink" title="5. 合并簇并更新堆"></a>5. 合并簇并更新堆</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stylus">while <span class="hljs-built_in">sum</span>(valid) &gt; numberOfcluster:<br>    while True:<br>        dist, <span class="hljs-selector-tag">i</span>, j = heapq<span class="hljs-selector-class">.heappop</span>(heap)<br>        <span class="hljs-keyword">if</span> valid<span class="hljs-selector-attr">[i]</span> and valid<span class="hljs-selector-attr">[j]</span>:<br>            break<br>    clusters<span class="hljs-selector-attr">[i]</span><span class="hljs-selector-class">.extend</span>(clusters<span class="hljs-selector-attr">[j]</span>)<br>    valid<span class="hljs-selector-attr">[j]</span> = False<br>    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(clusters)):<br>        <span class="hljs-keyword">if</span> k != <span class="hljs-selector-tag">i</span> and valid<span class="hljs-selector-attr">[k]</span>:<br>            dist = <span class="hljs-built_in">cluster_distance</span>(clusters<span class="hljs-selector-attr">[i]</span>, clusters<span class="hljs-selector-attr">[k]</span>, dist_matrix, method)<br>            heapq<span class="hljs-selector-class">.heappush</span>(heap, (dist, <span class="hljs-selector-tag">i</span>, k))<br><br></code></pre></td></tr></table></figure><ul><li><strong>有效簇标记</strong>：使用 <code>valid</code> 数组记录哪些簇是有效的。   </li><li><strong>动态更新距离</strong>：合并后重新计算新簇与其他簇的距离并插入堆中。</li></ul><hr><h2 id="📊-六、可视化展示"><a href="#📊-六、可视化展示" class="headerlink" title="📊 六、可视化展示"></a>📊 六、可视化展示</h2><p>我们绘制了四种图像：   </p><ol><li>原始数据按真实标签显示   </li><li><code>&#39;single&#39;</code> linkage 聚类结果   </li><li><code>&#39;complete&#39;</code> linkage 聚类结果   </li><li><code>&#39;average&#39;</code> linkage 聚类结果</li></ol><p>每种方法都使用不同颜色和形状的标记来区分簇。   </p><h3 id="示例代码片段："><a href="#示例代码片段：" class="headerlink" title="示例代码片段："></a>示例代码片段：</h3><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs prolog">plt.scatter(<br>    features[clu, feature_indices[<span class="hljs-number">0</span>]],<br>    features[clu, feature_indices[<span class="hljs-number">1</span>]],<br>    color=[color],<br>    marker=marker,<br>    label=f<span class="hljs-string">&#x27;Cluster &#123;idx+1&#125;&#x27;</span><br>)<br><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250523191326805.png" alt="Agglomerative Clustering"></p><hr><h2 id="🧩-七、三种-Linkage-方法对比"><a href="#🧩-七、三种-Linkage-方法对比" class="headerlink" title="🧩 七、三种 Linkage 方法对比"></a>🧩 七、三种 Linkage 方法对比</h2><table><thead><tr><th align="left">Linkage 方法</th><th align="left">特点</th><th align="left">适用场景</th></tr></thead><tbody><tr><td align="left"><code>&#39;single&#39;</code></td><td align="left">容易形成“链式”簇</td><td align="left">适用于流形型数据</td></tr><tr><td align="left"><code>&#39;complete&#39;</code></td><td align="left">强调簇内紧凑性</td><td align="left">适用于球形分布数据</td></tr><tr><td align="left"><code>&#39;average&#39;</code></td><td align="left">折中方案，平衡表现</td><td align="left">通用性强</td></tr></tbody></table><hr><h2 id="📚-参考资料"><a href="#📚-参考资料" class="headerlink" title="📚 参考资料"></a>📚 参考资料</h2><ul><li>[1] Scipy pdist &amp; squareform 文档   </li><li>[2] NumPy 与 Pandas 简介   </li><li>[3] 密度峰值聚类算法综述   </li><li>[4] 自适应密度峰值聚类算法   </li><li>[5] 层次聚类与 DPC 算法对比</li></ul><hr><h1 id="🧠-使用-Python-实现向量化-K-Means-聚类算法"><a href="#🧠-使用-Python-实现向量化-K-Means-聚类算法" class="headerlink" title="🧠 使用 Python 实现向量化 K-Means 聚类算法"></a>🧠 使用 Python 实现向量化 K-Means 聚类算法</h1><h2 id="K-Means-是一种经典的无监督聚类算法，广泛应用于数据挖掘、图像压缩、客户分群等领域。本文将带你一步步理解并实现一个高效的向量化-K-Means-算法，并通过-sklearn-加载-Iris-数据集进行实战演示。"><a href="#K-Means-是一种经典的无监督聚类算法，广泛应用于数据挖掘、图像压缩、客户分群等领域。本文将带你一步步理解并实现一个高效的向量化-K-Means-算法，并通过-sklearn-加载-Iris-数据集进行实战演示。" class="headerlink" title="K-Means 是一种经典的无监督聚类算法，广泛应用于数据挖掘、图像压缩、客户分群等领域。本文将带你一步步理解并实现一个高效的向量化 K-Means 算法，并通过 sklearn 加载 Iris 数据集进行实战演示。   "></a>K-Means 是一种经典的无监督聚类算法，广泛应用于数据挖掘、图像压缩、客户分群等领域。本文将带你一步步理解并实现一个<strong>高效的向量化 K-Means 算法</strong>，并通过 <code>sklearn</code> 加载 Iris 数据集进行实战演示。   </h2><h2 id="📦-一、环境依赖与数据准备"><a href="#📦-一、环境依赖与数据准备" class="headerlink" title="📦 一、环境依赖与数据准备"></a>📦 一、环境依赖与数据准备</h2><p>我们使用如下库：   </p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-title">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans<br><span class="hljs-title">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><br></code></pre></td></tr></table></figure><h3 id="✅-数据加载"><a href="#✅-数据加载" class="headerlink" title="✅ 数据加载"></a>✅ 数据加载</h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">iris</span> = datasets.load_iris()<br><span class="hljs-attr">X</span> = iris.data[:, :<span class="hljs-number">4</span>]<br><span class="hljs-attr">numberOfcluster</span> = len(iris.target_names)<br><br></code></pre></td></tr></table></figure><ul><li><code>X</code>: 特征矩阵（150 × 4）   </li><li><code>numberOfcluster</code>: 类别数为 3</li></ul><hr><h2 id="⚙️-二、使用-sklearn-的-KMeans-进行聚类"><a href="#⚙️-二、使用-sklearn-的-KMeans-进行聚类" class="headerlink" title="⚙️ 二、使用 sklearn 的 KMeans 进行聚类"></a>⚙️ 二、使用 sklearn 的 KMeans 进行聚类</h2><p>我们先调用 <code>sklearn.cluster.KMeans</code> 快速完成聚类任务：   </p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">estimator</span> <span class="hljs-operator">=</span> KMeans(n_clusters<span class="hljs-operator">=</span>numberOfcluster)<br>estimator.fit(X)<br>label_pred <span class="hljs-operator">=</span> estimator.labels_<br><br></code></pre></td></tr></table></figure><p>然后绘制原始数据和聚类后的结果图：   </p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs stylus">plt<span class="hljs-selector-class">.figure</span>(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">8</span>))<br>plt<span class="hljs-selector-class">.subplot</span>(<span class="hljs-number">121</span>)<br>plt<span class="hljs-selector-class">.scatter</span>(X<span class="hljs-selector-attr">[:, 1]</span>, X<span class="hljs-selector-attr">[:, 2]</span>, c=<span class="hljs-string">&quot;red&quot;</span>, <span class="hljs-attribute">marker</span>=<span class="hljs-string">&#x27;o&#x27;</span>, label=<span class="hljs-string">&#x27;data&#x27;</span>) <br>plt<span class="hljs-selector-class">.xlabel</span>(<span class="hljs-string">&#x27;sepal length&#x27;</span>) <br>plt<span class="hljs-selector-class">.ylabel</span>(<span class="hljs-string">&#x27;sepal width&#x27;</span>) <br>plt<span class="hljs-selector-class">.legend</span>(loc=<span class="hljs-number">2</span>) <br><br>plt<span class="hljs-selector-class">.subplot</span>(<span class="hljs-number">122</span>)<br>x0 = X<span class="hljs-selector-attr">[label_pred == 0]</span> <br>x1 = X<span class="hljs-selector-attr">[label_pred == 1]</span> <br>x2 = X<span class="hljs-selector-attr">[label_pred == 2]</span> <br>plt<span class="hljs-selector-class">.scatter</span>(x0<span class="hljs-selector-attr">[:, 1]</span>, x0<span class="hljs-selector-attr">[:, 2]</span>, c=<span class="hljs-string">&quot;red&quot;</span>, <span class="hljs-attribute">marker</span>=<span class="hljs-string">&#x27;o&#x27;</span>, label=<span class="hljs-string">&#x27;label0&#x27;</span>) <br>plt<span class="hljs-selector-class">.scatter</span>(x1<span class="hljs-selector-attr">[:, 1]</span>, x1<span class="hljs-selector-attr">[:, 2]</span>, c=<span class="hljs-string">&quot;green&quot;</span>, <span class="hljs-attribute">marker</span>=<span class="hljs-string">&#x27;*&#x27;</span>, label=<span class="hljs-string">&#x27;label1&#x27;</span>) <br>plt<span class="hljs-selector-class">.scatter</span>(x2<span class="hljs-selector-attr">[:, 1]</span>, x2<span class="hljs-selector-attr">[:, 2]</span>, c=<span class="hljs-string">&quot;blue&quot;</span>, <span class="hljs-attribute">marker</span>=<span class="hljs-string">&#x27;+&#x27;</span>, label=<span class="hljs-string">&#x27;label2&#x27;</span>) <br>plt<span class="hljs-selector-class">.xlabel</span>(<span class="hljs-string">&#x27;sepal length&#x27;</span>) <br>plt<span class="hljs-selector-class">.ylabel</span>(<span class="hljs-string">&#x27;sepal width&#x27;</span>) <br>plt<span class="hljs-selector-class">.legend</span>(loc=<span class="hljs-number">2</span>) <br>plt<span class="hljs-selector-class">.show</span>()<br><br></code></pre></td></tr></table></figure><blockquote><p>✅ 使用 sklearn 可以快速完成聚类，但了解其内部实现更有助于深入理解算法原理 。   </p></blockquote><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250523191344622.png" alt="K-Means"></p><hr><h2 id="🧩-三、手动实现向量化-K-Means"><a href="#🧩-三、手动实现向量化-K-Means" class="headerlink" title="🧩 三、手动实现向量化 K-Means"></a>🧩 三、手动实现向量化 K-Means</h2><p>为了更深入理解 K-Means 的工作原理，我们实现了<strong>向量化版本的 K-Means 算法</strong>，避免了传统的嵌套循环，提高了计算效率。   </p><h3 id="1-向量化计算距离矩阵"><a href="#1-向量化计算距离矩阵" class="headerlink" title="1. 向量化计算距离矩阵"></a>1. 向量化计算距离矩阵</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs maxima">def compute_distances(dataSet, centroids):<br>    m = dataSet.shape[<span class="hljs-number">0</span>]<br>    k = centroids.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-built_in">diff</span> = dataSet[:, <span class="hljs-built_in">np</span>.newaxis, :] - centroids[<span class="hljs-built_in">np</span>.newaxis, :, :]<br>    distances = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">sum</span>(<span class="hljs-built_in">diff</span>**<span class="hljs-number">2</span>, axis=<span class="hljs-number">2</span>)<br>    <span class="hljs-built_in">return</span> distances<br><br></code></pre></td></tr></table></figure><ul><li>利用 NumPy 广播机制一次性计算所有点到质心的距离。   </li><li>避免双重 for 循环，提升性能 。</li></ul><hr><h3 id="2-分配样本到最近质心"><a href="#2-分配样本到最近质心" class="headerlink" title="2. 分配样本到最近质心"></a>2. 分配样本到最近质心</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-keyword">def</span> <span class="hljs-title function_">assign_clusters</span>(<span class="hljs-params">distances</span>):<br>    <span class="hljs-keyword">return</span> np.argmin(distances, axis=<span class="hljs-number">1</span>)<br><br></code></pre></td></tr></table></figure><ul><li>沿列方向取最小值索引，确定每个样本所属簇。</li></ul><hr><h3 id="3-随机初始化质心"><a href="#3-随机初始化质心" class="headerlink" title="3. 随机初始化质心"></a>3. 随机初始化质心</h3><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs fortran">def randomCenter(dataSet, k): <br>    m, n = dataSet.<span class="hljs-built_in">shape</span>  <br>    centroids = np.zeros((k, n))  <br>    for i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):  <br>        <span class="hljs-built_in">index</span> = <span class="hljs-built_in">int</span>(np.random.uniform(<span class="hljs-number">0</span>, m))   <br>        centroids[i, :] = dataSet[<span class="hljs-built_in">index</span>, :]  <br>    <span class="hljs-keyword">return</span> centroids<br><br></code></pre></td></tr></table></figure><ul><li>从数据集中随机选择 <code>k</code> 个样本作为初始质心 。</li></ul><hr><h3 id="4-更新质心"><a href="#4-更新质心" class="headerlink" title="4. 更新质心"></a>4. 更新质心</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs maxima">def update_centroids(dataSet, cluster_indices, k):<br>    centroids = <span class="hljs-built_in">np</span>.zeros((k, dataSet.shape[<span class="hljs-number">1</span>]))<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>        mask = (cluster_indices == j)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">np</span>.any(mask):<br>            centroids[j] = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">mean</span>(dataSet[mask], axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-built_in">return</span> centroids<br><br></code></pre></td></tr></table></figure><ul><li>对每个簇计算均值作为新质心。</li></ul><hr><h3 id="5-主函数：向量化-K-Means"><a href="#5-主函数：向量化-K-Means" class="headerlink" title="5. 主函数：向量化 K-Means"></a>5. 主函数：向量化 K-Means</h3><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs scss">def <span class="hljs-built_in">KMeans_vectorized</span>(dataSet, k, max_iter=<span class="hljs-number">100</span>):<br>    centroids = <span class="hljs-built_in">randomCenter</span>(dataSet, k)<br>    <br>    for iter_num in <span class="hljs-built_in">range</span>(max_iter):<br>        distances = <span class="hljs-built_in">compute_distances</span>(dataSet, centroids)<br>        cluster_indices = <span class="hljs-built_in">assign_clusters</span>(distances)<br>        new_centroids = <span class="hljs-built_in">update_centroids</span>(dataSet, cluster_indices, k)<br><br>        if np.<span class="hljs-built_in">allclose</span>(centroids, new_centroids):<br>            break<br>        centroids = new_centroids<br>    return centroids, cluster_indices, iter_num<br><br></code></pre></td></tr></table></figure><ul><li>收敛条件：新旧质心几乎相等时停止迭代。   </li><li>最终返回质心、簇标签和迭代次数。</li></ul><hr><h2 id="📊-四、可视化聚类结果"><a href="#📊-四、可视化聚类结果" class="headerlink" title="📊 四、可视化聚类结果"></a>📊 四、可视化聚类结果</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs stylus">plt<span class="hljs-selector-class">.figure</span>(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">8</span>))<br>colors_list = <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;blue&#x27;</span>]</span><br>markers_list = <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;o&#x27;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;^&#x27;</span>]</span><br><br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>    plt<span class="hljs-selector-class">.scatter</span>(<br>        dataSet<span class="hljs-selector-attr">[clusterAssment == i, 1]</span>, <br>        dataSet<span class="hljs-selector-attr">[clusterAssment == i, 3]</span>, <br>        c=colors_list<span class="hljs-selector-attr">[i]</span>, <br>        <span class="hljs-attribute">marker</span>=markers_list[i], <br>        label=f<span class="hljs-string">&#x27;Cluster &#123;i+1&#125;&#x27;</span><br>    )<br>    plt<span class="hljs-selector-class">.scatter</span>(<br>        centroids<span class="hljs-selector-attr">[i, 1]</span>, <br>        centroids<span class="hljs-selector-attr">[i, 3]</span>, <br>        c=colors_list<span class="hljs-selector-attr">[i]</span>, <br>        <span class="hljs-attribute">marker</span>=<span class="hljs-string">&#x27;x&#x27;</span>, <br>        s=<span class="hljs-number">100</span>, <br>        label=<span class="hljs-string">&#x27;Centroids&#x27;</span><br>    )<br><br>plt<span class="hljs-selector-class">.xlabel</span>(<span class="hljs-string">&#x27;Feature 0&#x27;</span>)<br>plt<span class="hljs-selector-class">.ylabel</span>(<span class="hljs-string">&#x27;Feature 1&#x27;</span>)<br>plt<span class="hljs-selector-class">.title</span>(f<span class="hljs-string">&#x27;KMeans Clustering Result in iter num: &#123;iter_num&#125;&#x27;</span>)<br>plt<span class="hljs-selector-class">.legend</span>()<br>plt<span class="hljs-selector-class">.show</span>()<br><br></code></pre></td></tr></table></figure><ul><li>不同颜色代表不同簇。   </li><li>不同标记区分簇内点与质心。</li></ul><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250523191351498.png" alt="K-Means"></p><hr><h2 id="📌-五、总结"><a href="#📌-五、总结" class="headerlink" title="📌 五、总结"></a>📌 五、总结</h2><table><thead><tr><th align="left">功能</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">向量化实现</td><td align="left">提升聚类速度，适用于大规模数据</td></tr><tr><td align="left">随机初始化</td><td align="left">简单易懂，但可能陷入局部最优</td></tr><tr><td align="left">收敛判断</td><td align="left">使用 <code>np.allclose()</code> 避免无限迭代</td></tr><tr><td align="left">可视化支持</td><td align="left">帮助直观理解聚类效果</td></tr></tbody></table><hr><h2 id="📚-六、参考资料"><a href="#📚-六、参考资料" class="headerlink" title="📚 六、参考资料"></a>📚 六、参考资料</h2><ul><li>[1] Scikit-learn 官方文档：KMeans 聚类介绍   </li><li>[2] KMeans 初始化方法详解：<code>k-means++</code> vs <code>random</code>   </li><li>[3] NumPy 和 Matplotlib 在机器学习中的应用   </li><li>[4] 向量化计算提高效率的方法</li></ul><hr><h1 id="🧠-使用-Python-实现自定义-DBSCAN-聚类算法"><a href="#🧠-使用-Python-实现自定义-DBSCAN-聚类算法" class="headerlink" title="🧠 使用 Python 实现自定义 DBSCAN 聚类算法"></a>🧠 使用 Python 实现自定义 DBSCAN 聚类算法</h1><h2 id="DBSCAN（Density-Based-Spatial-Clustering-of-Applications-with-Noise）是一种基于密度的聚类算法，能够发现任意形状的簇，并且能识别出噪声点。本篇博客将带你一步步实现一个高效的-自定义-DBSCAN-算法，并使用极坐标方式生成测试样本数据集进行验证。"><a href="#DBSCAN（Density-Based-Spatial-Clustering-of-Applications-with-Noise）是一种基于密度的聚类算法，能够发现任意形状的簇，并且能识别出噪声点。本篇博客将带你一步步实现一个高效的-自定义-DBSCAN-算法，并使用极坐标方式生成测试样本数据集进行验证。" class="headerlink" title="DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是一种基于密度的聚类算法，能够发现任意形状的簇，并且能识别出噪声点。本篇博客将带你一步步实现一个高效的 自定义 DBSCAN 算法，并使用极坐标方式生成测试样本数据集进行验证。   "></a>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是一种基于密度的聚类算法，能够发现任意形状的簇，并且能识别出噪声点。本篇博客将带你一步步实现一个高效的 <strong>自定义 DBSCAN 算法</strong>，并使用极坐标方式生成测试样本数据集进行验证。   </h2><h2 id="📦-一、环境依赖与数据准备-1"><a href="#📦-一、环境依赖与数据准备-1" class="headerlink" title="📦 一、环境依赖与数据准备"></a>📦 一、环境依赖与数据准备</h2><p>我们使用如下库：   </p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-title">from</span> scipy.spatial.distance <span class="hljs-keyword">import</span> cdist<br><br></code></pre></td></tr></table></figure><h3 id="✅-生成测试样本"><a href="#✅-生成测试样本" class="headerlink" title="✅ 生成测试样本"></a>✅ 生成测试样本</h3><p>我们通过极坐标生成两个不同半径范围内的样本点，模拟环形分布的数据：   </p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs scss">def <span class="hljs-built_in">generate_sample</span>():<br>    number_of_samples = <span class="hljs-number">1000</span><br>    # 内部小圆：<span class="hljs-number">20%</span> 数据<br>    theta = np.random.<span class="hljs-built_in">uniform</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>*np.pi, <span class="hljs-built_in">int</span>(<span class="hljs-number">0.2</span>*number_of_samples))<br>    r = np.<span class="hljs-built_in">sqrt</span>(np.random.<span class="hljs-built_in">uniform</span>(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>, <span class="hljs-built_in">int</span>(<span class="hljs-number">0.2</span>*number_of_samples)))<br>    x = r * np.<span class="hljs-built_in">cos</span>(theta)<br>    y = r * np.<span class="hljs-built_in">sin</span>(theta)<br>    X_1 = np.<span class="hljs-built_in">column_stack</span>((x, y))<br><br>    # 外部大圆：<span class="hljs-number">80%</span> 数据<br>    theta = np.random.<span class="hljs-built_in">uniform</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>*np.pi, number_of_samples)<br>    r = np.<span class="hljs-built_in">sqrt</span>(np.random.<span class="hljs-built_in">uniform</span>(<span class="hljs-number">25</span>, <span class="hljs-number">36</span>, number_of_samples))<br>    x = r * np.<span class="hljs-built_in">cos</span>(theta)<br>    y = r * np.<span class="hljs-built_in">sin</span>(theta)<br>    X_2 = np.<span class="hljs-built_in">column_stack</span>((x, y))<br><br>    # 可视化<br>    plt.<span class="hljs-built_in">figure</span>(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">8</span>))<br>    plt.<span class="hljs-built_in">scatter</span>(X_1[:, <span class="hljs-number">0</span>], X_1[:, <span class="hljs-number">1</span>], color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>    plt.<span class="hljs-built_in">scatter</span>(X_2[:, <span class="hljs-number">0</span>], X_2[:, <span class="hljs-number">1</span>], color=<span class="hljs-string">&#x27;b&#x27;</span>)<br>    plt.<span class="hljs-built_in">title</span>(<span class="hljs-string">&#x27;Generated Sample Data (Polar Coordinates)&#x27;</span>)<br>    plt.<span class="hljs-built_in">xlabel</span>(<span class="hljs-string">&#x27;X&#x27;</span>)<br>    plt.<span class="hljs-built_in">ylabel</span>(<span class="hljs-string">&#x27;Y&#x27;</span>)<br>    plt.<span class="hljs-built_in">show</span>()<br><br>    return np.<span class="hljs-built_in">vstack</span>((X_1, X_2))<br><br></code></pre></td></tr></table></figure><blockquote><p>✅ 该方法参考了随机采样策略，适用于测试和可视化分析。   </p></blockquote><hr><h2 id="⚙️-二、DBSCAN-类设计与实现"><a href="#⚙️-二、DBSCAN-类设计与实现" class="headerlink" title="⚙️ 二、DBSCAN 类设计与实现"></a>⚙️ 二、DBSCAN 类设计与实现</h2><h3 id="1-初始化参数"><a href="#1-初始化参数" class="headerlink" title="1. 初始化参数"></a>1. 初始化参数</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-keyword">class</span> <span class="hljs-variable constant_">DBSCAN</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, eps=<span class="hljs-number">3</span></span>):<br>        <span class="hljs-variable language_">self</span>.eps = eps<br>        <span class="hljs-variable language_">self</span>.value_threshold = <span class="hljs-number">750</span><br>        <span class="hljs-variable language_">self</span>.labels = <span class="hljs-title class_">None</span><br>        <span class="hljs-variable language_">self</span>.cluster_centers = []<br><br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><code>eps</code></td><td align="left">邻域半径，用于判断邻近点</td></tr><tr><td align="left"><code>value\_threshold</code></td><td align="left">密度峰值选择阈值</td></tr></tbody></table><hr><h3 id="2-计算距离与密度"><a href="#2-计算距离与密度" class="headerlink" title="2. 计算距离与密度"></a>2. 计算距离与密度</h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">distances</span> = cdist(X, X, metric=<span class="hljs-string">&#x27;euclidean&#x27;</span>)<br><span class="hljs-attr">density</span> = np.sum(distances &lt; self.eps, axis=<span class="hljs-number">1</span>)<br><br></code></pre></td></tr></table></figure><ul><li>使用 <code>cdist</code> 一次性计算所有点之间的欧氏距离   </li><li>每个点的局部密度是其邻域内点的数量</li></ul><hr><h3 id="3-计算最小距离"><a href="#3-计算最小距离" class="headerlink" title="3. 计算最小距离"></a>3. 计算最小距离</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus">min_distances = <span class="hljs-selector-attr">[]</span><br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_samples):<br>    greater_density_indices = np<span class="hljs-selector-class">.where</span>(density &gt; density<span class="hljs-selector-attr">[i]</span>)<span class="hljs-selector-attr">[0]</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(greater_density_indices) &gt; <span class="hljs-number">0</span>:<br>        min_distance = np<span class="hljs-selector-class">.min</span>(distances<span class="hljs-selector-attr">[i, greater_density_indices]</span>)<br>        min_distances<span class="hljs-selector-class">.append</span>(min_distance)<br>    <span class="hljs-keyword">else</span>:<br>        min_distances<span class="hljs-selector-class">.append</span>(np<span class="hljs-selector-class">.max</span>(distances<span class="hljs-selector-attr">[i]</span>))<br><br></code></pre></td></tr></table></figure><ul><li>对每个点，找到比它密度高的点，并计算到这些点的最小距离</li></ul><hr><h3 id="4-选取聚类中心"><a href="#4-选取聚类中心" class="headerlink" title="4. 选取聚类中心"></a>4. 选取聚类中心</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs ruby">density_times_min_distance = density * np.array(min_distances)<br>idx = np.argsort(density_times_min_distance)[<span class="hljs-symbol">:</span><span class="hljs-symbol">:-</span><span class="hljs-number">1</span>]<br><br>mask = density_times_min_distance[idx] &gt; <span class="hljs-variable language_">self</span>.value_threshold<br>selected_indices = idx[mask]<br><span class="hljs-variable language_">self</span>.labels[selected_indices] = selected_indices<br><span class="hljs-variable language_">self</span>.cluster_centers.<span class="hljs-keyword">extend</span>(selected_indices.tolist())<br><br></code></pre></td></tr></table></figure><ul><li>通过 <code>density × min\_distance</code> 排序，结合阈值筛选聚类中心</li></ul><hr><h3 id="5-广度优先扩展聚类"><a href="#5-广度优先扩展聚类" class="headerlink" title="5. 广度优先扩展聚类"></a>5. 广度优先扩展聚类</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs stylus">Have_labeled = <span class="hljs-selector-attr">[]</span><br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">label</span> <span class="hljs-keyword">in</span> cluster_centers<span class="hljs-selector-class">.keys</span>():<br>    queue_center = cluster_centers<span class="hljs-selector-attr">[label]</span><span class="hljs-selector-class">.copy</span>()<br>    Have_labeled<span class="hljs-selector-class">.extend</span>(queue_center)<br><br>    while queue_center:<br>        current = queue_center<span class="hljs-selector-class">.pop</span>(<span class="hljs-number">0</span>)<br>        neighbors = np<span class="hljs-selector-class">.where</span>(distances<span class="hljs-selector-attr">[current]</span> &lt; self.eps)<span class="hljs-selector-attr">[0]</span><br>        <span class="hljs-keyword">for</span> neighbor <span class="hljs-keyword">in</span> neighbors:<br>            <span class="hljs-keyword">if</span> neighbor not <span class="hljs-keyword">in</span> Have_labeled:<br>                self<span class="hljs-selector-class">.labels</span><span class="hljs-selector-attr">[neighbor]</span> = self<span class="hljs-selector-class">.labels</span><span class="hljs-selector-attr">[current]</span><br>                Have_labeled<span class="hljs-selector-class">.append</span>(neighbor)<br>                queue_center<span class="hljs-selector-class">.append</span>(neighbor)<br><br></code></pre></td></tr></table></figure><ul><li>使用 BFS 扩展簇，将邻域点标记为相同标签</li></ul><hr><h3 id="6-统一标签编号"><a href="#6-统一标签编号" class="headerlink" title="6. 统一标签编号"></a>6. 统一标签编号</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs maxima">final_labels = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">unique</span>(self.<span class="hljs-built_in">labels</span>)<br>label_map = &#123;<span class="hljs-built_in">label</span>: i <span class="hljs-keyword">for</span> i, <span class="hljs-built_in">label</span> <span class="hljs-keyword">in</span> enumerate(final_labels)&#125;<br><span class="hljs-keyword">if</span> -<span class="hljs-number">1</span> <span class="hljs-keyword">in</span> label_map:<br>    label_map[-<span class="hljs-number">1</span>] = -<span class="hljs-number">1</span><br>self.<span class="hljs-built_in">labels</span> = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>([label_map[<span class="hljs-built_in">label</span>] <span class="hljs-keyword">for</span> <span class="hljs-built_in">label</span> <span class="hljs-keyword">in</span> self.<span class="hljs-built_in">labels</span>])<br><br></code></pre></td></tr></table></figure><ul><li>将原始索引标签映射为连续整数，便于后续处理</li></ul><hr><h2 id="📊-三、可视化聚类结果"><a href="#📊-三、可视化聚类结果" class="headerlink" title="📊 三、可视化聚类结果"></a>📊 三、可视化聚类结果</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs stylus">unique_labels = np<span class="hljs-selector-class">.unique</span>(labels)<br>colors = plt<span class="hljs-selector-class">.get_cmap</span>(<span class="hljs-string">&#x27;tab10&#x27;</span>, <span class="hljs-built_in">len</span>(unique_labels))<br><br>plt<span class="hljs-selector-class">.figure</span>(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">8</span>))<br><span class="hljs-keyword">for</span> idx, <span class="hljs-selector-tag">label</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(unique_labels):<br>    <span class="hljs-selector-tag">mask</span> = labels == <span class="hljs-selector-tag">label</span><br>    plt<span class="hljs-selector-class">.scatter</span>(X<span class="hljs-selector-attr">[mask, 0]</span>, X<span class="hljs-selector-attr">[mask, 1]</span>, s=<span class="hljs-number">10</span>, <span class="hljs-attribute">color</span>=<span class="hljs-built_in">colors</span>(idx),<br>                label=f<span class="hljs-string">&#x27;Cluster &#123;label&#125;&#x27;</span> <span class="hljs-keyword">if</span> <span class="hljs-selector-tag">label</span> != -<span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;Noise&#x27;</span>)<br><br>plt<span class="hljs-selector-class">.title</span>(<span class="hljs-string">&#x27;DBSCAN Clustering Result&#x27;</span>)<br>plt<span class="hljs-selector-class">.xlabel</span>(<span class="hljs-string">&#x27;X1&#x27;</span>)<br>plt<span class="hljs-selector-class">.ylabel</span>(<span class="hljs-string">&#x27;X2&#x27;</span>)<br>plt<span class="hljs-selector-class">.legend</span>()<br>plt<span class="hljs-selector-class">.show</span>()<br><br></code></pre></td></tr></table></figure><ul><li>不同颜色代表不同簇   </li><li><code>-1</code> 表示噪声点</li></ul><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250523191402097.png" alt="Raw division"><br><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250523191407495.png" alt="DBSCAN"></p><hr><h2 id="📌-四、总结与优化建议"><a href="#📌-四、总结与优化建议" class="headerlink" title="📌 四、总结与优化建议"></a>📌 四、总结与优化建议</h2><table><thead><tr><th align="left">功能</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">极坐标生成样本</td><td align="left">更适合环形或球形数据集</td></tr><tr><td align="left">向量化操作</td><td align="left">提升性能，避免双重循环</td></tr><tr><td align="left">支持噪声识别</td><td align="left">是 DBSCAN 的核心优势之一</td></tr><tr><td align="left">可视化清晰</td><td align="left">帮助理解聚类效果</td></tr></tbody></table><h3 id="✅-优化建议："><a href="#✅-优化建议：" class="headerlink" title="✅ 优化建议："></a>✅ 优化建议：</h3><ul><li>使用 <code>K-D Tree</code> 或 <code>Ball Tree</code> 加速邻域查询   </li><li>替换固定阈值为动态选择策略   </li><li>支持自动确定 <code>eps</code> 和 <code>min\_samples</code>   </li><li>使用 <code>numba</code> 或 <code>Cython</code> 加速核心循环部分</li></ul><hr><h2 id="📚-五、参考资料"><a href="#📚-五、参考资料" class="headerlink" title="📚 五、参考资料"></a>📚 五、参考资料</h2><ul><li>[1] <code>scipy.spatial.distance.cdist</code> 用法   </li><li>[2] 测试样本生成方法   </li><li>[3] 聚类算法在机器学习中的应用   </li><li>[4] DBSCAN 算法原理详解</li></ul><hr><p>🎉 感**谢阅读，希望这篇博客对你理解和实现 DBSCAN 聚类有所帮助！   </p>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3D建模下的参数估计</title>
    <link href="/2025/05/20/research/3D_Positioning_estimation/"/>
    <url>/2025/05/20/research/3D_Positioning_estimation/</url>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在信号处理领域，参数估计是实现目标识别与定位的核心技术之一。经典论文《ESPRIT: Estimation of Signal Parameters via Rotational Invariance Techniques》提出了基于旋转不变性的超分辨率参数估计算法，而《Multiple Emitter Location and Signal Parameter Estimation》则进一步拓展了多信号源定位的理论框架。本文结合原始思想与最新改进算法，探讨3D建模下的参数估计方法。</p><hr><h2 id="ESPRIT算法核心思想"><a href="#ESPRIT算法核心思想" class="headerlink" title="ESPRIT算法核心思想"></a>ESPRIT算法核心思想</h2><h3 id="旋转不变性原理"><a href="#旋转不变性原理" class="headerlink" title="旋转不变性原理"></a>旋转不变性原理</h3><p>ESPRIT算法的核心在于利用信号子空间的旋转不变性[[4]]。通过构建两个存在位移关系的传感器阵列，其接收信号满足：<br>$$<br>\mathbf{X}_2 &#x3D; \mathbf{X}_1 \mathbf{\Phi}<br>$$<br>其中 $\mathbf{\Phi}$ 为包含信号到达角（DOA）信息的对角矩阵。通过对信号子空间进行奇异值分解（SVD），可直接从矩阵 $\mathbf{\Phi}$ 中提取信号参数[[4]]。</p><h3 id="子空间分解"><a href="#子空间分解" class="headerlink" title="子空间分解"></a>子空间分解</h3><p>原始ESPRIT通过以下步骤实现参数估计：</p><ol><li>构造阵列协方差矩阵并进行特征值分解；</li><li>分离信号子空间与噪声子空间；</li><li>利用子阵列间的平移关系求解旋转矩阵 $\mathbf{\Psi}$；</li><li>通过特征分解获得信号的波达方向（DOA）[[4]]。</li></ol><hr><h2 id="MUSIC算法核心思想"><a href="#MUSIC算法核心思想" class="headerlink" title="MUSIC算法核心思想"></a>MUSIC算法核心思想</h2><h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><ol><li><p><strong>信号子空间与噪声子空间分离</strong><br>论文提出利用协方差矩阵特征值分解，将信号空间划分为信号子空间（由大特征值对应特征向量张成）和噪声子空间（由小特征值对应特征向量张成）。两者正交的特性成为参数估计的关键 [[2]][[9]]。</p></li><li><p><strong>空间谱搜索</strong><br>通过构建如下MUSIC谱函数实现信号源定位：<br>$$<br>P_{\text{MUSIC}}(\theta) &#x3D; \frac{1}{\mathbf{a}(\theta)^H \mathbf{E}_n \mathbf{E}_n^H \mathbf{a}(\theta)}<br>$$<br>其中 $\mathbf{E}_n$ 为噪声子空间，$\mathbf{a}(\theta)$ 为阵列流形向量。当 $\theta$ 扫描到真实信号方向时，分母趋近于零，谱峰位置即对应信号源方向 [[3]][[9]]。</p></li></ol><hr><h2 id="扩展到三维空间下的估计"><a href="#扩展到三维空间下的估计" class="headerlink" title="扩展到三维空间下的估计"></a>扩展到三维空间下的估计</h2><p>随着5G通感一体化和智能感知的发展，实际应用中对三维空间（方位角、俯仰角、距离等）参数的高精度估计提出了更高要求。传统MUSIC和ESPRIT算法主要针对二维（如仅估计方位角），而三维场景下需要对信号的多个空间参数进行联合估计。</p><h3 id="三维ESPRIT算法"><a href="#三维ESPRIT算法" class="headerlink" title="三维ESPRIT算法"></a>三维ESPRIT算法</h3><p>三维ESPRIT算法需要平面或者立体的天线阵列流形，这里我们以平面阵列流形为例，且相邻的天线之间的间距相等，即均匀平面天线（UPA）；</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250520101247882.png" alt="UPA"></p><p>通过将信号的波达角分解为水平的方位角以及垂直的俯仰角，可以将信号到达不同天线的路程差通过天线间距$d$、方位角$\phi$以及俯仰角$\theta$联合表示：</p><p>$$<br>\Delta \lambda_{m,n} &#x3D; d \left[ (m-1)\sin\theta\cos\phi + (n-1)\sin\theta\sin\phi \right]<br>$$</p><p>由于天线之间的间隔以及波达角导致的信号到达天线阵列所经历的时间不同，意味着信号到达不同天线的相位也不一样。由于是均匀分布的天线，我们可以推测，相邻天线之间的相位差是一个定值，因此可以通过选择天线对，然后由ESPRIT的算法得到旋转不变性，从而计算得到两个参数：$\sin\theta\cos\phi$ 以及 $\sin\theta\sin\phi$，之后便可以轻松的计算出我们需要的方位角$\phi$以及俯仰角$\theta$。</p><h3 id="三维ESPRIT算法的难点"><a href="#三维ESPRIT算法的难点" class="headerlink" title="三维ESPRIT算法的难点"></a>三维ESPRIT算法的难点</h3><p>这里的难点在于，对接收到的信号做信道估计以及信道补偿一系列操作后得到的信道响应是所有天线阵列接收信道的叠加，从信道响应的形状上来说已经没有了天线阵列的形状信息，<strong>如何将信道响应$H$重新塑形</strong>则是一大难题。</p><p>对于如何获得信道响应，从感知的角度而言，将不同参数对应的导向矢量做克罗内克积便得到了信道响应：</p><p>$$<br>H &#x3D; a_{aoa} \otimes a_{zoa}<br>$$</p><p>这里的$\otimes$代表克罗内克积（kronecker product），$a_{x}$表示为某个参数的导向矢量。这里得到的是理想信道响应，可以添加加性高斯白噪声以模仿实际的信道响应。</p><h3 id="三维ESPRIT算法的具体实现"><a href="#三维ESPRIT算法的具体实现" class="headerlink" title="三维ESPRIT算法的具体实现"></a>三维ESPRIT算法的具体实现</h3><p>联合导向矢量的定义可以用x方向天线的导向矢量与y方向天线的导向矢量做克罗内克积得到</p><p>$$ A &#x3D; A_{x} \otimes A_{y} $$</p><p>也可以通过直接的定义得到</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 构建二维阵列响应</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">steering_vector_2d</span>(<span class="hljs-params">az_deg, el_deg</span>):<br>    <span class="hljs-comment">#^ 角度值转弧度制</span><br>    az = np.radians(az_deg) <span class="hljs-comment"># 方位角</span><br>    el = np.radians(el_deg) <span class="hljs-comment"># 俯仰角</span><br>    kx = np.sin(el) * np.cos(az)<br>    ky = np.sin(el) * np.sin(az)<br>    a = np.zeros((Mx, My), dtype=<span class="hljs-built_in">complex</span>)<br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Mx):<br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(My):<br>            a[m, n] = np.exp(-<span class="hljs-number">1j</span> * <span class="hljs-number">2</span> * np.pi * (dx * m * kx + dy * n * ky) / wavelength)<br>    <span class="hljs-keyword">return</span> a.flatten()<br></code></pre></td></tr></table></figure><p>接收信号矩阵可以具体表现为</p><p>$$ X &#x3D; AS + N $$</p><p>其中的$A_{M, K}$为接收矩阵的阵列响应，$S_{K, snapshots}$为$N$个信号源在接收天线的采样值，$N_{M, snapshots}$为噪声。</p><p>对接收信号直接做SVD，可以得到接收信号的协方差矩阵以及信号子空间和噪声子空间的基</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 协方差矩阵估计与SVD分解</span><br>R = X @ X.conj().T / snapshots  <span class="hljs-comment">#^ [M, M]的协方差矩阵</span><br>U, _, _ = svd(R)<br>Us = U[:, :K]                   <span class="hljs-comment">#^ [M, K]的信号子空间矩阵</span><br></code></pre></td></tr></table></figure><p>其中特征向量的选择取决于信号源的个数，且形状为<strong>天线数X信号源数</strong>,对每一个特征向量进行重新塑形，具体思想为选择前$row - 1$天线阵元的响应和后$row - 1$天线阵元的响应，通过ESPRIT算法可以得到相位偏差，对应于x轴方向天线阵元之间的相位偏移$\sin\theta\cos\phi$。同理选择前$col - 1$天线阵元的响应和后$col - 1$天线阵元的响应可以计算出y轴方向天线阵元之间的相位偏移$\sin\theta\sin\phi$，从而得到波达角。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 构造移位子阵列索引</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">shift_indices</span>(<span class="hljs-params">dim_x, dim_y, axis</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    函数作用: 先构建一个dim_x * dim_y的二维矩阵 索引从(0, 0)到(dim_x-1, dim_y-1)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    如果传入axis=0 则将行进行删除操作 然后按照行的顺序 顺次存取为一个一维的index 如0、1、2、...或者6、7、8、...</span><br><span class="hljs-string">    如果传入axis=1 则将列进行删除操作 然后按照行的顺序 顺次存取为一个一维的index 如0、1、2、3、4、6、...或者1、2、3、4、5、7、...</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> axis == <span class="hljs-number">0</span>:  <span class="hljs-comment"># x 方向（垂直方向）移位</span><br>        rows = np.arange(dim_x - <span class="hljs-number">1</span>)<br>        idx1 = np.ravel_multi_index(np.meshgrid(rows, np.arange(dim_y), indexing=<span class="hljs-string">&#x27;ij&#x27;</span>), (dim_x, dim_y))<br>        idx2 = np.ravel_multi_index(np.meshgrid(rows + <span class="hljs-number">1</span>, np.arange(dim_y), indexing=<span class="hljs-string">&#x27;ij&#x27;</span>), (dim_x, dim_y))<br>    <span class="hljs-keyword">elif</span> axis == <span class="hljs-number">1</span>:  <span class="hljs-comment"># y 方向（水平方向）移位</span><br>        cols = np.arange(dim_y - <span class="hljs-number">1</span>)<br>        idx1 = np.ravel_multi_index(np.meshgrid(np.arange(dim_x), cols, indexing=<span class="hljs-string">&#x27;ij&#x27;</span>), (dim_x, dim_y))<br>        idx2 = np.ravel_multi_index(np.meshgrid(np.arange(dim_x), cols + <span class="hljs-number">1</span>, indexing=<span class="hljs-string">&#x27;ij&#x27;</span>), (dim_x, dim_y))<br>    <span class="hljs-keyword">return</span> idx1.flatten(), idx2.flatten()<br><br><span class="hljs-comment"># 获取两个方向的子阵列</span><br>Ux1_idx, Ux2_idx = shift_indices(Mx, My, axis=<span class="hljs-number">0</span>)<br>Uy1_idx, Uy2_idx = shift_indices(Mx, My, axis=<span class="hljs-number">1</span>)<br><br>Ux1 = Us[Ux1_idx, :]<br>Ux2 = Us[Ux2_idx, :]<br>Uy1 = Us[Uy1_idx, :]<br>Uy2 = Us[Uy2_idx, :]<br><br><span class="hljs-comment"># 分别计算x方向和y方向的Psi矩阵</span><br>Psi_x = pinv(Ux1) @ Ux2<br>Psi_y = pinv(Uy1) @ Uy2<br><br><span class="hljs-comment"># 求解特征值并估计方向余弦</span><br>eigvals_x, _ = eig(Psi_x)<br>eigvals_y, _ = eig(Psi_y)<br><br>angles_x = np.angle(eigvals_x)<br>angles_y = np.angle(eigvals_y)<br><br>kx_est = angles_x * wavelength / (<span class="hljs-number">2</span> * np.pi * dx)<br>ky_est = angles_y * wavelength / (<span class="hljs-number">2</span> * np.pi * dy)<br></code></pre></td></tr></table></figure><p>代码中定义的函数<code>shift_indices</code>中根据接收天线的形状定义每根天线的索引，x方向和y方向上分别取子阵列的阵元索引，具体可以看函数的解析。再通过索引选取特征向量中的元素，通过ESPRIT的算法便可以得到不同方向上天线阵元之间的信号相位差，再由相位差便可以轻松的得到波达角。</p><h3 id="三维MUSIC算法"><a href="#三维MUSIC算法" class="headerlink" title="三维MUSIC算法"></a>三维MUSIC算法</h3><p>三维MUSIC算法通常基于三维阵列（如平面阵列或立体阵列），其核心思想与二维类似，但需要构造三维空间的阵列流形向量 $\mathbf{a}(\theta, \phi, r)$，并在三维参数空间内进行谱峰搜索：</p><p>$$<br>P_{\text{MUSIC}}(\theta, \phi, r) &#x3D; \frac{1}{\mathbf{a}(\theta, \phi, r)^H \mathbf{E}_n \mathbf{E}_n^H \mathbf{a}(\theta, \phi, r)}<br>$$</p><p>其中，$\theta$ 为方位角，$\phi$ 为俯仰角，$r$ 可为距离或极化等参数。通过在三维参数空间内搜索谱峰，实现对信号源空间位置的精确估计。该方法分辨率高，但计算量大，常需结合降维或并行计算优化。</p><h3 id="互素阵列流形——降维MUSIC算法"><a href="#互素阵列流形——降维MUSIC算法" class="headerlink" title="互素阵列流形——降维MUSIC算法"></a>互素阵列流形——降维MUSIC算法</h3><p>均匀平面阵列(Uniform Planar Array, UPA)  是一种经典模型,其相邻阵元间距均为半波长,该  模型在3维信源定位时精度较高,但在阵列口径较  大时,较高的结构复杂度限制了该模型的应用。为  了实现低复杂度的3维信源精确定位,本文提出  CLACS-SPA结构,其主要特征是将一列互素线阵  (Coprime Linear Array, CLA)沿着与之垂直的方  向按照相同的互素规律进行平移而得到 [[5]]。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250520134601234.png" alt="互素面阵"></p><p>图中左图$ULA1$为间隔为$a$的均匀线阵，$ULA2$为间隔为$b$的均匀线阵，将两个线阵拼接在一起且间隔互为素数则得到了互素线阵；有图中将这样的互素线阵在垂直的方向上拼接就得到了互素面阵。</p><p>对于这样的互素面阵，信源到不同天线之间相位差可以如下面这样表示：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250520135243124.png" alt="相位差计算"></p><p>分别从x轴方向和y轴方向计算相邻两个天线之间的信源波程差可以得到</p><p>$$<br>\begin{align}<br>\Delta_{x,k} &amp;&#x3D; \sqrt{r^2 + l_{x,k}^2 - 2l_{x,k}r \sin\varphi \cos\theta} - r \tag{2} \<br>\Delta_{y,k} &amp;&#x3D; \sqrt{r^2 + l_{y,k}^2 - 2l_{y,k}r \sin\varphi \sin\theta} - r \tag{3}<br>\end{align}<br>$$</p><p>有前面我们可以清楚的知道，波程差一定程度上等价于相位差，而波程差又取决于波达角以及距离（飞行时间）。所以，相位差是由三维参数共同决定的，这也就是说通过MUSIC算法遍历三维空间计算量十分庞大，那么有没有什么办法减少计算呢？</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250520140147302.png" alt="泰勒展开降维"></p><p>上述式子展示了将x或者y方向的波程差通过泰勒公式展开，对高阶项直接舍去便得到了<br>$\gamma_x &#x3D; -\frac{2\pi \sin\varphi \cos\theta}{\lambda}, \quad<br>\phi_x &#x3D; \pi \left(1 - \frac{\sin^2\varphi \cos^2\theta}{\lambda r}\right); \quad$</p><p>其中的$\gamma_x$只跟波达角有关，在求出波达角后$\phi_x$就只跟距离有关，如此便将一个三维的搜索转换为二维的搜索<strong>加上</strong>一维的搜索，大大降低了计算复杂度。</p><h3 id="互素阵列流形MUSIC算法具体实现"><a href="#互素阵列流形MUSIC算法具体实现" class="headerlink" title="互素阵列流形MUSIC算法具体实现"></a>互素阵列流形MUSIC算法具体实现</h3><p>首先是根据泰勒展开后的第一项构建搜索导向矢量$\hat{A}_{x}$，在一定的角度范围内遍历$\theta, \phi$并计算谱值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 泰勒近似方向导向项构造函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">xi</span>(<span class="hljs-params">l, gamma</span>):<br>    <span class="hljs-keyword">return</span> np.exp(<span class="hljs-number">1j</span> * gamma * l)<br><br><span class="hljs-comment">#^ 第一阶段：二维角度搜索 泰勒展开后的零次项作为预测的导向矢量估计ZOA、AOA</span><br><span class="hljs-keyword">for</span> i, phi <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(phi_scan):<br>    <span class="hljs-keyword">for</span> j, theta <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(theta_scan):<br>        <span class="hljs-comment">#^ 泰勒展开的零次项</span><br>        gamma_x = -k * np.sin(phi) * np.cos(theta)<br>        gamma_y = -k * np.sin(phi) * np.sin(theta)<br>        <br>        xi_x = xi(Lx, gamma_x)  <span class="hljs-comment">#^ [9, 1] 横向的天线响应</span><br>        xi_y = xi(Ly, gamma_y)  <span class="hljs-comment">#^ [9, 1] 纵向的天线响应</span><br>        xi_xy = np.kron(xi_x, xi_y).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)          <span class="hljs-comment">#^ [81, 1] 降维后x方向的导向搜索矢量</span><br>        <br>        <span class="hljs-comment">#^ 遍历角度 构建导向矢量 计算与噪声子空间的距离 </span><br>        psi = xi_xy.conj().T @ Un @ Un.conj().T @ xi_xy     <br>        Pmap[i, j] = <span class="hljs-number">1</span> / np.real(psi)                       <span class="hljs-comment">#^ 计算谱值 1/psi 最大值为波达角</span><br><br></code></pre></td></tr></table></figure><p>找到最大的谱值对应的波达角，将波达角带入到第二项中，就变成了距离$r$的单一求解，构建搜索导向矢量并在给定的范围内搜索谱值的最大值，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">upsilon</span>(<span class="hljs-params">l, phi_term</span>):<br>    <span class="hljs-keyword">return</span> np.exp(<span class="hljs-number">1j</span> * phi_term * l**<span class="hljs-number">2</span>)<br><br><span class="hljs-comment">#^ 泰勒展开的一次项 带入估计的波达角</span><br><span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> r_scan:<br>    phi_x = np.pi / (lam * r) * (<span class="hljs-number">1</span> - np.sin(phi_est)**<span class="hljs-number">2</span> * np.cos(theta_est)**<span class="hljs-number">2</span>)<br>    phi_y = np.pi / (lam * r) * (<span class="hljs-number">1</span> - np.sin(phi_est)**<span class="hljs-number">2</span> * np.sin(theta_est)**<span class="hljs-number">2</span>)<br>    <br>    upsilon_x = upsilon(Lx, phi_x)<br>    upsilon_y = upsilon(Ly, phi_y)<br>    upsilon_xy = np.kron(upsilon_x, upsilon_y).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-comment"># 需要带上零次项进行估计</span><br>    xi_x = xi(Lx, -<span class="hljs-number">2</span> * np.pi / lam * np.sin(phi_est) * np.cos(theta_est))<br>    xi_y = xi(Ly, -<span class="hljs-number">2</span> * np.pi / lam * np.sin(phi_est) * np.sin(theta_est))<br>    xi_xy = np.kron(xi_x, xi_y).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-comment"># 指数相乘等于相位相加 对应泰勒展开的项</span><br>    A_est = xi_xy * upsilon_xy<br>    pseudospectrum = <span class="hljs-number">1</span> / np.real((A_est.conj().T @ Un @ Un.conj().T @ A_est))<br>    P_r.append(pseudospectrum[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><p>最后便可以在保持高精度的前提下简化计算复杂度提高速度</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250520144154490.png" alt="参数估计"></p><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从最初的经典ESPRIT和MUSIC算法，到近年来面向三维建模和5G通感一体化的多维参数估计算法，参数估计技术正不断向高精度、高分辨率和强鲁棒性方向演进。随着阵列结构的创新（如互素阵、稀疏阵列）和信号处理手段的提升（如空间平滑、极化信息融合、降维搜索等），改进算法不仅在低信噪比、强干扰等复杂环境下展现出更优的性能，还显著降低了计算复杂度，提升了实时性和工程可用性。这些进步为5G通感一体化、智能感知、无人系统等前沿应用提供了坚实的技术基础和广阔的发展空间[[1]][[2]][[4]]。</p><blockquote><p>参考资料：<br>[[1]] 基于改进3D-ESPRIT的GTD模型参数估计<br>[[2]] 三维GTD模型参数估计的改进算法<br>[[3]] CN111781573A 专利文档<br>[[4]] TLS-ESPRIT改进空间平滑算法<br>[[5]] 基于稀疏面阵的低复杂度三维信源定位算法</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>5G 通感</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于5G通信的定位感知——AOA解算</title>
    <link href="/2025/04/24/research/AOA_Positioning/"/>
    <url>/2025/04/24/research/AOA_Positioning/</url>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p><em><strong>5G-NR</strong></em>，具有⾼速、低延迟的特性，是现代通信强有⼒的技术之一。又因广泛的基站建设，5G逐渐覆盖日常生活中的每个角落，随着覆盖范围的扩张，不仅意味着越来越稳定的通信，感知，更是随之不断的发展。</p><p>下⾯，本文将针对无人机向5G基站通信这一应用场景，尝试通过仿真验证利用无人机与5G基站的通信能够实现利用 <em><strong>CSI</strong></em> 解算出无人机的位置信息，如 <em><strong>AOA、AOD、ToF</strong></em> 等参数，验证 <em><strong>MUSIC</strong></em> 算法的可行性。下面是对如何通过通信的 <em><strong>CSI</strong></em> 实现对位置信息感知的理论描述。</p><h1 id="理论篇"><a href="#理论篇" class="headerlink" title="理论篇"></a>理论篇</h1><h2 id="信号在发送端天线的传播特性"><a href="#信号在发送端天线的传播特性" class="headerlink" title="信号在发送端天线的传播特性"></a>信号在发送端天线的传播特性</h2><p>发送端（无人机）仅考虑单根天线进行收发，且天线是全向极化天线。信号由无人机发出，向四面八方发送信号，这些信号在Tx天线处发出时对应的角度我们称为 <em><strong>AOD（Angle of Departure）</strong></em>。在 <em><strong>Tx</strong></em> 处的AOD有很多不同的值，我们近似认为范围为 <em><strong>[0, 2*pi]</strong></em>。</p><p><img src="https://raw.github.com/allforkarina/embadded_image/refs/heads/master/20250425123140384.png" alt="无人机发送天线"></p><p>由于发送端 —&gt; 接收端的距离很远，信号在信道中传输之后在到达5G基站的天线阵列时，我们近似认为这些信号可以被视为平⾏波。</p><h2 id="接收端天线阵列接收信号"><a href="#接收端天线阵列接收信号" class="headerlink" title="接收端天线阵列接收信号"></a>接收端天线阵列接收信号</h2><p>由于信号在信道中传递有多径特性，其中某⼀个单径上的信号在到达天线阵列时可以被视为⼀组平⾏波。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250425123346494.png" alt="接收天线阵列"></p><p>下面我们仅考虑某一个单径上的信号，这个信号以一组平行波的形式被接收端的天线阵列接收。作⼀条垂直于平⾏波的虚线，我们可以近似认为它与这一组平⾏波的交点所对应的信号相位相同，即这个虚线是一个等相线。由上图可⻅相邻两根天线之间信号传播距离相差 <em><strong>L</strong></em>，又因为波⻓与相应间存在某种关系，我们可以理解为，传播的距离差 <em><strong>L</strong></em> 等价于信号到达天线的相位差 <em><strong>φ</strong></em>。因此可以说,相邻两概天线在同时接收到的信号之间差⼀个恒定的 <em><strong>φ</strong></em> 。以另⼀个⻆度上说，同时接收 <em><strong>N</strong></em> 个天线上的信号且相邻信号之间差⼀个 <em><strong>φ</strong></em>，那么我们可以压缩天线，我只对第⼀根天线接收的信号采样，采样间隔 <em><strong>t &#x3D; L&#x2F;c &#x3D; φ&#x2F;f</strong></em> （ <em><strong>c</strong></em> 是光速，<em><strong>f</strong></em> 是信号的频率）。</p><p>以第⼀根天线接收的信号为基准定义为 <em><strong>S0 &#x3D; exp(j*2*pi*d*cosx)</strong></em>,如此其余天线接收的信号就能够定义为 <em><strong>Sk &#x3D; exp(j*2*pi*k*d*cosx) &#x3D; （exp(j*2*pi*d*cosx)）^k</strong></em> 等等，第k根天线的信号是第一根天线的k次方，又因为第k根天线相较于第一根天线有 <em><strong>k * d</strong></em> 的距离差，表现在信号上有k次方的关系，于是我们认为，第k根天线相较于第一根天线有 <em><strong>φ^k</strong></em> 的相位延迟。若我们定义第一根天线没有延迟，那么我们就可以写出第一条单径对应信号的导向矢量</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250425123744616.png" alt="导向矢量"></p><p>又因为多径，不同AOA的信号同时到达接收天线阵列，彼此叠加。所以我们在天线处采样得到的信号，是K个不同AOA路径信号的叠加。我们多次进行采样，一共采样 <em><strong>M</strong></em> 次就可以得到 <em><strong>MxN</strong></em> 的导向矩阵。</p><p>又因为每个列向量（导向矢量）的元素之间是成指数递增的关系，因此根据矩阵论的相关知识，该导向矩阵是满秩的。</p><h2 id="AOA解算"><a href="#AOA解算" class="headerlink" title="AOA解算"></a>AOA解算</h2><p>这里我们假设一共有一根 <em><strong>Tx</strong></em> ，3根 <em><strong>Rx</strong></em>，这里我们考虑两条多径（一条直射、一条反射）。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250425123355885.png" alt="多径模型"></p><p>对天线上接收的信号进行采样，每一次采样计算出来的导向矢量是由两条路径对应不同的导向矢量叠加得到。我们多次进行采样，这些采样得到的所有导向矢量构成一个导向矩阵，该导向矩阵一定是满秩的。</p><p>每一个导向矢量，xyz三个坐标，对应在一个三维空间中的一个位置，采样了 <em><strong>m</strong></em> 次，则一共有 <em><strong>m</strong></em> 个三维空间中的矢量，每一个矢量又是由两条路径对应的导向矢量通过平行四边形法则叠加得到。两条路径的导向矢量不同是因为不同路径到达接收天线阵列的AOA不同，因此导向矢量也不同。我们可以假设，如果有无数条路径，这些路径对应的AOA也不同，意味着有无数条不同的导向矢量，这些导向矢量的末端连起来必然是一个封闭的空间曲线（因为AOA有界）。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250425123406300.png" alt="空间封闭曲线"></p><p>已知每一个导向矢量对应一个AOA，导向矢量的模长受到对应信道时变衰落的影响，因此每一个导向矢量是对应方向延长线上的点。由于不同AOA的信号在天线处叠加，采样得到的导向矢量对应在空间中是不同AOA导向矢量的加权（信道衰落）和。</p><p>如果每次采样的信号是由两个多径信号叠加，那么采样信号的导向矢量就是这两个多径信号的导向矢量加权和。又两个向量可以张成一个二维的平面（子空间），我们称这个子空间为 <strong>信号子空间</strong>。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250425123415468.png" alt="信号子空间"></p><p>假设你的信道中没有噪声，那么我们可以推断出，无论采样多少次，每次采样的信号对应的导向矢量一定属于这个信号子空间。<em><strong>n</strong></em> 条路径 <em><strong>m</strong></em> 根接收天线对应的信号子空间维数为 <em><strong>R_min &#x3D; min(n, m)</strong></em>。因为信号子空间的维数一定小于或者等于整个导向矢量的空间维数，因此一定可以找到一个垂直于信号子空间的基，这个基对应的空间我们称为 <strong>噪声子空间</strong>。如果你的信道中有噪声，你的导向矢量在空间中表现为在垂直信号子空间的方向上有一定的偏移</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250425123421082.png" alt="正交噪声子空间"></p><h2 id="实际解算过程"><a href="#实际解算过程" class="headerlink" title="实际解算过程"></a>实际解算过程</h2><ol><li><p>同时对 <em><strong>N</strong></em> 个天线阵元采样得第⼀个导向矢量；多次采样得 <em><strong>M</strong></em> 个导向矢量；每一个导向矢量是来自 <em><strong>K</strong></em> 个路径的信号叠加（每个路径的AOA不同）。</p></li><li><p>得到导向矢量矩阵 <em><strong>A &#x3D; [P_1, P_2, …, P_n]</strong></em> ，矩阵的形状为 <em><strong>M x N</strong></em> 且一定是满秩的，信号子空间为维度为天线阵元数量与多径数量中的较小值。假设信号子空间为 <em><strong>K</strong></em> 维，导向矢量的空间维度为 <em><strong>N</strong></em> 维，对导向矢量矩阵做特征值分解，能够得到 <em><strong>N</strong></em> 个特征矢量，其中 <em><strong>K</strong></em> 个构成了信号子空间，也对应着 <em><strong>K</strong></em> 个多径各自的 <em><strong>AOA</strong></em>。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>5G 通感</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>阅读札记——“5G信道的估计与均衡”</title>
    <link href="/2025/04/02/research/Channel-state-info/"/>
    <url>/2025/04/02/research/Channel-state-info/</url>
    
    <content type="html"><![CDATA[<h1 id="5G通信信道估计"><a href="#5G通信信道估计" class="headerlink" title="5G通信信道估计"></a>5G通信信道估计</h1><h2 id="一、MIMO——OFDM技术简介"><a href="#一、MIMO——OFDM技术简介" class="headerlink" title="一、MIMO——OFDM技术简介"></a>一、MIMO——OFDM技术简介</h2><h3 id="MIMO："><a href="#MIMO：" class="headerlink" title="MIMO："></a>MIMO：</h3><p>多输入-多输出，即大规模天线阵列用于发送以及接收。</p><p>用基站端天线数量的扩展代替基站数量的扩展。</p><p>减少基站数量意味着多径效应的削弱，有利于减少小尺度衰减对信号传输的影响。</p><h3 id="OFDM："><a href="#OFDM：" class="headerlink" title="OFDM："></a>OFDM：</h3><p>在传统的频分传输基础上，进一步节省频带资源，实现正交频分调制。</p><h2 id="虽然OFDM各个子载波存在有频谱交叠的部分，但是由于是正交的，接收端仍能够解调信号并且可以高效的利用频谱。"><a href="#虽然OFDM各个子载波存在有频谱交叠的部分，但是由于是正交的，接收端仍能够解调信号并且可以高效的利用频谱。" class="headerlink" title="虽然OFDM各个子载波存在有频谱交叠的部分，但是由于是正交的，接收端仍能够解调信号并且可以高效的利用频谱。"></a>虽然OFDM各个子载波存在有频谱交叠的部分，但是由于是正交的，接收端仍能够解调信号并且可以高效的利用频谱。</h2><p>MIMO在空间域上节省资源；OFDM调制在频域上节省资源。</p><h2 id="二、mMIMO——Massive-MIMO"><a href="#二、mMIMO——Massive-MIMO" class="headerlink" title="二、mMIMO——Massive MIMO"></a>二、mMIMO——Massive MIMO</h2><h3 id="MIMO的信道增益"><a href="#MIMO的信道增益" class="headerlink" title="MIMO的信道增益"></a>MIMO的信道增益</h3><p>多用户大规模MIMO，面向于多个用户接入，单个基站端配备有几十上百跟天线：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image001.png" alt="MIMO and UE"></p><p>每个用户端只有一根天线，基站端配备有多根天线与用户相匹配。其中，第m根天线接收到来自第K个用户的信号Im,K在信道中的增益等于：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image002.png" alt="signal amp"></p><p>大尺度的衰减与小尺度的衰减相乘得到。其中，小尺度的衰减系数受天线的影响最大，可以认为是多个用户导致的用户间串扰（IUI-interUser interference）对于有M根天线阵列的基站来说，每根天线接收到K个用户传来的信号，将这<img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image003.png" alt="Channel Matrix">的信号组成矩阵，对应每个信号的信道增益就构成了信道矩阵。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image005.png" alt="Channel Matrix"></p><p>这也是CSI最终我们要得到的参数（矩阵）。</p><h3 id="MIMO的信道分析"><a href="#MIMO的信道分析" class="headerlink" title="MIMO的信道分析"></a>MIMO的信道分析</h3><p>已知不同信道、不同信号的信道估计增益都不一样，这取决于大尺度衰弱叠加上小尺度干扰；因此为了增强信号的信噪比以及削弱用户间的干扰，我们可以采用最大合并比以及最大比发送实现，具体的思想就是根据CSI估计的信道衰减反馈在接收端或者发送端添加一个增益，以追求所有天线的信噪比之和最大。通常不同天线的增益满足：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image006.png" alt="MRC"></p><p>即增益与信道衰减成正比，与上述的描述相符。</p><p>那么我们如何通过CSI解得的信道矩阵求出最大比合并的权重？我们将矩阵写成列向量矩阵，每一列表示一个用户发出的信号被M根天线接受的信道衰减系数，属于小尺度衰减。我们对信道矩阵取模计算衰减可以得到下面式子：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image007.png" alt="MRC"></p><p>中间的展开式暂时不理解为什么等于这个结果，但是直接考虑到展开之前的部分，由于空间域的复杂性，我们可以假设不同天线的信道之间是互不相关的，由此我们就能知道一个信道的共轭转置乘上另一个信道可以理解求取为两个信道的相关性，因此可以近似于0；式子1的结果是因为当前信道和自己的相关性固然为1.这样我们只需要采用线性的处理方式即最大比合并就可以实现大规模MIMO中多个用户的传播。</p><h3 id="MIMO优缺点"><a href="#MIMO优缺点" class="headerlink" title="MIMO优缺点"></a>MIMO优缺点</h3><p>MIMO实现了在同时、同频进行多用户传播（利用波束空间复用），开发了空间域的资源利用，提高了容量。但是于此同时，随着用户数量大量增加，信道数量根据基站侧的天线数量尺度进行扩张，这也会导致导频资源的紧缺（世间真理，一件事物的宽裕会导致另一件事物的紧缺），导致导频污染。就像原本是一个8x8的象棋格，原本是错开的排列，当用户（列数）增加时，就会出现某一行有两个用户，这也就造成了导频污染。</p><h2 id="OFDM调制"><a href="#OFDM调制" class="headerlink" title="OFDM调制"></a>OFDM调制</h2><h3 id="什么是OFDM调制"><a href="#什么是OFDM调制" class="headerlink" title="什么是OFDM调制"></a>什么是OFDM调制</h3><p>OFDM：正交频分复用，通过多载波调制（加载在不同的频段上）实现对频率选择性衰弱一定的抵抗，同时实现串行信号并行传输，提高速率且尽量节省频带资源。并行传输的优势还在于延长了单个符号的持续时间，假设我需要传输四个符号，每个符号持续0.25ns，那么一共传输1ns；如果我使用OFDM并行传输的话，使用4个子载波进行调制，那么在原来的传输时间1ns内我可以每个符号传输1ns并行传输，这样我单个符号的长度是原来的4倍，通过一些纠错码可以更容易校验符号、纠错，提高系统对ISI的抵抗性。</p><p>OFDM实信号的调制表达式如下：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image008.png" alt="MRC"><br><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image009.png" alt="MRC"></p><p>N为子载波的个数。在接收端由于每个子载波在频域上是相互正交的，可以容易的通过相干解调分离出每一个子载波承载的信号，最后再并串转换就可以得到信道传输后的接收信号。当然实际的调制过程更加复杂，一个可能的框图如下：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image010.png" alt="MRC"></p><h3 id="OFDM的技术特点"><a href="#OFDM的技术特点" class="headerlink" title="OFDM的技术特点"></a>OFDM的技术特点</h3><p>由于信道的不确定性，如多普勒频移导致的非正交性都会对OFDM传递的符号间产生严重的干扰；或者普遍存在的符号间干扰都会导致OFDM的正常传输，因此我们在传输的符号之间插入一段间隔称为保护间隔，通过牺牲一部分资源换取通信的稳定性。</p><p>在插入保护间隔的同时手动引入了时延，再加上多普勒频移导致子载波间不再是严格的正交，子载波信道之间会产生干扰，ICI即信道间干扰。于是添加了循环前缀，补全保护间隔的空缺，是不同信道的符号之间对齐，保持子载波之间的正交性，当然，这样也导致了资源的浪费，但是也能够减少复杂信号处理的开销。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image012.png" alt="MRC"></p><h2 id="信道估计"><a href="#信道估计" class="headerlink" title="信道估计"></a>信道估计</h2><p>信道估计即是通过信道估计算法等数学分析手段研究时变无线信道的信道相关参数，这些参数对于接收端的数据恢复有很重要的作用。信道估计算法大致上可以分为三类，非盲估计、半盲估计和盲估计。这里的“盲”是指发送端的信号是否含有导频，所谓导频是一段接收方和发送方约定好的信号，通过观测导频发生的变化可以解出信道对当前信号的响应。因此我们一般使用非盲估计的方法。</p><h3 id="传统信道估计算法"><a href="#传统信道估计算法" class="headerlink" title="传统信道估计算法"></a>传统信道估计算法</h3><p>接收端的信号是传输信号通过信道的冲激响应后叠加一个加性高斯白噪声的结果，通过算法将接收信号还原接近发送信号，而估计与实际之间的误差就是衡量算法优越性的一个指标：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image013.png" alt="MRC"></p><p>非盲估计是基于导频的信道估计算法，其中比较有代表性的有LS算法。即最小二乘法，其优点是复杂度低，易实现。信道模型如下</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image014.png" alt="MRC"><br><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image015.png" alt="MRC"></p><p>上述数学表达式是信号经过FFT后的频域表达，LS的估计目标是找到一个信道响应能够使HX即估计值与Y实际接收值之间的残差最小，数学表示如下：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image016.png" alt="MRC"></p><p>第一行就是求取两者的残差，矩阵运算也就等于共轭转置×原矩阵。最后的展开式是一个关于HLS的一个方程，我们想要让残差最小，也就是在方程的极小值处取值，因此我们对上式求偏导令等式两边为零，最终的结果是：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image017.png" alt="MRC"><br><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image018.png" alt="MRC"></p><p>其中<img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image019.png" alt="MRC">表示为X的伪逆矩阵。对LS算法求一下均方误差可以得到：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image021.png" alt="MRC"></p><p>结果是信噪比（SNR）的倒数，也就是说当信道的信噪比越高，LS算法的估计效果越好，反过来也意味着LS算法易受噪声干扰。从模型的建立也可以看出，若忽略加性白噪声那一项，估计值就等于实际值。</p><p>由于LS算法对噪声的忽略，导致LS在实际的应用上估计误差较大，所以我们考虑另一种算法即MMSE算法。不像LS算法通过对导频信号的估计与原信号之间的差值来取得信道估计的最佳，MMSE直接对信道的冲激响应进行估计，然后通过信道响应的估计与真实信道响应之间的差值来取得最佳，这也就考虑到信道的多种特质（包括噪声）。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image022.png" alt="MRC"></p><p>最小均方误差算法的思路就是实现信道估计结果与信道响应的真实值之间的均方误差达到最低值。我们假设一个矩阵M使得MY能够逼近发射信号X，令信道响应估计矩阵HMMSE为MY，均方差也就是</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image023.png" alt="MRC"></p><p>这是一个关于M矩阵的函数，我们想让均方差取得极小值也就是要令偏导为0。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image024.png" alt="MRC"></p><p>发现M矩阵是真实信道矩阵冲激响应与接收端信号的互相关矩阵乘上接收端信号自相关矩阵的逆。最后信道响应估计矩阵由等式HMMSE &#x3D; MY得出</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image025.png" alt="MRC"></p><p>MMSE 信道估计算法相对于前面的 LS 算法,最大的改进之处在于消除噪声对信道估计的不良影响,能够实现更为精准的信道估计效果。但是我们从算法的思想中也可以发现，MMSE算法是基于真实信道的自相关矩阵实现的，算法要求信道的统计先验信息，而这往往需要很大的工作量，而且大量的矩阵运算也导致运算的复杂度增大以及算力的需求。</p><hr><p>总结一下，上面两种算法对于信道估计在某些层面上都有较好的表现，LS算法是通过假定一个信道响应HLS，通过将导频通过假设的信道响应与接收端实际接收的导频之间的均方差来估计信道响应，这种假设忽略了信道中噪声的影响。而MMSE算法通过假设一个矩阵M，假定信道响应等于接收端的导频乘上矩阵M即MY，通过真实信道响应与估计的信道响应之间的均方差来估计信道响应，这种假设考虑到信道中的噪声提高了精度，但是需要先验条件即真是信道的自相关矩阵。</p><h2 id="压缩感知"><a href="#压缩感知" class="headerlink" title="压缩感知"></a>压缩感知</h2><p>压缩感知基于信号的稀疏性。该技术的原理是:首先求取得到一个域,它可以实现将原始信号转换至此域后能展现出信号的稀疏性质,完成原始信号的稀疏变换;然后为变换得来的稀疏信号寻找合适的观测矩阵,形成较低维度的信号;最后以低采样的代价,应用重构算法把原来的信号估计出来,回到稀疏域进行处理。例如，信号通过无线信道到达基站的天线阵列，从到达的角度考虑，实际信号到达的角度很有限，在角度域上呈现出稀疏性。</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image026.png" alt="MRC"></p><p>如果信号本身不具有某些稀疏性，则利用某一正交基实现线性的稀疏转变：</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image028.png" alt="MRC"></p><p>X是原始的N为信号向量，<img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image029.png" alt="thi">是稀疏变化矩阵，<img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image031.png" alt="theta">是完成转变的稀疏信号。完成信号的稀疏转变后的第二部就是进行测量矩阵的设计问题，将上一步完成的稀疏信号与测量矩阵相乘的目的是将信号降维。（去除冗余的信息）</p><p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/image033.png" alt="MRC"></p><p>测量矩阵×稀疏变换矩阵得到了A即感知矩阵。原信号是一个N维的信号，而感知矩阵是一个M×N的矩阵，也就是说实现了降维，后续只需要借助M维信号就可以实现最终的原始信号的恢复。</p>]]></content>
    
    
    <categories>
      
      <category>5G, 通感</category>
      
    </categories>
    
    
    <tags>
      
      <tag>5G, Channel state infomation(CSI)</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>初识无线通信——5G 信道估计</title>
    <link href="/2025/04/02/research/Knowing_5G/"/>
    <url>/2025/04/02/research/Knowing_5G/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是无线通信"><a href="#什么是无线通信" class="headerlink" title="什么是无线通信"></a>什么是无线通信</h1><p>你在你的手机微信上编辑了一段文字，轻点发送，远在天边的亲朋好友便能够几乎瞬时的接收到你讯息，这固然很好。但是你是否想象过，这个传输的过程是如何实现的？可能你知道，手机向手机基站发送信息，然后基站之间再进行传输，最后由基站向手机对面的人发送消息。那么，现在请你抬头，看看你周围，你是否生活在“盘丝洞”之中。我相信正常的答案是否的（如果你说yes，那你很厉害哟），这就是我们所说的无线通信。这是一个堪称伟大的科技手段，要是信号都只能通过光纤、信号线传输，那我们就真的生活在盘丝洞之中了（!_!）我们现在常用的移动设备像手机、电脑、电视这些，都配备有天线，在基站安装这几十上百的天线构成阵列来接受我们向他发送的信息（后面统称为信号）。</p><p>那你可能会说，就这？你一根天线、我一根天线就能解决的事情，能称得上伟大？当然不是这么简单，你在生活中不难发现，向前推一辆车，过一会他就会自己停下来；向前说话，声音却像是从前面传来。这些说明两点：</p><ol><li>日常生活中存在阻力，或者说衰减，空中传递的信号也不例外会受到衰减，导致从手机到基站的信号的质量往往不如手机端刚发出。</li><li>信号不是像一根线一样固定一个方向传播，而是像声波一样向四周扩散的传播，碰到物体也会反射。现实生活中的反射物更加多，这导致你发出的信号在传播过程中会变成2个、4个、8个甚至更多，这些信号传输到基站就会产生诸多问题，比如哪个信号才是你手机发出的？不同信号之间的到达时间还不同，可能导致通信的延迟。</li></ol><p>无论是上面信号的衰减还是反射导致多径（后续称反射导致的多个信号为多径）都会造成信号延时、信号错乱或者丢包的现象。这也就引起科学家们对无线信号传输的介质（后续我们称为信道）的研究热情，也就是我们所说的信道估计。</p><h1 id="什么是信道"><a href="#什么是信道" class="headerlink" title="什么是信道"></a>什么是信道</h1><p>通过上面的简单讲述，我们知道了信号传输需要借助信道来进行，但是信道是什么？简单来说，信道就是信息传输的“道路”，它决定了你的信号在传输过程中会遇到哪些“坑坑洼洼”，以及它最终能否顺利到达终点。信道可以按照物理性质进一步细分成两大类：</p><ol><li><strong>有线信道</strong>：你可以把它理解成现实生活中的“高速公路”，光纤、电缆等物理介质就像是坚固的公路，保证了信号可以稳定传输。</li><li><strong>无线信道</strong>：它更像是一条“空中航线”，信号依靠电磁波在空中传播，不需要任何实体的介质支撑，但也因此容易受到干扰。</li></ol><p>而我们的手机信号在绝大部分的情况下是按照无线的方式进行传输的，而无线信道不像有线信道那样受物理线路保护，它在现实环境中会受到各种因素的影响，导致信号在传输过程中变得“崎岖不平”。那么我们为了更好的传输信号，我们就需要研究无线信道的一些特性。</p><h3 id="衰弱"><a href="#衰弱" class="headerlink" title="衰弱"></a><strong>衰弱</strong></h3><p>你有没有试过在一个房间里走动时，手机的信号时好时坏？这就是衰落的表现。衰落的原因有很多，比如信号在传播过程中遇到障碍物（墙壁、建筑物等），或者随着传播距离的增加，能量逐渐减少。我们通常把衰落分成两类：</p><ol><li><strong>大尺度衰落</strong>：影响的是信号的整体强度，和传播距离、环境密集程度有关。比如，你站在空旷的草原上，手机信号可能很好；但如果你进入高楼大厦的电梯，信号可能会瞬间变差。</li><li><strong>小尺度衰落</strong>：影响的是信号的细微波动，通常是因为多条路径的信号相互干扰，比如你在城市的街道上走动时，信号可能会在不同建筑物间反射，导致质量不稳定。</li></ol><h3 id="多径效应"><a href="#多径效应" class="headerlink" title="多径效应"></a><strong>多径效应</strong></h3><p>想象一下你在山谷中大喊一声，你的声音会经过不同路径反射回来，形成“回声”。无线信号的情况也是如此——信号在传播过程中，会因为碰到建筑物、树木、地面等产生反射、折射、散射等现象，从而形成多个到达接收端的路径。问题是，不同路径的信号传播时间不一样，到达接收端时可能会相互叠加或抵消，导致信号失真。这种现象被称为多径效应。多径效应会导致两种衰落：</p><ol><li>平坦衰落：如果信号的带宽较小，整个频段的信道影响几乎相同，衰落不会太严重。</li><li>频率选择性衰落：如果信号的带宽较大，不同频率的信号分量会受到不同程度的衰落，从而导致接收信号的畸变。</li></ol><h3 id="多普勒效应"><a href="#多普勒效应" class="headerlink" title="多普勒效应"></a><strong>多普勒效应</strong></h3><p>如果你坐在路边，听着远处驶来的救护车警笛声，你会发现声音的频率在接近时变高，远离时变低。这就是多普勒效应。在无线通信中，如果信号的发射端或接收端在运动（比如你在开车时打电话），信号的频率会发生偏移，影响通信质量。多普勒效应带来的主要影响是：</p><ol><li><strong>频率偏移</strong>：信号的频率发生变化，可能会导致解调困难。</li><li><strong>快衰落</strong>：当信道的变化速度比信号的变化快时，你在传输一个信号符号的时候，还没传完信道的性质就发生了改变，信号就会迅速失真，影响通信的稳定性。</li></ol><p>无线信道是信息传输的“无形道路”，但它并不总是平坦顺畅的。衰落、多径效应、多普勒效应这些问题，使得无线信号在传输过程中会出现各种不可预测的变化。这也正是科学家们研究信道特性的原因——他们希望找到更好的方法来对抗信道的不利影响，让无线通信变得更加稳定高效。那么，如何才能让信号在复杂的无线环境下依然保持良好的质量呢？别着急，这就是我们下一步要讨论的话题——信道估计！</p><h1 id="什么是信道估计（CSI）"><a href="#什么是信道估计（CSI）" class="headerlink" title="什么是信道估计（CSI）"></a>什么是信道估计（CSI）</h1><p>我在上面通过一种举例子的方式带你简要的理解了一下什么是无线通信以及我们为什么要做信道估计，下面我从学术一点的角度上解释什么是信道估计、为什么需要信道估计，以及信道估计有什么用（作者也是初学者，仅作为参考以及补充）？信道估计，顾名思义是对信道参数进行的一种估计。由于信道的不确定性，我们通常采用统计的角度对信道的一些影响信号传输的参数进行估计，比如衰减、时延等等。那我们为什么需要信道估计？我还是举例进行说明，假设一个用户向基站传输10个信号，每个信号经历完全相同的信道（也就是说信道对信号的影响完全一样），如果我不做信道估计，那基站每接收一个信号都要对这个信号进行一个信道影响的消除，这对于基站这种大吞吐量的应用场景显然不合理。如果基站对第一个信号做信道估计，知道了信道对信号的冲激响应是幅度衰减为1&#x2F;2、相位延后10，那么后续的9个信号基站可以直接给一个2倍的增益，然后将相位提前10以此消除信道的干扰，如此就节省了资源又提高了效率。</p><p>后续科学家们通过对信道估计得到的参数进行研究，推出了许多的算法，发现可以通过CSI得到信号从发出到达基站的时间、信号到基站使被接收的角度等，由此衍生了CSI得出信道响应用于定位用户的功能等。</p>]]></content>
    
    
    <categories>
      
      <category>5G 通感</category>
      
    </categories>
    
    
    <tags>
      
      <tag>5G Channel state infomation(CSI)</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Wi-Fi Backscatter communication</title>
    <link href="/2025/03/18/research/Wi-Fi%20Backscatter%20communication/"/>
    <url>/2025/03/18/research/Wi-Fi%20Backscatter%20communication/</url>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>This article is about a new way of communication for edge IoT devices. Aims at transmitting information of sensors without consuming energy or even store energy for sensing environment.</p><p>It is a great method to deal with situation which may encounter some problems like short-energy.</p><p>We realise this method based on 802.11.ac frame structure, using a mcu controling RFID switch to change the resist value, which cause the changing in phase of the Wi-Fi packets.</p><p>The <strong>180 degrees</strong> inversion in phase of Wi-Fi packets will destroy the mac frame of signal transmitted in Los(Line of sight) as superimposed by the inversed Wi-Fi packets, which cause the <strong>0 bits</strong> in ACK block.</p><p>So we can get the information that we modulated onto the Wi-Fi packets without transmitting it by decoding the ACK blocks. That is the main concept of what we do.</p><h2 id="什么是WiFi反向散射系统（WiFi-BackScatter-Communication-System）"><a href="#什么是WiFi反向散射系统（WiFi-BackScatter-Communication-System）" class="headerlink" title="什么是WiFi反向散射系统（WiFi BackScatter Communication System）"></a>什么是WiFi反向散射系统（WiFi BackScatter Communication System）</h2><p>直观点说，Backscatter 通信是一种极低功耗通信方式，设备不用主动“发射信号”，而是通过反射已有的无线信号（比如WiFi）来传递数据。基本原理是假设空气中已经存在一个无线信号（比如 WiFi 路由器发出的信号），背散射设备（比如标签）不自己发射信号，而是通过调节天线的阻抗，选择性地反射或不反射这些信号。接收端设备（比如智能手机）检测这些变化，从中恢复出数据。</p><p>可以理解为有人一直在用手电筒（WiFi 信号）照一个镜子，这个镜子（WiFi Tag）可以控制自己是反光还是吸光（反射或不反射信号），你站在另一边看，就能根据“亮”或“不亮”来解码信息。这样的通信方式可以实现超低功耗（甚至可以完全无电池），完全适配物联网（IoT）设备、RFID 标签等。</p><h2 id="如何理解WiFi-Backscatter所谓的破坏"><a href="#如何理解WiFi-Backscatter所谓的破坏" class="headerlink" title="如何理解WiFi Backscatter所谓的破坏"></a>如何理解WiFi Backscatter所谓的破坏</h2><ol><li><p>理解WiFi Tag的工作方式我们就需要先知道WiFi是怎么传输数据的。我们都知道数据在电脑中是呈现为0101这样的二进制比特流的，每8个bit构成一个字节。而WiFi将至少一个字节包装成一个子帧（subFrame），Tag就是以子帧为基本单位实现破坏的功能的（也就是说破坏很多个bit）。已知我们手机（UE）向路由器发送数据，如果路由器成功接收了那么就会回应UE一个BA（Block ACK）。如果接收到了，在BA对应的帧位置上会显示为1.假设我们原本要传输一共10个子帧，如果AP（例如路由器）全部都接收到了，那么在Wireshark（一个抓包软件）上就会显示BA对应位置有10个1（1表示成功接收）。</p></li><li><p>有的人想你把用户发出的数据破坏了，那用户不就丢包了吗？这时候，我们就要理解多径。信号在空气中不是只沿一条直线传播的，而是在一定范围的角度范围内都有的，这也导致了多径的产生。假设我们现在发出的信号只有两条路径</p></li></ol><p><img src="https://github.com/allforkarina/embadded_image/blob/master/20250406065801171.png?raw=true" alt="Multiple Path"></p><p>其中从Helper到Reader的路径是最短的直线（称为LOS）。另一条路径的信号可能由于外界环境的反射（跟声波一样），路径长度更长，使得信号到达Reader时相比于LOS有一个时延，而这个时延就会导致信号的相位发生改变（改变180°就相当于反向）。</p><ol start="3"><li>那么我们如何实现这个相位反向呢，靠运气等环境自己使信号相位改变吗？下面我们就要讲硬件实现思路。我们都知道信号波长与频率之间的关系：</li></ol><p><img src="https://github.com/allforkarina/embadded_image/blob/master/20250406065807770.png?raw=true" alt="Multiple Path"></p><p>一般频率我们已知，那么我们也就能够算出来信号的波长。一个波长从公式的角度等价于一个完整周期，等价于一个360°的相位偏移，那么我们可以设计一个标签我们的Tag在信号的传输路径中间，用一个开关切换路径，一共两条，一条路径长度是一个完整波长，那么信号通过Tag的天线进入标签再出来经过了一个完整的周期，可以认为相位不变；另一条路径的长度是半个波长，同理信号进入Tag再出来相位改变了180°，与原来的信号反向。相当于我们人为的将多径的长度差变成了一个波长。</p><h2 id="WiFi-Tag调制的具体实现流程"><a href="#WiFi-Tag调制的具体实现流程" class="headerlink" title="WiFi Tag调制的具体实现流程"></a>WiFi Tag调制的具体实现流程</h2><p>假设我们的手机和WiFi路由器在进行数据交换，在一种理想的情况下我们的信号质量很好，没有丢包的情况。我们在中间加入WiFi Backscatter Tag，并且以10KHz的频率去切换开关。假设我们手机网卡发送子帧的速率也是10K个子帧每秒，那么我们可以假设在LOS（即前面说的直射路径）中传输的信号（调制了10K个子帧）的相位都是0°（相对的）。然后在有WiFi Tag的另一条路径，信号调制的10K个子帧有5K个相位为360°，有5K个相位为180°。相位为360°的跟LOS的信号叠加在一起由于同相，对原来的信号起到增强的作用，接收端全是1（参考基础知识1）而相位为180°的跟LOS的信号反向，叠加到一起刚好相互抵消了，那么接收端就是全0（理想情况）。那么我们就可以通过这个0、1之间的交替得出我们WiFi Tag要调制的信号，如下：</p><p><img src="https://github.com/allforkarina/embadded_image/blob/master/20250406065816107.png?raw=true" alt="Multiple Path"></p><hr><p>以下是，我们如何通过软件实现对上述流程的仿真以及体现。</p><h2 id="Introduction-of-environment"><a href="#Introduction-of-environment" class="headerlink" title="Introduction of environment"></a>Introduction of environment</h2><p>In this section I will briefly give a introduction of the hardware requirement, software requirement and the system environment which we based on.</p><ul><li>Firstly, we setup ubuntu 22.04 version in real PC because one of the software we used requires real NIC(Network Interface Card).</li><li>Secondly, we need a low-speed, high-frequency RFID switch which also required low power consuming. Together with a mini-mcu to control it, which means you need a energy provided method.</li><li>thirdly, you may need wireshark to get packets info at initial, then you need PicoScenes as CSI Tool to get ACK block. Also you need pktgen which is provided by Linux kernel.</li></ul><h2 id="Process-of-experiment"><a href="#Process-of-experiment" class="headerlink" title="Process of experiment"></a>Process of experiment</h2><p>Let’s start from equiping your computer with necessary software. First thing is that you need an PC with a Ubuntu system at version 22.04. Then after your configuration of basic settings, you can start from ‘Pktgen’ which is already in your system software and all you need to do is activate it using your root privacy. The detail of the overall process please follow the blog: <a href="https://blog.csdn.net/qq_41596356/article/details/134004341">How to use Pktgen-powerful Wlan test tools</a>. Notice: once you reboot your system, you need to activate the Pktgen using root privacy again.</p><p>Pktgen, used as packet genration and transmission tool, you can send packet which you configure. You then need a software to receive packet and evaluate the infomation of signal-channel through the packet you received. Here I recommend using wireshark to capture packet, and using PicoScenes to get CSI. The installation steps as followed.<br>For Wireshark, you can visit its <a href="https://github.com/wireshark/wireshark">github repository</a> and paste the command at your terminal. The second one PicoScenes, you can download it following this <a href="https://www.bing.com/search?form=QBLH&q=PicoScenes">blog</a>, or visit the <a href="https://ps.zpj.io/">official docs</a> to get to know how to install, how to use it and what is the meaning of CSI values.</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>关于博客的那些事o.O</title>
    <link href="/2025/03/18/etc/hello-world/"/>
    <url>/2025/03/18/etc/hello-world/</url>
    
    <content type="html"><![CDATA[<h1 id="Hexo-的使用指引"><a href="#Hexo-的使用指引" class="headerlink" title="Hexo 的使用指引"></a><em>Hexo</em> 的使用指引</h1><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><h1 id="如何快速入门-Markdown"><a href="#如何快速入门-Markdown" class="headerlink" title="如何快速入门 Markdown"></a>如何快速入门 <em><strong>Markdown</strong></em></h1><p><em>Markdown</em>，作为一种基于文本的快速格式化编写语法，相较于传统的文本编译器如 <em>Word</em>、<em>WPS</em> 这些基于图形化的 <em>format</em> 工具，只需要简单的几个字符便可以便可实现 <em>斜体</em>、<strong>粗体</strong>以及<code>高亮</code>等特殊 <em>format</em>。</p><p>而对比起 <em>Latex</em>，<em>Markdown</em> 虽然功能不如其强大，但是由于 <em>Latex</em> 需要更长的学习周期、繁杂的公式和文本表达式，以及较慢的编译速度，对于想快速编写 <em>blog</em> 或者 <em>diary</em> 的新手，我个人更加推荐使用 <em>Markdown</em>。下面我将带领你们快速入手 <em>Markdown</em>，让我们省去一些没用的废话，<em><strong>Let’s start it!!!</strong></em></p><h2 id="清晰分明的标题分级"><a href="#清晰分明的标题分级" class="headerlink" title="清晰分明的标题分级"></a>清晰分明的标题分级</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section"># | ## | ### | ####</span><br></code></pre></td></tr></table></figure><p>上述，便是 <em>Markdown</em> 中定义的标题分级方式，怎么样，是不是非常的简单清晰！只要你想，你可以不断地叠加<code>#</code>来实现多级标题，当然这样的结果可能只是标题比你的正文还要不起眼。</p><h2 id="强大、快捷的特殊-Format"><a href="#强大、快捷的特殊-Format" class="headerlink" title="强大、快捷的特殊 Format"></a>强大、快捷的特殊 <em>Format</em></h2><p>当你使用 <em>Word</em> 撰写一篇文章的时候，如果你想将某段文字变成粗体来起到强调的作用，你大概率会选中文字，移动你的鼠标到<code>B</code>的粗体标识上，Click一声，实现加粗的效果；如果你是高手，那么你可能会使用快捷键来加粗文字，但是在 <em>Markdown</em> 的世界里，你只需要</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-strong">**加粗的文字**</span><br></code></pre></td></tr></table></figure><p>便可以实现 <strong>加粗</strong> 的效果。</p><hr><p>同理，像 <strong>加粗</strong> 这样的方便快捷的 <em>Format</em> 还有 <em>斜体</em>、<code>代码</code>、<del>删除线</del>等等。他们分别对应的格式为</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-emphasis">_斜体_</span> | <span class="hljs-code">`代码`</span> | ~~删除线~~<br></code></pre></td></tr></table></figure><h2 id="常用的文本结构"><a href="#常用的文本结构" class="headerlink" title="常用的文本结构"></a>常用的文本结构</h2><p>这时候有人会问了，博主博主，你的文本 <em><code>format</code></em> 还是太普通了，有没有不吃操作更强大的功能？有的有的！比如，你可以快速的自定义一个列表：</p><table><thead><tr><th></th><th>col1</th><th>col2</th></tr></thead><tbody><tr><td>row1</td><td>—-</td><td>—-</td></tr><tr><td>row2</td><td>—-</td><td>—-</td></tr></tbody></table><p>像上面这个2x2的表格只需要简单的定义方式，如下</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs markdown">|      | col1 | col2 |<br>| ---- | ---- | ---- |<br>| row1 | ---- | ---- |<br>| row2 | ---- | ---- |<br></code></pre></td></tr></table></figure><p>其中的<code>| ---- | ---- | ---- |</code>，也就是第二行，作用是区分表格的内容以及每一列的Title. </p><hr><p>当然，你可结合我们上一节的特殊format来自定义你的表格，像</p><table><thead><tr><th></th><th align="left">col1</th><th align="left">col2</th></tr></thead><tbody><tr><td>row1</td><td align="left"><code>code</code></td><td align="left"><em>Italic</em></td></tr><tr><td>row2</td><td align="left"><strong>Bold</strong></td><td align="left"><del>Dele</del></td></tr></tbody></table><hr><p>或许你正在尝试编写一个技术性的博客，你对如何将源码展示开源而感到头痛。直接复制粘贴，格式不对，不够优美；截图呢，虽然有高亮，但是没有办法<code>ctrl + c\v</code>. 对此，我强烈建议你使用 <em>Markdonw</em> 的代码块Structure</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">$ <span class="hljs-code">``` (language)</span><br><span class="hljs-code">(Warning: $ 只是用于防止代码块在我定义的markdown代码块中生效，实际使用只需要上下用```</span>标注这是一个代码块即可生效)    <br>$ <span class="hljs-code">```</span><br></code></pre></td></tr></table></figure><p>括号内的Language表示，<em>Markdown</em> 的代码块支持多种不同的语言，像python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.random.randn(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure><hr><p>或者你需要一个<code>TODO List</code>来帮助你管理你的事项，那么你可能需要使用到列表。</p><p><em>Markdown</em> 支持多种不同的列表，例如数字列表：</p><ol><li>This is the first list.</li><li>This is the second list</li></ol><p>又或者是点列表：</p><ul><li>list here.</li><li>list here.</li></ul><h2 id="特殊的玩法"><a href="#特殊的玩法" class="headerlink" title="特殊的玩法"></a>特殊的玩法</h2><p><em>Markdown</em> 不仅仅是提供一个方便快捷的文本编辑方式，它还有一些特殊的使用方法来装点你的Markdown文本。</p><ul><li><em><strong>Emoji</strong></em>：✅、😶‍🌫️ etc.</li></ul><hr><p>以上就是比较常用的Markdown使用格式，希望这个指引能够对你有帮助。</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
