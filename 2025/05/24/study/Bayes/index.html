

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/avatar.png">
  <link rel="icon" href="/img/avatar.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Karina">
  <meta name="keywords" content="">
  
    <meta name="description" content="最小错误率贝叶斯决策分类器实战：代码解析与理论详解一、背景与应用场景贝叶斯决策分类器是一种基于**贝叶斯定理**的统计分类方法，其核心思想是通过最大化后验概率来最小化分类错误率。该方法广泛应用于医学诊断、金融风控等场景，尤其适合特征分布符合正态分布的小规模数据集。本文以鸢尾花（Iris）数据集为例，详解如何实现一个基于贝叶斯决策的分类器 。   二、核心代码解析1. 数据准备与划分12from s">
<meta property="og:type" content="article">
<meta property="og:title" content="基于贝叶斯决策的分类器">
<meta property="og:url" content="http://example.com/2025/05/24/study/Bayes/index.html">
<meta property="og:site_name" content="Katarina&#39;s daily record">
<meta property="og:description" content="最小错误率贝叶斯决策分类器实战：代码解析与理论详解一、背景与应用场景贝叶斯决策分类器是一种基于**贝叶斯定理**的统计分类方法，其核心思想是通过最大化后验概率来最小化分类错误率。该方法广泛应用于医学诊断、金融风控等场景，尤其适合特征分布符合正态分布的小规模数据集。本文以鸢尾花（Iris）数据集为例，详解如何实现一个基于贝叶斯决策的分类器 。   二、核心代码解析1. 数据准备与划分12from s">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_02.png">
<meta property="og:image" content="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_03.png">
<meta property="og:image" content="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_01.png">
<meta property="article:published_time" content="2025-05-23T23:00:00.000Z">
<meta property="article:modified_time" content="2025-05-23T23:45:54.369Z">
<meta property="article:author" content="Karina">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_02.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>基于贝叶斯决策的分类器 - Katarina&#39;s daily record</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.16.2/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/custom_css.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":60,"cursorChar":"_","loop":true,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>(♥ ω ♥) Karina</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/desktop.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="基于贝叶斯决策的分类器"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-05-24 07:00" pubdate>
          May 24, 2025 am
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.6k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          46 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">基于贝叶斯决策的分类器</h1>
            
              <p id="updated-time" class="note note-info" style="">
                
                  
                    Last updated on May 24, 2025 am
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h1 id="最小错误率贝叶斯决策分类器实战：代码解析与理论详解"><a href="#最小错误率贝叶斯决策分类器实战：代码解析与理论详解" class="headerlink" title="最小错误率贝叶斯决策分类器实战：代码解析与理论详解"></a>最小错误率贝叶斯决策分类器实战：代码解析与理论详解</h1><h2 id="一、背景与应用场景"><a href="#一、背景与应用场景" class="headerlink" title="一、背景与应用场景"></a>一、背景与应用场景</h2><p>贝叶斯决策分类器是一种基于**贝叶斯定理**的统计分类方法，其核心思想是通过最大化后验概率来最小化分类错误率。该方法广泛应用于医学诊断、金融风控等场景，尤其适合特征分布符合正态分布的小规模数据集。本文以鸢尾花（Iris）数据集为例，详解如何实现一个基于贝叶斯决策的分类器 。  </p>
<h2 id="二、核心代码解析"><a href="#二、核心代码解析" class="headerlink" title="二、核心代码解析"></a>二、核心代码解析</h2><h2 id="1-数据准备与划分"><a href="#1-数据准备与划分" class="headerlink" title="1. 数据准备与划分"></a>1. 数据准备与划分</h2><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-type">X</span>, y = datasets.load_iris().<span class="hljs-class"><span class="hljs-keyword">data</span>, datasets.load_iris().target</span><br></code></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：加载鸢尾花数据集，包含4个特征（花萼&#x2F;花瓣长度和宽度）和3个类别（Setosa, Versicolor, Virginica）。   </li>
<li><strong>理论基础</strong>：数据集需满足<strong>独立同分布</strong>假设，即样本间相互独立且特征分布一致 。</li>
</ul>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">X_train, X_test, y_train, y_test = train_test_split(X, y, <span class="hljs-attribute">test_size</span>=0.3, <span class="hljs-attribute">random_state</span>=42)<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：按7:3比例划分训练集和测试集，<code>random\_state</code>确保实验可复现 。</li>
</ul>
<hr>
<h3 id="2-先验概率与类别条件概率估计"><a href="#2-先验概率与类别条件概率估计" class="headerlink" title="2. 先验概率与类别条件概率估计"></a>2. 先验概率与类别条件概率估计</h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">class_counts</span> = np.bincount(y_train)<br><span class="hljs-attr">priors</span> = class_counts / len(y_train)<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>原理</strong>：先验概率 $ P(Y) $ 反映类别在训练集中的分布比例。例如，若某类别占30%样本，则 $ P(Y&#x3D;\text{class}) &#x3D; 0.3 $ 。</li>
</ul>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros">class_conditional_probs = []<br><span class="hljs-keyword">for</span> class_idx <span class="hljs-keyword">in</span> range(3):<br>    class_data = X_train[y_train == class_idx]<br>    class_mean = np.mean(class_data, <span class="hljs-attribute">axis</span>=0)<br>    class_cov = np.cov(class_data, <span class="hljs-attribute">rowvar</span>=<span class="hljs-literal">False</span>)<br>    class_conditional_probs.append(multivariate_normal(<span class="hljs-attribute">mean</span>=class_mean, <span class="hljs-attribute">cov</span>=class_cov))<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>关键步骤</strong>：   <ol>
<li><strong>类别条件概率建模</strong>：假设每个类别的特征服从多元正态分布，通过均值向量（<code>class\_mean</code>）和协方差矩阵（<code>class\_cov</code>）描述分布特性。   </li>
<li><strong>参数估计</strong>：使用最大似然估计（MLE）计算均值和协方差矩阵，这是参数化方法的核心 。</li>
</ol>
</li>
</ul>
<hr>
<h3 id="3-贝叶斯决策分类器实现"><a href="#3-贝叶斯决策分类器实现" class="headerlink" title="3. 贝叶斯决策分类器实现"></a>3. 贝叶斯决策分类器实现</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MinimumErrorRateBayesianDecision</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">classify</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, features</span>):<br>        posterior_probs = [<span class="hljs-variable language_">self</span>.priors[i] * prob.pdf(features) <span class="hljs-keyword">for</span> i, prob <span class="hljs-keyword">in</span> enumerate(<span class="hljs-variable language_">self</span>.class_conditional_probs)]<br>        <span class="hljs-keyword">return</span> np.argmax(posterior_probs)<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>决策逻辑</strong>：   <ul>
<li><strong>后验概率计算</strong>：根据贝叶斯公式 $ P(Y|X) \propto P(Y) \cdot P(X|Y) $，计算每个类别的后验概率。   </li>
<li><strong>最小错误率决策</strong>：选择后验概率最大的类别作为预测结果，此决策规则理论上最小化分类错误率 。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-模型评估"><a href="#4-模型评估" class="headerlink" title="4. 模型评估"></a>4. 模型评估</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs stylus">correct_predictions = <span class="hljs-number">0</span><br>class_correct_predictions = <span class="hljs-selector-attr">[0]</span>*<span class="hljs-number">3</span><br>class_total_samples = <span class="hljs-selector-attr">[0]</span>*<span class="hljs-number">3</span><br><br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(X_test)):<br>    predicted_class = classifier<span class="hljs-selector-class">.classify</span>(X_test<span class="hljs-selector-attr">[i]</span>)<br>    class_total_samples<span class="hljs-selector-attr">[y_test[i]</span>] += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> predicted_class == y_test<span class="hljs-selector-attr">[i]</span>:<br>        correct_predictions += <span class="hljs-number">1</span><br>        class_correct_predictions<span class="hljs-selector-attr">[y_test[i]</span>] += <span class="hljs-number">1</span><br><br>accuracy = correct_predictions / <span class="hljs-built_in">len</span>(X_test)<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>评估指标</strong>：计算整体准确率和类别级别的准确率，验证分类器性能 。</li>
</ul>
<hr>
<h2 id="三、数学原理详解"><a href="#三、数学原理详解" class="headerlink" title="三、数学原理详解"></a>三、数学原理详解</h2><h3 id="1-贝叶斯定理"><a href="#1-贝叶斯定理" class="headerlink" title="1. 贝叶斯定理"></a>1. 贝叶斯定理</h3><p>贝叶斯公式定义为：<br>$$<br>P(Y|X) &#x3D; \frac{P(X|Y) \cdot P(Y)}{P(X)}<br>$$   </p>
<ul>
<li><strong>先验概率</strong> $ P(Y) $：类别在训练集中的分布比例。   </li>
<li><strong>似然</strong> $ P(X|Y) $：类别条件概率密度，通过多元正态分布建模。   </li>
<li><strong>证据</strong> $ P(X) $：常数项（对所有类别相同），不影响比较后验概率大小 。</li>
</ul>
<h3 id="2-多元正态分布假设"><a href="#2-多元正态分布假设" class="headerlink" title="2. 多元正态分布假设"></a>2. 多元正态分布假设</h3><p>假设特征向量 $ X \sim \mathcal{N}(\mu, \Sigma) $，其概率密度函数为：<br>$$<br>f(X) &#x3D; \frac{1}{\sqrt{(2\pi)^k |\Sigma|}} \exp\left( -\frac{1}{2}(X-\mu)^T \Sigma^{-1}(X-\mu) \right)<br>$$   </p>
<ul>
<li><strong>均值向量</strong> $ \mu $：反映特征的集中趋势。   </li>
<li><strong>协方差矩阵</strong> $ \Sigma $：描述特征间的相关性 。</li>
</ul>
<h3 id="3-决策边界"><a href="#3-决策边界" class="headerlink" title="3. 决策边界"></a>3. 决策边界</h3><h2 id="当两类的后验概率相等时，即：-P-Y-1-cdot-P-X-Y-1-P-Y-2-cdot-P-X-Y-2-此时对应的超平面即为决策边界，用于划分不同类别的样本空间-。"><a href="#当两类的后验概率相等时，即：-P-Y-1-cdot-P-X-Y-1-P-Y-2-cdot-P-X-Y-2-此时对应的超平面即为决策边界，用于划分不同类别的样本空间-。" class="headerlink" title="当两类的后验概率相等时，即：$$P(Y_1) \cdot P(X|Y_1) &#x3D; P(Y_2) \cdot P(X|Y_2)$$此时对应的超平面即为决策边界，用于划分不同类别的样本空间 。   "></a>当两类的后验概率相等时，即：<br>$$<br>P(Y_1) \cdot P(X|Y_1) &#x3D; P(Y_2) \cdot P(X|Y_2)<br>$$<br>此时对应的超平面即为决策边界，用于划分不同类别的样本空间 。   </h2><h2 id="四、实验结果与分析"><a href="#四、实验结果与分析" class="headerlink" title="四、实验结果与分析"></a>四、实验结果与分析</h2><h3 id="1-分类准确率"><a href="#1-分类准确率" class="headerlink" title="1. 分类准确率"></a>1. 分类准确率</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 输出示例（实际运行结果可能不同）</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Setosa准确率: 1.0&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Versicolor准确率: 0.93&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;整体准确率: 0.95&quot;</span>)<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>结果分析</strong>：模型在测试集上表现优异，尤其对Setosa类别实现完美分类，表明正态分布假设在该数据集上成立 。</li>
</ul>
<h3 id="2-可视化决策边界"><a href="#2-可视化决策边界" class="headerlink" title="2. 可视化决策边界"></a>2. 可视化决策边界</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import matplotlib<span class="hljs-selector-class">.pyplot</span> as plt<br>plt<span class="hljs-selector-class">.scatter</span>(X_test<span class="hljs-selector-attr">[:, 0]</span>, X_test<span class="hljs-selector-attr">[:, 1]</span>, c=y_test, cmap=<span class="hljs-string">&#x27;viridis&#x27;</span>)<br>plt<span class="hljs-selector-class">.xlabel</span>(<span class="hljs-string">&quot;Sepal Length&quot;</span>)<br>plt<span class="hljs-selector-class">.ylabel</span>(<span class="hljs-string">&quot;Sepal Width&quot;</span>)<br>plt<span class="hljs-selector-class">.title</span>(<span class="hljs-string">&quot;Bayesian Decision Boundary&quot;</span>)<br>plt<span class="hljs-selector-class">.colorbar</span>(label=<span class="hljs-string">&quot;Class&quot;</span>)<br>plt<span class="hljs-selector-class">.show</span>()<br><br></code></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_02.png" srcset="/img/loading.gif" lazyload alt="Agglomerative Clustering"><br><em>图2：基于贝叶斯决策的分类边界可视化（示例）</em>   </p>
<hr>
<h2 id="五、总结与扩展"><a href="#五、总结与扩展" class="headerlink" title="五、总结与扩展"></a>五、总结与扩展</h2><h3 id="1-优势与局限性"><a href="#1-优势与局限性" class="headerlink" title="1. 优势与局限性"></a>1. 优势与局限性</h3><ul>
<li><strong>优势</strong>：   <ul>
<li>理论基础扎实，适用于小规模数据。   </li>
<li>通过参数估计可解释性强 。</li>
</ul>
</li>
<li><strong>局限性</strong>：   <ul>
<li>依赖正态分布假设，若实际数据分布偏离较大可能导致性能下降。   </li>
<li>协方差矩阵可能因样本不足而奇异，需正则化处理 。</li>
</ul>
</li>
</ul>
<h3 id="2-改进方向"><a href="#2-改进方向" class="headerlink" title="2. 改进方向"></a>2. 改进方向</h3><ul>
<li><strong>非参数化方法</strong>：使用核密度估计替代正态分布假设。   </li>
<li><strong>正则化技术</strong>：在协方差矩阵中加入微小扰动（如 <code>class\_cov += 1e-6 \* np.eye(dim)</code>）防止奇异 。</li>
</ul>
<blockquote>
<p>完整代码仓库：[GitHub链接]   </p>
</blockquote>
<h1 id="🎃-朴素贝叶斯实现决策分类"><a href="#🎃-朴素贝叶斯实现决策分类" class="headerlink" title="🎃 朴素贝叶斯实现决策分类"></a>🎃 朴素贝叶斯实现决策分类</h1><h3 id="1-导入库"><a href="#1-导入库" class="headerlink" title="1. 导入库"></a>1. 导入库</h3><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_classification <br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt <br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：导入所需的库。   <ul>
<li><code>make\_classification</code>：用于生成合成的分类数据集 。   </li>
<li><code>matplotlib.pyplot</code>：用于可视化结果。   </li>
<li><code>numpy</code>：进行数值计算。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-定义高斯概率密度函数"><a href="#2-定义高斯概率密度函数" class="headerlink" title="2. 定义高斯概率密度函数"></a>2. 定义高斯概率密度函数</h3><figure class="highlight gml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gml">def gaussian_pdf(<span class="hljs-variable language_">x</span>, <span class="hljs-built_in">mean</span>, std_dev): <br>    <span class="hljs-keyword">return</span> (<span class="hljs-number">1</span> / (np.<span class="hljs-built_in">sqrt</span>(<span class="hljs-number">2</span> * np.<span class="hljs-symbol">pi</span>) * std_dev)) * np.<span class="hljs-built_in">exp</span>(<span class="hljs-number">-0.5</span> * ((<span class="hljs-variable language_">x</span> - <span class="hljs-built_in">mean</span>) / std_dev)**<span class="hljs-number">2</span>) <br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：计算单个特征值在高斯分布下的概率密度。   </li>
<li><strong>公式解释</strong>：</li>
</ul>
<p>高斯分布（正态分布）的概率密度函数公式为：<br>$$<br>f(x) &#x3D; \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}}<br>$$<br>其中 <code>mean</code> 是均值 $ \mu $，<code>std\_dev</code> 是标准差 $ \sigma $。   </p>
<ul>
<li><strong>应用场景</strong>：在朴素贝叶斯分类器中，假设每个特征在给定类别下服从高斯分布。</li>
</ul>
<hr>
<h3 id="3-自定义数据集划分函数"><a href="#3-自定义数据集划分函数" class="headerlink" title="3. 自定义数据集划分函数"></a>3. 自定义数据集划分函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_test_split</span>(<span class="hljs-params">X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-literal">None</span></span>): <br>    <span class="hljs-keyword">if</span> random_state <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>: <br>        np.random.seed(random_state)    <br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：将数据集划分为训练集和测试集。   </li>
<li><strong>参数说明</strong>：   <ul>
<li><code>X</code>：特征数据。   </li>
<li><code>y</code>：目标标签。   </li>
<li><code>test\_size</code>：测试集比例（默认 20%）。   </li>
<li><code>random\_state</code>：随机种子，确保结果可复现 。</li>
</ul>
</li>
<li><strong>实现逻辑</strong>：   <ul>
<li>使用 <code>np.random.permutation</code> 打乱数据索引。   </li>
<li>按比例划分测试集和训练集。</li>
</ul>
</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">m</span> = X.shape[<span class="hljs-number">0</span>]                              <span class="hljs-comment"># 获取数据集的大小 </span><br><span class="hljs-attr">permutation</span> = np.random.permutation(m)      <span class="hljs-comment"># 随机生成打乱的数组 对应为打乱的索引</span><br><span class="hljs-attr">test_size</span> = int(m * test_size)              <span class="hljs-comment"># 计算测试集的大小 </span><br><span class="hljs-attr">test_indices</span> = permutation[:test_size]      <span class="hljs-comment"># 取test_size个打乱的索引</span><br><span class="hljs-attr">train_indices</span> = permutation[test_size:]     <span class="hljs-comment"># 取后面所有索引作为训练集    </span><br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>关键步骤</strong>：   <ul>
<li><code>X.shape[0]</code>：获取样本总数。   </li>
<li><code>permutation</code>：生成随机索引。   </li>
<li><code>test\_indices</code>：前 <code>test\_size</code> 个索引作为测试集。   </li>
<li><code>train\_indices</code>：剩余索引作为训练集。</li>
</ul>
</li>
</ul>
<figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs inform7">X_train = X<span class="hljs-comment">[train_indices]</span> <br>X_test = X<span class="hljs-comment">[test_indices]</span> <br>y_train = y<span class="hljs-comment">[train_indices]</span> <br>y_test = y<span class="hljs-comment">[test_indices]</span> <br> <br>return X_train, X_test, y_train, y_test <br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>输出</strong>：返回划分后的训练集和测试集。</li>
</ul>
<hr>
<h3 id="4-贝叶斯分类器的预测函数"><a href="#4-贝叶斯分类器的预测函数" class="headerlink" title="4. 贝叶斯分类器的预测函数"></a>4. 贝叶斯分类器的预测函数</h3><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs scss">def <span class="hljs-built_in">predict_bayes</span>(x, means, variances, priors): <br>    posteriors = [] <br>    for i in <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(means)): <br>        likelihood = np.<span class="hljs-built_in">prod</span>(<span class="hljs-built_in">gaussian_pdf</span>(x, means[i], np.<span class="hljs-built_in">sqrt</span>(variances[i])))      <br>        posterior = likelihood * priors[i]                                          <br>        posteriors.<span class="hljs-built_in">append</span>(posterior)                                                <br>    return np.<span class="hljs-built_in">argmax</span>(posteriors) <br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：基于朴素贝叶斯算法预测样本类别。   </li>
<li><strong>步骤解析</strong>：   <ol>
<li><strong>似然计算</strong>：对每个特征计算高斯概率密度，并通过 <code>np.prod</code> 连乘得到联合概率（假设特征条件独立）。   </li>
<li><strong>后验概率</strong>：似然乘以先验概率 <code>priors[i]</code>。   </li>
<li><strong>分类决策</strong>：选择后验概率最大的类别作为预测结果（<code>np.argmax</code>）。</li>
</ol>
</li>
</ul>
<hr>
<h3 id="5-生成合成数据集"><a href="#5-生成合成数据集" class="headerlink" title="5. 生成合成数据集"></a>5. 生成合成数据集</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">X, y = make_classification(<span class="hljs-attribute">n_samples</span>=1500, <span class="hljs-attribute">n_features</span>=2, <br>                            <span class="hljs-attribute">n_informative</span>=2, <span class="hljs-attribute">n_redundant</span>=0,  <br>                            <span class="hljs-attribute">n_clusters_per_class</span>=1, <span class="hljs-attribute">random_state</span>=6) <br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：生成一个二维二分类数据集。   </li>
<li><strong>参数解释</strong>：   <ul>
<li><code>n\_samples=1500</code>：生成 1500 个样本。   </li>
<li><code>n\_features=2</code>：每个样本有 2 个特征（x1, x2）。   </li>
<li><code>n\_informative=2</code>：两个特征均为信息性特征（用于分类）。   </li>
<li><code>n\_redundant=0</code>：无冗余特征。   </li>
<li><code>n\_clusters\_per\_class=1</code>：每个类别有 1 个聚类中心。   </li>
<li><code>random\_state=6</code>：确保数据生成可复现 。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="6-数据集划分"><a href="#6-数据集划分" class="headerlink" title="6. 数据集划分"></a>6. 数据集划分</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">X_train, X_test, y_train, y_test = train_test_split(X, y, <span class="hljs-attribute">test_size</span>=0.2, <span class="hljs-attribute">random_state</span>=2)<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：将数据集按 80%&#x2F;20% 划分为训练集和测试集。</li>
</ul>
<hr>
<h3 id="7-计算类别均值和方差"><a href="#7-计算类别均值和方差" class="headerlink" title="7. 计算类别均值和方差"></a>7. 计算类别均值和方差</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs maxima">unique_classes = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">unique</span>(y_train) <br><br>means = []          <br>variances = []      <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> unique_classes: <br>    X_train_class_i = X_train[y_train == i]                 <br>    mean_class_i = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">mean</span>(X_train_class_i, axis=<span class="hljs-number">0</span>)         <br>    variance_class_i = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">var</span>(X_train_class_i, axis=<span class="hljs-number">0</span>)     <br>    means.<span class="hljs-built_in">append</span>(mean_class_i) <br>    variances.<span class="hljs-built_in">append</span>(variance_class_i) <br> <br>means = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>(means) <br>variances = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>(variances) <br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：对每个类别计算特征的均值和方差。   </li>
<li><strong>关键点</strong>：   <ul>
<li><code>np.unique(y\_train)</code>：获取训练集中所有类别标签。   </li>
<li><code>X\_train[y\_train == i]</code>：筛选当前类别的样本。   </li>
<li><code>np.mean</code> 和 <code>np.var</code>：计算均值和方差。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="8-计算先验概率"><a href="#8-计算先验概率" class="headerlink" title="8. 计算先验概率"></a>8. 计算先验概率</h3><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">priors</span> <span class="hljs-operator">=</span> [np.mean(y_train <span class="hljs-operator">=</span><span class="hljs-operator">=</span> i) for i in np.unique(y_train)] <br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：计算每个类别的先验概率 $ P(Y) $。   </li>
<li><strong>实现原理</strong>：</li>
</ul>
<h2 id="对于布尔数组-y-train-i，np-mean-返回-True（即类别-i-的样本）的比例。"><a href="#对于布尔数组-y-train-i，np-mean-返回-True（即类别-i-的样本）的比例。" class="headerlink" title="对于布尔数组 y\_train == i，np.mean 返回 True（即类别 i 的样本）的比例。   "></a>对于布尔数组 <code>y\_train == i</code>，<code>np.mean</code> 返回 <code>True</code>（即类别 i 的样本）的比例。   </h2><h3 id="9-预测与评估"><a href="#9-预测与评估" class="headerlink" title="9. 预测与评估"></a>9. 预测与评估</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">y_pred = <span class="hljs-selector-attr">[predict_bayes(x, means, variances, priors) for x in X_test]</span> <br>correct = np<span class="hljs-selector-class">.sum</span>(y_pred == y_test) / <span class="hljs-built_in">len</span>(y_test)                            <br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;Accuracy: &#123;:.2f&#125;%&quot;</span>.format(correct * <span class="hljs-number">100</span>)</span></span>) <br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：   <ul>
<li>对测试集逐样本预测类别。   </li>
<li>计算准确率：预测正确的样本数占总样本数的比例。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="10-可视化结果"><a href="#10-可视化结果" class="headerlink" title="10. 可视化结果"></a>10. 可视化结果</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs stylus">plt<span class="hljs-selector-class">.figure</span>(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>))<br>scatter_true = plt<span class="hljs-selector-class">.scatter</span>(X_test<span class="hljs-selector-attr">[:, 0]</span>, X_test<span class="hljs-selector-attr">[:, 1]</span>, c=y_test,  <br>                           s=<span class="hljs-number">30</span>, cmap=<span class="hljs-string">&#x27;coolwarm&#x27;</span>,label=<span class="hljs-string">&#x27;True class&#x27;</span>) <br>scatter_pred = plt<span class="hljs-selector-class">.scatter</span>(X_test<span class="hljs-selector-attr">[:, 0]</span>, X_test<span class="hljs-selector-attr">[:, 1]</span>, s=<span class="hljs-number">30</span>,  <br>                           facecolors=<span class="hljs-string">&#x27;none&#x27;</span>,  <br>                           edgecolors=np<span class="hljs-selector-class">.array</span>(<span class="hljs-selector-attr">[<span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>]</span>)<span class="hljs-selector-attr">[y_pred]</span>, <br>                           <span class="hljs-selector-tag">label</span> = <span class="hljs-string">&#x27;Predicted class&#x27;</span>) <br>plt<span class="hljs-selector-class">.legend</span>(handles=<span class="hljs-selector-attr">[scatter_true, scatter_pred]</span>) <br>plt<span class="hljs-selector-class">.show</span>()<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：可视化测试集的真实标签和预测结果。   </li>
<li><strong>图形说明</strong>：   <ul>
<li><code>c=y\_test</code>：颜色表示真实类别（红&#x2F;蓝）。   </li>
<li><code>edgecolors=np.array([&#39;b&#39;, &#39;r&#39;])[y\_pred]</code>：边缘颜色表示预测类别。   </li>
<li><code>facecolors=&#39;none&#39;</code>：仅显示边缘，便于对比预测与真实标签。</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_03.png" srcset="/img/loading.gif" lazyload alt="Accuracy&#x3D;95%"> </p>
<hr>
<h3 id="关键知识点总结"><a href="#关键知识点总结" class="headerlink" title="关键知识点总结"></a>关键知识点总结</h3><ol>
<li><strong>朴素贝叶斯假设</strong>：特征之间条件独立，通过连乘计算联合概率 。   </li>
<li><strong>高斯分布建模</strong>：假设每个特征在给定类别下服从正态分布。   </li>
<li><strong>先验概率估计</strong>：通过训练集中类别的频率计算 $ P(Y) $。   </li>
<li><strong>决策规则</strong>：最大化后验概率 $ P(Y|X) \propto P(X|Y)P(Y) $。</li>
</ol>
<hr>
<h1 id="核函数估计概率密度函数的朴素贝叶斯"><a href="#核函数估计概率密度函数的朴素贝叶斯" class="headerlink" title="核函数估计概率密度函数的朴素贝叶斯"></a>核函数估计概率密度函数的朴素贝叶斯</h1><h3 id="1-predict-bayes-函数：基于损失矩阵的贝叶斯决策"><a href="#1-predict-bayes-函数：基于损失矩阵的贝叶斯决策" class="headerlink" title="1. predict_bayes 函数：基于损失矩阵的贝叶斯决策"></a>1. predict_bayes 函数：基于损失矩阵的贝叶斯决策</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_bayes</span>(<span class="hljs-params">x, parzen_estimations, priors, loss_matrix</span>): <br>    expected_losses = []                                        <span class="hljs-comment"># 初始化期望损失列表 </span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(parzen_estimations)): <br>        expected_loss = <span class="hljs-number">0</span>                                       <span class="hljs-comment"># 初始化期望损失 </span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(parzen_estimations)): <br>            posterior = priors[i] * parzen_estimations[i]       <span class="hljs-comment"># 计算后验概率     </span><br>            expected_loss += loss_matrix[i][j] * posterior      <span class="hljs-comment"># 计算期望损失 </span><br>        expected_losses.append(expected_loss)                   <span class="hljs-comment"># 将期望损失添加到列表中 </span><br>    <span class="hljs-keyword">return</span> np.argmin(expected_losses, axis=<span class="hljs-number">0</span>)                   <span class="hljs-comment"># 返回期望损失最小的类别作为预测结果</span><br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：根据<strong>期望损失最小化</strong>原则，将输入样本 <code>x</code> 分类到某个类别。   </li>
<li><strong>关键步骤解析</strong>：   <ol>
<li><strong>后验概率计算</strong>：    <figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">posterior</span> <span class="hljs-operator">=</span> priors[i] * parzen_estimations[i]<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>公式</strong>：</li>
</ul>
</li>
</ol>
<ul>
<li><strong>理论依据</strong>：贝叶斯定理 $ P(Y|X) &#x3D; \frac{P(Y) \cdot P(X|Y)}{P(X)} $，分母 $ P(X) $ 对所有类别相同，可忽略 。</li>
</ul>
</li>
</ul>
<ol>
<li><strong>期望损失计算</strong>：    <figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">expected_loss += loss_matrix<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span> * posterior<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>公式</strong>：</li>
</ul>
</li>
</ol>
<ul>
<li><strong>理论依据</strong>：贝叶斯决策的目标是最小化<strong>条件风险</strong>（即期望损失），而非单纯最大化后验概率 。</li>
</ul>
<ol start="2">
<li><strong>决策规则</strong>：    <figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs kotlin"><span class="hljs-keyword">return</span> np.argmin(expected_losses, axis=<span class="hljs-number">0</span>)<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>解释</strong>：选择期望损失最小的类别 <code>j</code> 作为预测结果，而非直接选择后验概率最大的类别。   </li>
<li><strong>对比普通贝叶斯</strong>：普通朴素贝叶斯仅比较后验概率（即损失矩阵为单位矩阵时的情况），而此代码通过自定义 <code>loss\_matrix</code> 实现<strong>风险敏感决策</strong> 。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="2-Parzen窗口估计：非参数概率密度估计"><a href="#2-Parzen窗口估计：非参数概率密度估计" class="headerlink" title="2. Parzen窗口估计：非参数概率密度估计"></a>2. Parzen窗口估计：非参数概率密度估计</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell">def parzen_window_estimation(x, <span class="hljs-keyword">data</span>, <span class="hljs-built_in">h</span>=<span class="hljs-number">1</span>, window_func=squ_window): <br>    N, d = data.shape                           <span class="hljs-comment"># 获取数据的数量和维度</span><br>    k_n = window_func(cdist(x, <span class="hljs-keyword">data</span>) / <span class="hljs-built_in">h</span>)       <span class="hljs-comment"># 计算每个样本到x的距离并应用窗口函数限制权重</span><br>    <span class="hljs-keyword">return</span> np.sum(k_n, axis=<span class="hljs-number">1</span>) / (N * <span class="hljs-built_in">h</span>**d)     <span class="hljs-comment"># 返回Parzen窗口估计的结果 shape=[N, ] h是窗大小</span><br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：通过Parzen窗口法估计样本 <code>x</code> 的概率密度。   </li>
<li><strong>关键步骤解析</strong>：   <ol>
<li><strong>距离计算</strong>：    <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">cdist</span><span class="hljs-params">(x, data)</span></span> / h<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：计算测试样本 <code>x</code> 与所有训练样本 <code>data</code> 的欧氏距离，并除以带宽 <code>h</code> 进行归一化。   </li>
<li><strong>理论依据</strong>：Parzen窗口是一种非参数密度估计方法，通过核函数（窗口函数）加权邻域内的样本点 。</li>
</ul>
</li>
<li><strong>窗口函数应用</strong>：    <figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-function"><span class="hljs-title">window_func</span>(<span class="hljs-params">...</span>)</span><br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>窗口函数类型</strong>：   <ul>
<li><strong>方窗</strong>（<code>squ\_window</code>）：仅统计距离在 <code>[-h/2, h/2]</code> 内的样本。   </li>
<li><strong>正态窗</strong>（<code>nor\_window</code>）：使用高斯分布权重（权重随距离指数衰减）。   </li>
<li><strong>指数窗</strong>（<code>exp\_window</code>）：权重随距离线性衰减。   </li>
<li><strong>三角窗</strong>（<code>tri\_window</code>）：权重随距离线性衰减至零。</li>
</ul>
</li>
<li><strong>理论依据</strong>：不同窗口函数对密度估计的平滑性有影响，正态窗适合连续分布，方窗适合离散分布 。</li>
</ul>
</li>
<li><strong>密度估计值</strong>：    <figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lasso">np.<span class="hljs-keyword">sum</span>(<span class="hljs-params">...</span>) / (N * h**d)<br><br></code></pre></td></tr></table></figure>
<ul>
<li><strong>公式</strong>：</li>
</ul>
</li>
</ol>
<ul>
<li><strong>理论依据</strong>：Parzen窗口通过核密度估计逼近真实分布，无需假设数据服从特定分布 。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-代码整体流程与贝叶斯决策的关系"><a href="#3-代码整体流程与贝叶斯决策的关系" class="headerlink" title="3. 代码整体流程与贝叶斯决策的关系"></a>3. 代码整体流程与贝叶斯决策的关系</h3><ol>
<li><strong>训练阶段</strong>：   <ul>
<li>对每个类别 <code>i</code>，使用训练数据 <code>X\_train[y\_train == i]</code> 计算 Parzen 窗口密度估计 <code>parzen\_estimations[i]</code>。   </li>
<li>计算每个类别的先验概率 <code>priors[i] = P(Y=i)</code>。</li>
</ul>
</li>
<li><strong>预测阶段</strong>：   <ul>
<li>对每个测试样本 <code>x</code>：   <ul>
<li>使用 Parzen 窗口法计算其在每个类别下的概率密度 <code>parzen\_estimations</code>。   </li>
<li>结合先验概率和损失矩阵，计算每个可能决策的期望损失。   </li>
<li>选择期望损失最小的类别作为预测结果。</li>
</ul>
</li>
</ul>
</li>
<li><strong>与普通朴素贝叶斯的区别</strong>：   <ul>
<li><strong>普通朴素贝叶斯</strong>：假设特征服从特定分布（如高斯分布），且特征条件独立，直接计算后验概率。   </li>
<li><strong>本代码实现</strong>：   <ul>
<li>使用非参数方法（Parzen窗口）估计概率密度，无需假设分布形式。   </li>
<li>引入损失矩阵，允许自定义误分类代价（如医疗诊断中误诊癌症的代价更高）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="4-关键参数的作用"><a href="#4-关键参数的作用" class="headerlink" title="4. 关键参数的作用"></a>4. 关键参数的作用</h3><ul>
<li>带宽 <code>**h**</code>：   <ul>
<li><code>h</code> 越大，密度估计越平滑（可能欠拟合），<code>h</code> 越小，密度估计越尖锐（可能过拟合）。</li>
</ul>
</li>
<li><strong>窗口函数</strong>：   <ul>
<li>方窗（<code>squ\_window</code>）适合离散分布，正态窗（<code>nor\_window</code>）适合连续分布。</li>
</ul>
</li>
<li>损失矩阵 <code>**loss\_matrix**</code>：   <ul>
<li>单位矩阵（<code>[[0,1],[1,0]]</code>）对应最小错误率决策，非单位矩阵对应最小风险决策 。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="5-示例说明"><a href="#5-示例说明" class="headerlink" title="5. 示例说明"></a>5. 示例说明</h3><p>假设 <code>loss\_matrix = [[0, 2], [1, 0]]</code>：   </p>
<ul>
<li>将实际类别为 0 的样本误判为 1 的代价是 2，而将实际类别为 1 的样本误判为 0 的代价是 1。   </li>
<li>分类器会更倾向于避免将类别 0 误判为 1，从而在代价敏感场景下优化决策 。</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><strong>核心思想</strong>：通过非参数密度估计（Parzen窗口）和风险最小化（损失矩阵）实现灵活的贝叶斯决策。   </li>
<li><strong>适用场景</strong>：   <ul>
<li>数据分布未知或非高斯分布。   </li>
<li>不同类别的误分类代价不一致（如医疗、金融风控）。</li>
</ul>
</li>
<li><strong>改进方向</strong>：   <ul>
<li>使用交叉验证选择最优带宽 <code>h</code>。   </li>
<li>替换更复杂的核函数（如高斯混合核）。</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_01.png" srcset="/img/loading.gif" lazyload alt="Accuracy&#x3D;97%"></p>
<p>➡️ 通过加窗以及损失矩阵补偿错误判断，可以发现对于同一个数据在分类的正确性上有一定的增强；   </p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/ML/" class="print-no-link">#ML</a>
      
        <a href="/tags/Python/" class="print-no-link">#Python</a>
      
        <a href="/tags/Deep-Learning/" class="print-no-link">#Deep Learning</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>基于贝叶斯决策的分类器</div>
      <div>http://example.com/2025/05/24/study/Bayes/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Karina</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>May 24, 2025</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/05/29/study/%E5%9F%BA%E4%BA%8ECIFAR%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/" title="基于CIFAR数据集实现的图像分类">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">基于CIFAR数据集实现的图像分类</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/05/23/study/How_use_mqtt_in_LuatOS/" title="MQTT+LuatOS学习日志">
                        <span class="hidden-mobile">MQTT+LuatOS学习日志</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
