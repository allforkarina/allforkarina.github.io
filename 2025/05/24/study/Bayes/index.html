<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>基于贝叶斯决策的分类器 | Katarina's diary</title><meta name="author" content="Karina"><meta name="copyright" content="Karina"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="最小错误率贝叶斯决策分类器实战：代码解析与理论详解一、背景与应用场景贝叶斯决策分类器是一种基于**贝叶斯定理**的统计分类方法，其核心思想是通过最大化后验概率来最小化分类错误率。该方法广泛应用于医学诊断、金融风控等场景，尤其适合特征分布符合正态分布的小规模数据集。本文以鸢尾花（Iris）数据集为例，详解如何实现一个基于贝叶斯决策的分类器 。   二、核心代码解析1. 数据准备与划分12from s">
<meta property="og:type" content="article">
<meta property="og:title" content="基于贝叶斯决策的分类器">
<meta property="og:url" content="https://uestc-xtkx.github.io/2025/05/24/study/Bayes/index.html">
<meta property="og:site_name" content="Katarina&#39;s diary">
<meta property="og:description" content="最小错误率贝叶斯决策分类器实战：代码解析与理论详解一、背景与应用场景贝叶斯决策分类器是一种基于**贝叶斯定理**的统计分类方法，其核心思想是通过最大化后验概率来最小化分类错误率。该方法广泛应用于医学诊断、金融风控等场景，尤其适合特征分布符合正态分布的小规模数据集。本文以鸢尾花（Iris）数据集为例，详解如何实现一个基于贝叶斯决策的分类器 。   二、核心代码解析1. 数据准备与划分12from s">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://uestc-xtkx.github.io/img/rich_man_karina_1.jpg">
<meta property="article:published_time" content="2025-05-23T23:00:00.000Z">
<meta property="article:modified_time" content="2025-05-23T23:45:54.369Z">
<meta property="article:author" content="Karina">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://uestc-xtkx.github.io/img/rich_man_karina_1.jpg"><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "基于贝叶斯决策的分类器",
  "url": "https://uestc-xtkx.github.io/2025/05/24/study/Bayes/",
  "image": "https://uestc-xtkx.github.io/img/rich_man_karina_1.jpg",
  "datePublished": "2025-05-23T23:00:00.000Z",
  "dateModified": "2025-05-23T23:45:54.369Z",
  "author": [
    {
      "@type": "Person",
      "name": "Karina",
      "url": "https://uestc-xtkx.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/nav_logo.png"><link rel="canonical" href="https://uestc-xtkx.github.io/2025/05/24/study/Bayes/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '基于贝叶斯决策的分类器',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/background_card.css"><link rel="stylesheet" href="/css/custom_nav.css"><link rel="stylesheet" href="/css/universe.css"><link rel="stylesheet" href="/css/avatar_bg.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="/css/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="/css/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      if ($loadingBox.classList.contains('loaded')) return
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()

  if (document.readyState === 'complete') {
    preloader.endLoading()
  } else {
    window.addEventListener('load', preloader.endLoading)
    document.addEventListener('DOMContentLoaded', preloader.endLoading)
    // Add timeout protection: force end after 7 seconds
    setTimeout(preloader.endLoading, 7000)
  }

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="web_bg" style="background-image: url(/img/star_karina.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/karina_avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/rich_man_karina_1.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/nav_logo.png" alt="Logo"><span class="site-name">Katarina's diary</span></a><a class="nav-page-title" href="/"><span class="site-name">基于贝叶斯决策的分类器</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">基于贝叶斯决策的分类器</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-05-23T23:00:00.000Z" title="发表于 2025-05-24 07:00:00">2025-05-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-23T23:45:54.369Z" title="更新于 2025-05-24 07:45:54">2025-05-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/">AI</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="最小错误率贝叶斯决策分类器实战：代码解析与理论详解"><a href="#最小错误率贝叶斯决策分类器实战：代码解析与理论详解" class="headerlink" title="最小错误率贝叶斯决策分类器实战：代码解析与理论详解"></a>最小错误率贝叶斯决策分类器实战：代码解析与理论详解</h1><h2 id="一、背景与应用场景"><a href="#一、背景与应用场景" class="headerlink" title="一、背景与应用场景"></a>一、背景与应用场景</h2><p>贝叶斯决策分类器是一种基于**贝叶斯定理**的统计分类方法，其核心思想是通过最大化后验概率来最小化分类错误率。该方法广泛应用于医学诊断、金融风控等场景，尤其适合特征分布符合正态分布的小规模数据集。本文以鸢尾花（Iris）数据集为例，详解如何实现一个基于贝叶斯决策的分类器 。  </p>
<h2 id="二、核心代码解析"><a href="#二、核心代码解析" class="headerlink" title="二、核心代码解析"></a>二、核心代码解析</h2><h2 id="1-数据准备与划分"><a href="#1-数据准备与划分" class="headerlink" title="1. 数据准备与划分"></a>1. 数据准备与划分</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">X, y = datasets.load_iris().data, datasets.load_iris().target</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：加载鸢尾花数据集，包含4个特征（花萼&#x2F;花瓣长度和宽度）和3个类别（Setosa, Versicolor, Virginica）。   </li>
<li><strong>理论基础</strong>：数据集需满足<strong>独立同分布</strong>假设，即样本间相互独立且特征分布一致 。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：按7:3比例划分训练集和测试集，<code>random\_state</code>确保实验可复现 。</li>
</ul>
<hr>
<h3 id="2-先验概率与类别条件概率估计"><a href="#2-先验概率与类别条件概率估计" class="headerlink" title="2. 先验概率与类别条件概率估计"></a>2. 先验概率与类别条件概率估计</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class_counts = np.bincount(y_train)</span><br><span class="line">priors = class_counts / len(y_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>原理</strong>：先验概率 $ P(Y) $ 反映类别在训练集中的分布比例。例如，若某类别占30%样本，则 $ P(Y&#x3D;\text{class}) &#x3D; 0.3 $ 。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class_conditional_probs = []</span><br><span class="line">for class_idx in range(3):</span><br><span class="line">    class_data = X_train[y_train == class_idx]</span><br><span class="line">    class_mean = np.mean(class_data, axis=0)</span><br><span class="line">    class_cov = np.cov(class_data, rowvar=False)</span><br><span class="line">    class_conditional_probs.append(multivariate_normal(mean=class_mean, cov=class_cov))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>关键步骤</strong>：   <ol>
<li><strong>类别条件概率建模</strong>：假设每个类别的特征服从多元正态分布，通过均值向量（<code>class\_mean</code>）和协方差矩阵（<code>class\_cov</code>）描述分布特性。   </li>
<li><strong>参数估计</strong>：使用最大似然估计（MLE）计算均值和协方差矩阵，这是参数化方法的核心 。</li>
</ol>
</li>
</ul>
<hr>
<h3 id="3-贝叶斯决策分类器实现"><a href="#3-贝叶斯决策分类器实现" class="headerlink" title="3. 贝叶斯决策分类器实现"></a>3. 贝叶斯决策分类器实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class MinimumErrorRateBayesianDecision:</span><br><span class="line">    def classify(self, features):</span><br><span class="line">        posterior_probs = [self.priors[i] * prob.pdf(features) for i, prob in enumerate(self.class_conditional_probs)]</span><br><span class="line">        return np.argmax(posterior_probs)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>决策逻辑</strong>：   <ul>
<li><strong>后验概率计算</strong>：根据贝叶斯公式 $ P(Y|X) \propto P(Y) \cdot P(X|Y) $，计算每个类别的后验概率。   </li>
<li><strong>最小错误率决策</strong>：选择后验概率最大的类别作为预测结果，此决策规则理论上最小化分类错误率 。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-模型评估"><a href="#4-模型评估" class="headerlink" title="4. 模型评估"></a>4. 模型评估</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">correct_predictions = 0</span><br><span class="line">class_correct_predictions = [0]*3</span><br><span class="line">class_total_samples = [0]*3</span><br><span class="line"></span><br><span class="line">for i in range(len(X_test)):</span><br><span class="line">    predicted_class = classifier.classify(X_test[i])</span><br><span class="line">    class_total_samples[y_test[i]] += 1</span><br><span class="line">    if predicted_class == y_test[i]:</span><br><span class="line">        correct_predictions += 1</span><br><span class="line">        class_correct_predictions[y_test[i]] += 1</span><br><span class="line"></span><br><span class="line">accuracy = correct_predictions / len(X_test)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>评估指标</strong>：计算整体准确率和类别级别的准确率，验证分类器性能 。</li>
</ul>
<hr>
<h2 id="三、数学原理详解"><a href="#三、数学原理详解" class="headerlink" title="三、数学原理详解"></a>三、数学原理详解</h2><h3 id="1-贝叶斯定理"><a href="#1-贝叶斯定理" class="headerlink" title="1. 贝叶斯定理"></a>1. 贝叶斯定理</h3><p>贝叶斯公式定义为：<br>$$<br>P(Y|X) &#x3D; \frac{P(X|Y) \cdot P(Y)}{P(X)}<br>$$   </p>
<ul>
<li><strong>先验概率</strong> $ P(Y) $：类别在训练集中的分布比例。   </li>
<li><strong>似然</strong> $ P(X|Y) $：类别条件概率密度，通过多元正态分布建模。   </li>
<li><strong>证据</strong> $ P(X) $：常数项（对所有类别相同），不影响比较后验概率大小 。</li>
</ul>
<h3 id="2-多元正态分布假设"><a href="#2-多元正态分布假设" class="headerlink" title="2. 多元正态分布假设"></a>2. 多元正态分布假设</h3><p>假设特征向量 $ X \sim \mathcal{N}(\mu, \Sigma) $，其概率密度函数为：<br>$$<br>f(X) &#x3D; \frac{1}{\sqrt{(2\pi)^k |\Sigma|}} \exp\left( -\frac{1}{2}(X-\mu)^T \Sigma^{-1}(X-\mu) \right)<br>$$   </p>
<ul>
<li><strong>均值向量</strong> $ \mu $：反映特征的集中趋势。   </li>
<li><strong>协方差矩阵</strong> $ \Sigma $：描述特征间的相关性 。</li>
</ul>
<h3 id="3-决策边界"><a href="#3-决策边界" class="headerlink" title="3. 决策边界"></a>3. 决策边界</h3><h2 id="当两类的后验概率相等时，即：-P-Y-1-cdot-P-X-Y-1-P-Y-2-cdot-P-X-Y-2-此时对应的超平面即为决策边界，用于划分不同类别的样本空间-。"><a href="#当两类的后验概率相等时，即：-P-Y-1-cdot-P-X-Y-1-P-Y-2-cdot-P-X-Y-2-此时对应的超平面即为决策边界，用于划分不同类别的样本空间-。" class="headerlink" title="当两类的后验概率相等时，即：$$P(Y_1) \cdot P(X|Y_1) &#x3D; P(Y_2) \cdot P(X|Y_2)$$此时对应的超平面即为决策边界，用于划分不同类别的样本空间 。   "></a>当两类的后验概率相等时，即：<br>$$<br>P(Y_1) \cdot P(X|Y_1) &#x3D; P(Y_2) \cdot P(X|Y_2)<br>$$<br>此时对应的超平面即为决策边界，用于划分不同类别的样本空间 。   </h2><h2 id="四、实验结果与分析"><a href="#四、实验结果与分析" class="headerlink" title="四、实验结果与分析"></a>四、实验结果与分析</h2><h3 id="1-分类准确率"><a href="#1-分类准确率" class="headerlink" title="1. 分类准确率"></a>1. 分类准确率</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 输出示例（实际运行结果可能不同）</span><br><span class="line">print(&quot;Setosa准确率: 1.0&quot;)</span><br><span class="line">print(&quot;Versicolor准确率: 0.93&quot;)</span><br><span class="line">print(&quot;整体准确率: 0.95&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>结果分析</strong>：模型在测试集上表现优异，尤其对Setosa类别实现完美分类，表明正态分布假设在该数据集上成立 。</li>
</ul>
<h3 id="2-可视化决策边界"><a href="#2-可视化决策边界" class="headerlink" title="2. 可视化决策边界"></a>2. 可视化决策边界</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=&#x27;viridis&#x27;)</span><br><span class="line">plt.xlabel(&quot;Sepal Length&quot;)</span><br><span class="line">plt.ylabel(&quot;Sepal Width&quot;)</span><br><span class="line">plt.title(&quot;Bayesian Decision Boundary&quot;)</span><br><span class="line">plt.colorbar(label=&quot;Class&quot;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_02.png" alt="Agglomerative Clustering"><br><em>图2：基于贝叶斯决策的分类边界可视化（示例）</em>   </p>
<hr>
<h2 id="五、总结与扩展"><a href="#五、总结与扩展" class="headerlink" title="五、总结与扩展"></a>五、总结与扩展</h2><h3 id="1-优势与局限性"><a href="#1-优势与局限性" class="headerlink" title="1. 优势与局限性"></a>1. 优势与局限性</h3><ul>
<li><strong>优势</strong>：   <ul>
<li>理论基础扎实，适用于小规模数据。   </li>
<li>通过参数估计可解释性强 。</li>
</ul>
</li>
<li><strong>局限性</strong>：   <ul>
<li>依赖正态分布假设，若实际数据分布偏离较大可能导致性能下降。   </li>
<li>协方差矩阵可能因样本不足而奇异，需正则化处理 。</li>
</ul>
</li>
</ul>
<h3 id="2-改进方向"><a href="#2-改进方向" class="headerlink" title="2. 改进方向"></a>2. 改进方向</h3><ul>
<li><strong>非参数化方法</strong>：使用核密度估计替代正态分布假设。   </li>
<li><strong>正则化技术</strong>：在协方差矩阵中加入微小扰动（如 <code>class\_cov += 1e-6 \* np.eye(dim)</code>）防止奇异 。</li>
</ul>
<blockquote>
<p>完整代码仓库：[GitHub链接]   </p>
</blockquote>
<h1 id="🎃-朴素贝叶斯实现决策分类"><a href="#🎃-朴素贝叶斯实现决策分类" class="headerlink" title="🎃 朴素贝叶斯实现决策分类"></a>🎃 朴素贝叶斯实现决策分类</h1><h3 id="1-导入库"><a href="#1-导入库" class="headerlink" title="1. 导入库"></a>1. 导入库</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import make_classification </span><br><span class="line">import matplotlib.pyplot as plt </span><br><span class="line">import numpy as np </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：导入所需的库。   <ul>
<li><code>make\_classification</code>：用于生成合成的分类数据集 。   </li>
<li><code>matplotlib.pyplot</code>：用于可视化结果。   </li>
<li><code>numpy</code>：进行数值计算。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-定义高斯概率密度函数"><a href="#2-定义高斯概率密度函数" class="headerlink" title="2. 定义高斯概率密度函数"></a>2. 定义高斯概率密度函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def gaussian_pdf(x, mean, std_dev): </span><br><span class="line">    return (1 / (np.sqrt(2 * np.pi) * std_dev)) * np.exp(-0.5 * ((x - mean) / std_dev)**2) </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：计算单个特征值在高斯分布下的概率密度。   </li>
<li><strong>公式解释</strong>：</li>
</ul>
<p>高斯分布（正态分布）的概率密度函数公式为：<br>$$<br>f(x) &#x3D; \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}}<br>$$<br>其中 <code>mean</code> 是均值 $ \mu $，<code>std\_dev</code> 是标准差 $ \sigma $。   </p>
<ul>
<li><strong>应用场景</strong>：在朴素贝叶斯分类器中，假设每个特征在给定类别下服从高斯分布。</li>
</ul>
<hr>
<h3 id="3-自定义数据集划分函数"><a href="#3-自定义数据集划分函数" class="headerlink" title="3. 自定义数据集划分函数"></a>3. 自定义数据集划分函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def train_test_split(X, y, test_size=0.2, random_state=None): </span><br><span class="line">    if random_state is not None: </span><br><span class="line">        np.random.seed(random_state)    </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：将数据集划分为训练集和测试集。   </li>
<li><strong>参数说明</strong>：   <ul>
<li><code>X</code>：特征数据。   </li>
<li><code>y</code>：目标标签。   </li>
<li><code>test\_size</code>：测试集比例（默认 20%）。   </li>
<li><code>random\_state</code>：随机种子，确保结果可复现 。</li>
</ul>
</li>
<li><strong>实现逻辑</strong>：   <ul>
<li>使用 <code>np.random.permutation</code> 打乱数据索引。   </li>
<li>按比例划分测试集和训练集。</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">m = X.shape[0]                              # 获取数据集的大小 </span><br><span class="line">permutation = np.random.permutation(m)      # 随机生成打乱的数组 对应为打乱的索引</span><br><span class="line">test_size = int(m * test_size)              # 计算测试集的大小 </span><br><span class="line">test_indices = permutation[:test_size]      # 取test_size个打乱的索引</span><br><span class="line">train_indices = permutation[test_size:]     # 取后面所有索引作为训练集    </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>关键步骤</strong>：   <ul>
<li><code>X.shape[0]</code>：获取样本总数。   </li>
<li><code>permutation</code>：生成随机索引。   </li>
<li><code>test\_indices</code>：前 <code>test\_size</code> 个索引作为测试集。   </li>
<li><code>train\_indices</code>：剩余索引作为训练集。</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_train = X[train_indices] </span><br><span class="line">X_test = X[test_indices] </span><br><span class="line">y_train = y[train_indices] </span><br><span class="line">y_test = y[test_indices] </span><br><span class="line"> </span><br><span class="line">return X_train, X_test, y_train, y_test </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>输出</strong>：返回划分后的训练集和测试集。</li>
</ul>
<hr>
<h3 id="4-贝叶斯分类器的预测函数"><a href="#4-贝叶斯分类器的预测函数" class="headerlink" title="4. 贝叶斯分类器的预测函数"></a>4. 贝叶斯分类器的预测函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def predict_bayes(x, means, variances, priors): </span><br><span class="line">    posteriors = [] </span><br><span class="line">    for i in range(len(means)): </span><br><span class="line">        likelihood = np.prod(gaussian_pdf(x, means[i], np.sqrt(variances[i])))      </span><br><span class="line">        posterior = likelihood * priors[i]                                          </span><br><span class="line">        posteriors.append(posterior)                                                </span><br><span class="line">    return np.argmax(posteriors) </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：基于朴素贝叶斯算法预测样本类别。   </li>
<li><strong>步骤解析</strong>：   <ol>
<li><strong>似然计算</strong>：对每个特征计算高斯概率密度，并通过 <code>np.prod</code> 连乘得到联合概率（假设特征条件独立）。   </li>
<li><strong>后验概率</strong>：似然乘以先验概率 <code>priors[i]</code>。   </li>
<li><strong>分类决策</strong>：选择后验概率最大的类别作为预测结果（<code>np.argmax</code>）。</li>
</ol>
</li>
</ul>
<hr>
<h3 id="5-生成合成数据集"><a href="#5-生成合成数据集" class="headerlink" title="5. 生成合成数据集"></a>5. 生成合成数据集</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X, y = make_classification(n_samples=1500, n_features=2, </span><br><span class="line">                            n_informative=2, n_redundant=0,  </span><br><span class="line">                            n_clusters_per_class=1, random_state=6) </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：生成一个二维二分类数据集。   </li>
<li><strong>参数解释</strong>：   <ul>
<li><code>n\_samples=1500</code>：生成 1500 个样本。   </li>
<li><code>n\_features=2</code>：每个样本有 2 个特征（x1, x2）。   </li>
<li><code>n\_informative=2</code>：两个特征均为信息性特征（用于分类）。   </li>
<li><code>n\_redundant=0</code>：无冗余特征。   </li>
<li><code>n\_clusters\_per\_class=1</code>：每个类别有 1 个聚类中心。   </li>
<li><code>random\_state=6</code>：确保数据生成可复现 。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="6-数据集划分"><a href="#6-数据集划分" class="headerlink" title="6. 数据集划分"></a>6. 数据集划分</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：将数据集按 80%&#x2F;20% 划分为训练集和测试集。</li>
</ul>
<hr>
<h3 id="7-计算类别均值和方差"><a href="#7-计算类别均值和方差" class="headerlink" title="7. 计算类别均值和方差"></a>7. 计算类别均值和方差</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">unique_classes = np.unique(y_train) </span><br><span class="line"></span><br><span class="line">means = []          </span><br><span class="line">variances = []      </span><br><span class="line">for i in unique_classes: </span><br><span class="line">    X_train_class_i = X_train[y_train == i]                 </span><br><span class="line">    mean_class_i = np.mean(X_train_class_i, axis=0)         </span><br><span class="line">    variance_class_i = np.var(X_train_class_i, axis=0)     </span><br><span class="line">    means.append(mean_class_i) </span><br><span class="line">    variances.append(variance_class_i) </span><br><span class="line"> </span><br><span class="line">means = np.array(means) </span><br><span class="line">variances = np.array(variances) </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：对每个类别计算特征的均值和方差。   </li>
<li><strong>关键点</strong>：   <ul>
<li><code>np.unique(y\_train)</code>：获取训练集中所有类别标签。   </li>
<li><code>X\_train[y\_train == i]</code>：筛选当前类别的样本。   </li>
<li><code>np.mean</code> 和 <code>np.var</code>：计算均值和方差。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="8-计算先验概率"><a href="#8-计算先验概率" class="headerlink" title="8. 计算先验概率"></a>8. 计算先验概率</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">priors = [np.mean(y_train == i) for i in np.unique(y_train)] </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：计算每个类别的先验概率 $ P(Y) $。   </li>
<li><strong>实现原理</strong>：</li>
</ul>
<h2 id="对于布尔数组-y-train-i，np-mean-返回-True（即类别-i-的样本）的比例。"><a href="#对于布尔数组-y-train-i，np-mean-返回-True（即类别-i-的样本）的比例。" class="headerlink" title="对于布尔数组 y\_train == i，np.mean 返回 True（即类别 i 的样本）的比例。   "></a>对于布尔数组 <code>y\_train == i</code>，<code>np.mean</code> 返回 <code>True</code>（即类别 i 的样本）的比例。   </h2><h3 id="9-预测与评估"><a href="#9-预测与评估" class="headerlink" title="9. 预测与评估"></a>9. 预测与评估</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_pred = [predict_bayes(x, means, variances, priors) for x in X_test] </span><br><span class="line">correct = np.sum(y_pred == y_test) / len(y_test)                            </span><br><span class="line">print(&quot;Accuracy: &#123;:.2f&#125;%&quot;.format(correct * 100)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：   <ul>
<li>对测试集逐样本预测类别。   </li>
<li>计算准确率：预测正确的样本数占总样本数的比例。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="10-可视化结果"><a href="#10-可视化结果" class="headerlink" title="10. 可视化结果"></a>10. 可视化结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(16, 8))</span><br><span class="line">scatter_true = plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test,  </span><br><span class="line">                           s=30, cmap=&#x27;coolwarm&#x27;,label=&#x27;True class&#x27;) </span><br><span class="line">scatter_pred = plt.scatter(X_test[:, 0], X_test[:, 1], s=30,  </span><br><span class="line">                           facecolors=&#x27;none&#x27;,  </span><br><span class="line">                           edgecolors=np.array([&#x27;b&#x27;, &#x27;r&#x27;])[y_pred], </span><br><span class="line">                           label = &#x27;Predicted class&#x27;) </span><br><span class="line">plt.legend(handles=[scatter_true, scatter_pred]) </span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：可视化测试集的真实标签和预测结果。   </li>
<li><strong>图形说明</strong>：   <ul>
<li><code>c=y\_test</code>：颜色表示真实类别（红&#x2F;蓝）。   </li>
<li><code>edgecolors=np.array([&#39;b&#39;, &#39;r&#39;])[y\_pred]</code>：边缘颜色表示预测类别。   </li>
<li><code>facecolors=&#39;none&#39;</code>：仅显示边缘，便于对比预测与真实标签。</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_03.png" alt="Accuracy&#x3D;95%"> </p>
<hr>
<h3 id="关键知识点总结"><a href="#关键知识点总结" class="headerlink" title="关键知识点总结"></a>关键知识点总结</h3><ol>
<li><strong>朴素贝叶斯假设</strong>：特征之间条件独立，通过连乘计算联合概率 。   </li>
<li><strong>高斯分布建模</strong>：假设每个特征在给定类别下服从正态分布。   </li>
<li><strong>先验概率估计</strong>：通过训练集中类别的频率计算 $ P(Y) $。   </li>
<li><strong>决策规则</strong>：最大化后验概率 $ P(Y|X) \propto P(X|Y)P(Y) $。</li>
</ol>
<hr>
<h1 id="核函数估计概率密度函数的朴素贝叶斯"><a href="#核函数估计概率密度函数的朴素贝叶斯" class="headerlink" title="核函数估计概率密度函数的朴素贝叶斯"></a>核函数估计概率密度函数的朴素贝叶斯</h1><h3 id="1-predict-bayes-函数：基于损失矩阵的贝叶斯决策"><a href="#1-predict-bayes-函数：基于损失矩阵的贝叶斯决策" class="headerlink" title="1. predict_bayes 函数：基于损失矩阵的贝叶斯决策"></a>1. predict_bayes 函数：基于损失矩阵的贝叶斯决策</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def predict_bayes(x, parzen_estimations, priors, loss_matrix): </span><br><span class="line">    expected_losses = []                                        # 初始化期望损失列表 </span><br><span class="line">    for j in range(len(parzen_estimations)): </span><br><span class="line">        expected_loss = 0                                       # 初始化期望损失 </span><br><span class="line">        for i in range(len(parzen_estimations)): </span><br><span class="line">            posterior = priors[i] * parzen_estimations[i]       # 计算后验概率     </span><br><span class="line">            expected_loss += loss_matrix[i][j] * posterior      # 计算期望损失 </span><br><span class="line">        expected_losses.append(expected_loss)                   # 将期望损失添加到列表中 </span><br><span class="line">    return np.argmin(expected_losses, axis=0)                   # 返回期望损失最小的类别作为预测结果</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：根据<strong>期望损失最小化</strong>原则，将输入样本 <code>x</code> 分类到某个类别。   </li>
<li><strong>关键步骤解析</strong>：   <ol>
<li><strong>后验概率计算</strong>：    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">posterior = priors[i] * parzen_estimations[i]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>公式</strong>：</li>
</ul>
</li>
</ol>
<ul>
<li><strong>理论依据</strong>：贝叶斯定理 $ P(Y|X) &#x3D; \frac{P(Y) \cdot P(X|Y)}{P(X)} $，分母 $ P(X) $ 对所有类别相同，可忽略 。</li>
</ul>
</li>
</ul>
<ol>
<li><strong>期望损失计算</strong>：    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">expected_loss += loss_matrix[i][j] * posterior</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>公式</strong>：</li>
</ul>
</li>
</ol>
<ul>
<li><strong>理论依据</strong>：贝叶斯决策的目标是最小化<strong>条件风险</strong>（即期望损失），而非单纯最大化后验概率 。</li>
</ul>
<ol start="2">
<li><strong>决策规则</strong>：    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">return np.argmin(expected_losses, axis=0)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>解释</strong>：选择期望损失最小的类别 <code>j</code> 作为预测结果，而非直接选择后验概率最大的类别。   </li>
<li><strong>对比普通贝叶斯</strong>：普通朴素贝叶斯仅比较后验概率（即损失矩阵为单位矩阵时的情况），而此代码通过自定义 <code>loss\_matrix</code> 实现<strong>风险敏感决策</strong> 。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="2-Parzen窗口估计：非参数概率密度估计"><a href="#2-Parzen窗口估计：非参数概率密度估计" class="headerlink" title="2. Parzen窗口估计：非参数概率密度估计"></a>2. Parzen窗口估计：非参数概率密度估计</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def parzen_window_estimation(x, data, h=1, window_func=squ_window): </span><br><span class="line">    N, d = data.shape                           # 获取数据的数量和维度</span><br><span class="line">    k_n = window_func(cdist(x, data) / h)       # 计算每个样本到x的距离并应用窗口函数限制权重</span><br><span class="line">    return np.sum(k_n, axis=1) / (N * h**d)     # 返回Parzen窗口估计的结果 shape=[N, ] h是窗大小</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>功能</strong>：通过Parzen窗口法估计样本 <code>x</code> 的概率密度。   </li>
<li><strong>关键步骤解析</strong>：   <ol>
<li><strong>距离计算</strong>：    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cdist(x, data) / h</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：计算测试样本 <code>x</code> 与所有训练样本 <code>data</code> 的欧氏距离，并除以带宽 <code>h</code> 进行归一化。   </li>
<li><strong>理论依据</strong>：Parzen窗口是一种非参数密度估计方法，通过核函数（窗口函数）加权邻域内的样本点 。</li>
</ul>
</li>
<li><strong>窗口函数应用</strong>：    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">window_func(...)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>窗口函数类型</strong>：   <ul>
<li><strong>方窗</strong>（<code>squ\_window</code>）：仅统计距离在 <code>[-h/2, h/2]</code> 内的样本。   </li>
<li><strong>正态窗</strong>（<code>nor\_window</code>）：使用高斯分布权重（权重随距离指数衰减）。   </li>
<li><strong>指数窗</strong>（<code>exp\_window</code>）：权重随距离线性衰减。   </li>
<li><strong>三角窗</strong>（<code>tri\_window</code>）：权重随距离线性衰减至零。</li>
</ul>
</li>
<li><strong>理论依据</strong>：不同窗口函数对密度估计的平滑性有影响，正态窗适合连续分布，方窗适合离散分布 。</li>
</ul>
</li>
<li><strong>密度估计值</strong>：    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.sum(...) / (N * h**d)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>公式</strong>：</li>
</ul>
</li>
</ol>
<ul>
<li><strong>理论依据</strong>：Parzen窗口通过核密度估计逼近真实分布，无需假设数据服从特定分布 。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-代码整体流程与贝叶斯决策的关系"><a href="#3-代码整体流程与贝叶斯决策的关系" class="headerlink" title="3. 代码整体流程与贝叶斯决策的关系"></a>3. 代码整体流程与贝叶斯决策的关系</h3><ol>
<li><strong>训练阶段</strong>：   <ul>
<li>对每个类别 <code>i</code>，使用训练数据 <code>X\_train[y\_train == i]</code> 计算 Parzen 窗口密度估计 <code>parzen\_estimations[i]</code>。   </li>
<li>计算每个类别的先验概率 <code>priors[i] = P(Y=i)</code>。</li>
</ul>
</li>
<li><strong>预测阶段</strong>：   <ul>
<li>对每个测试样本 <code>x</code>：   <ul>
<li>使用 Parzen 窗口法计算其在每个类别下的概率密度 <code>parzen\_estimations</code>。   </li>
<li>结合先验概率和损失矩阵，计算每个可能决策的期望损失。   </li>
<li>选择期望损失最小的类别作为预测结果。</li>
</ul>
</li>
</ul>
</li>
<li><strong>与普通朴素贝叶斯的区别</strong>：   <ul>
<li><strong>普通朴素贝叶斯</strong>：假设特征服从特定分布（如高斯分布），且特征条件独立，直接计算后验概率。   </li>
<li><strong>本代码实现</strong>：   <ul>
<li>使用非参数方法（Parzen窗口）估计概率密度，无需假设分布形式。   </li>
<li>引入损失矩阵，允许自定义误分类代价（如医疗诊断中误诊癌症的代价更高）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="4-关键参数的作用"><a href="#4-关键参数的作用" class="headerlink" title="4. 关键参数的作用"></a>4. 关键参数的作用</h3><ul>
<li>带宽 <code>**h**</code>：   <ul>
<li><code>h</code> 越大，密度估计越平滑（可能欠拟合），<code>h</code> 越小，密度估计越尖锐（可能过拟合）。</li>
</ul>
</li>
<li><strong>窗口函数</strong>：   <ul>
<li>方窗（<code>squ\_window</code>）适合离散分布，正态窗（<code>nor\_window</code>）适合连续分布。</li>
</ul>
</li>
<li>损失矩阵 <code>**loss\_matrix**</code>：   <ul>
<li>单位矩阵（<code>[[0,1],[1,0]]</code>）对应最小错误率决策，非单位矩阵对应最小风险决策 。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="5-示例说明"><a href="#5-示例说明" class="headerlink" title="5. 示例说明"></a>5. 示例说明</h3><p>假设 <code>loss\_matrix = [[0, 2], [1, 0]]</code>：   </p>
<ul>
<li>将实际类别为 0 的样本误判为 1 的代价是 2，而将实际类别为 1 的样本误判为 0 的代价是 1。   </li>
<li>分类器会更倾向于避免将类别 0 误判为 1，从而在代价敏感场景下优化决策 。</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><strong>核心思想</strong>：通过非参数密度估计（Parzen窗口）和风险最小化（损失矩阵）实现灵活的贝叶斯决策。   </li>
<li><strong>适用场景</strong>：   <ul>
<li>数据分布未知或非高斯分布。   </li>
<li>不同类别的误分类代价不一致（如医疗、金融风控）。</li>
</ul>
</li>
<li><strong>改进方向</strong>：   <ul>
<li>使用交叉验证选择最优带宽 <code>h</code>。   </li>
<li>替换更复杂的核函数（如高斯混合核）。</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/allforkarina/embadded_image/refs/heads/master/20250524_01.png" alt="Accuracy&#x3D;97%"></p>
<p>➡️ 通过加窗以及损失矩阵补偿错误判断，可以发现对于同一个数据在分类的正确性上有一定的增强；   </p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://uestc-xtkx.github.io">Karina</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://uestc-xtkx.github.io/2025/05/24/study/Bayes/">https://uestc-xtkx.github.io/2025/05/24/study/Bayes/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://uestc-xtkx.github.io" target="_blank">Katarina's diary</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ML/">ML</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></div><div class="post-share"><div class="social-share" data-image="/img/rich_man_karina_1.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/05/29/study/SVM/" title="SVM——Python代码实现以及解析"><img class="cover" src="/img/scene.jpg" onerror="onerror=null;src='/img/default.png'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">SVM——Python代码实现以及解析</div></div><div class="info-2"><div class="info-item-1">支持向量机(SVM)原理详解与代码解析一、SVM算法原理详解1. 核心思想支持向量机通过最大化分类间隔实现最优分类，其数学本质是求解一个凸二次优化问题。核心思想包括：  最大间隔原则：寻找使类别间距离最大的分类超平面 支持向量：决定分类边界的关键样本点 核技巧：通过核函数将低维不可分数据映射到高维空间  2. 数学基础(1) 线性可分情况$$\min_{w,b} \frac{1}{2}||w||^2 \quad \text{s.t.} \quad y_i(w^T x_i + b) \geq 1$$  $ w $：超平面法向量 $ b $：偏置项 $ y_i \in {-1,1} $：类别标签  (2) 非线性情况（使用核函数）$$K(x_i,x_j) &#x3D; \phi(x_i)^T\phi(x_j)$$ 常用核函数：  线性核：$ K(x,y) &#x3D; x^Ty $ 多项式核：$ K(x,y) &#x3D; (x^Ty + c)^d $ RBF核：$ K(x,y) &#x3D; e^{-\gamma ||x-y||^2} $  (3) 正则化参数C$$\min_{w,...</div></div></div></a><a class="pagination-related" href="/2025/05/23/study/K_Means/" title="聚类分类—算法以及python实现"><img class="cover" src="/img/rich_man_karina_2.jpg" onerror="onerror=null;src='/img/default.png'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">聚类分类—算法以及python实现</div></div><div class="info-2"><div class="info-item-1">🧠 使用 Python 实现高效凝聚层次聚类（Agglomerative Clustering）在本篇博客中，我们将一起探索如何使用 Python 实现一个高效的 凝聚层次聚类（Agglomerative Hierarchical Clustering）算法，并支持三种不同的簇间距离度量方式：single linkage, complete linkage 和 average linkage。我们还将通过可视化展示不同方法的效果，并分析其优劣。   📚 一、什么是凝聚层次聚类？凝聚层次聚类是一种 自底向上的无监督聚类算法，它的核心思想是：     每个数据点初始时都是一个独立的簇，然后逐步合并最相似的两个簇，直到达到预设的簇数。     与 K-Means 不同，它不需要提前指定簇的数量即可构建整个聚类树（dendrogram），因此非常适合探索性数据分析。   ⚙️ 二、代码概述🔍 功能亮点： 支持三种 linkage 方法：    &#39;single&#39;: 最短距离法（最近邻）    &#39;complete&#39;: 最长距离法（最远邻）    &#39...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/karina_avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Karina</div><div class="author-info-description">Love what you do, do what you love.</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/allforkarina/"><i class="fa-solid fa-blog"></i><span>My Home Page</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/allforkarina" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="https://allforkarina.github.io/" target="_blank" title="Blog"><i class="fas fa-blog" style="color: #4a7dbe;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E9%94%99%E8%AF%AF%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8E%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.</span> <span class="toc-text">最小错误率贝叶斯决策分类器实战：代码解析与理论详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%83%8C%E6%99%AF%E4%B8%8E%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.1.</span> <span class="toc-text">一、背景与应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="toc-number">1.2.</span> <span class="toc-text">二、核心代码解析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%E4%B8%8E%E5%88%92%E5%88%86"><span class="toc-number">1.3.</span> <span class="toc-text">1. 数据准备与划分</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%E4%B8%8E%E7%B1%BB%E5%88%AB%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E4%BC%B0%E8%AE%A1"><span class="toc-number">1.3.1.</span> <span class="toc-text">2. 先验概率与类别条件概率估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.3.2.</span> <span class="toc-text">3. 贝叶斯决策分类器实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">1.3.3.</span> <span class="toc-text">4. 模型评估</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.4.</span> <span class="toc-text">三、数学原理详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"><span class="toc-number">1.4.1.</span> <span class="toc-text">1. 贝叶斯定理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%A4%9A%E5%85%83%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E5%81%87%E8%AE%BE"><span class="toc-number">1.4.2.</span> <span class="toc-text">2. 多元正态分布假设</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8C"><span class="toc-number">1.4.3.</span> <span class="toc-text">3. 决策边界</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%93%E4%B8%A4%E7%B1%BB%E7%9A%84%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E7%9B%B8%E7%AD%89%E6%97%B6%EF%BC%8C%E5%8D%B3%EF%BC%9A-P-Y-1-cdot-P-X-Y-1-P-Y-2-cdot-P-X-Y-2-%E6%AD%A4%E6%97%B6%E5%AF%B9%E5%BA%94%E7%9A%84%E8%B6%85%E5%B9%B3%E9%9D%A2%E5%8D%B3%E4%B8%BA%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8C%EF%BC%8C%E7%94%A8%E4%BA%8E%E5%88%92%E5%88%86%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%88%AB%E7%9A%84%E6%A0%B7%E6%9C%AC%E7%A9%BA%E9%97%B4-%E3%80%82"><span class="toc-number">1.5.</span> <span class="toc-text">当两类的后验概率相等时，即：$$P(Y_1) \cdot P(X|Y_1) &#x3D; P(Y_2) \cdot P(X|Y_2)$$此时对应的超平面即为决策边界，用于划分不同类别的样本空间 。   </span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E4%B8%8E%E5%88%86%E6%9E%90"><span class="toc-number">1.6.</span> <span class="toc-text">四、实验结果与分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%86%E7%B1%BB%E5%87%86%E7%A1%AE%E7%8E%87"><span class="toc-number">1.6.1.</span> <span class="toc-text">1. 分类准确率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8C"><span class="toc-number">1.6.2.</span> <span class="toc-text">2. 可视化决策边界</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%80%BB%E7%BB%93%E4%B8%8E%E6%89%A9%E5%B1%95"><span class="toc-number">1.7.</span> <span class="toc-text">五、总结与扩展</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BC%98%E5%8A%BF%E4%B8%8E%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">1.7.1.</span> <span class="toc-text">1. 优势与局限性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%94%B9%E8%BF%9B%E6%96%B9%E5%90%91"><span class="toc-number">1.7.2.</span> <span class="toc-text">2. 改进方向</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%8E%83-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9E%E7%8E%B0%E5%86%B3%E7%AD%96%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">🎃 朴素贝叶斯实现决策分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AF%BC%E5%85%A5%E5%BA%93"><span class="toc-number">2.0.1.</span> <span class="toc-text">1. 导入库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AE%9A%E4%B9%89%E9%AB%98%E6%96%AF%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-number">2.0.2.</span> <span class="toc-text">2. 定义高斯概率密度函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86%E5%87%BD%E6%95%B0"><span class="toc-number">2.0.3.</span> <span class="toc-text">3. 自定义数据集划分函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0"><span class="toc-number">2.0.4.</span> <span class="toc-text">4. 贝叶斯分类器的预测函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%94%9F%E6%88%90%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.0.5.</span> <span class="toc-text">5. 生成合成数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86"><span class="toc-number">2.0.6.</span> <span class="toc-text">6. 数据集划分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E8%AE%A1%E7%AE%97%E7%B1%BB%E5%88%AB%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE"><span class="toc-number">2.0.7.</span> <span class="toc-text">7. 计算类别均值和方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E8%AE%A1%E7%AE%97%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87"><span class="toc-number">2.0.8.</span> <span class="toc-text">8. 计算先验概率</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E5%B8%83%E5%B0%94%E6%95%B0%E7%BB%84-y-train-i%EF%BC%8Cnp-mean-%E8%BF%94%E5%9B%9E-True%EF%BC%88%E5%8D%B3%E7%B1%BB%E5%88%AB-i-%E7%9A%84%E6%A0%B7%E6%9C%AC%EF%BC%89%E7%9A%84%E6%AF%94%E4%BE%8B%E3%80%82"><span class="toc-number">2.1.</span> <span class="toc-text">对于布尔数组 y\_train &#x3D;&#x3D; i，np.mean 返回 True（即类别 i 的样本）的比例。   </span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E9%A2%84%E6%B5%8B%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="toc-number">2.1.1.</span> <span class="toc-text">9. 预测与评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BB%93%E6%9E%9C"><span class="toc-number">2.1.2.</span> <span class="toc-text">10. 可视化结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93"><span class="toc-number">2.1.3.</span> <span class="toc-text">关键知识点总结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0%E4%BC%B0%E8%AE%A1%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-number">3.</span> <span class="toc-text">核函数估计概率密度函数的朴素贝叶斯</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-predict-bayes-%E5%87%BD%E6%95%B0%EF%BC%9A%E5%9F%BA%E4%BA%8E%E6%8D%9F%E5%A4%B1%E7%9F%A9%E9%98%B5%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96"><span class="toc-number">3.0.1.</span> <span class="toc-text">1. predict_bayes 函数：基于损失矩阵的贝叶斯决策</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Parzen%E7%AA%97%E5%8F%A3%E4%BC%B0%E8%AE%A1%EF%BC%9A%E9%9D%9E%E5%8F%82%E6%95%B0%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1"><span class="toc-number">3.0.2.</span> <span class="toc-text">2. Parzen窗口估计：非参数概率密度估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%BB%A3%E7%A0%81%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">3.0.3.</span> <span class="toc-text">3. 代码整体流程与贝叶斯决策的关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%85%B3%E9%94%AE%E5%8F%82%E6%95%B0%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">3.0.4.</span> <span class="toc-text">4. 关键参数的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%A4%BA%E4%BE%8B%E8%AF%B4%E6%98%8E"><span class="toc-number">3.0.5.</span> <span class="toc-text">5. 示例说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.0.6.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-calendar"><div class="card-content"><div class="item-headline"><i class="fas fa-calendar"></i><span>Calendar</span></div><div class="widget" id="calendar"></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/09/21/research/survey-on-wifi-sensing-generalization/" title="面向WiFi-Sensing的文献总结"><img src="/img/Dirty_work_Karina_2.jpg" onerror="this.onerror=null;this.src='/img/default.png'" alt="面向WiFi-Sensing的文献总结"/></a><div class="content"><a class="title" href="/2025/09/21/research/survey-on-wifi-sensing-generalization/" title="面向WiFi-Sensing的文献总结">面向WiFi-Sensing的文献总结</a><time datetime="2025-09-21T01:35:00.000Z" title="发表于 2025-09-21 09:35:00">2025-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/20/research/Unsupervised-adversarial-domain-adaptation-By-han/" title="Unsupervised adversarial domain adaptation——对抗生成跨域泛化"><img src="/img/Dirty_work_Karina_1.jpg" onerror="this.onerror=null;this.src='/img/default.png'" alt="Unsupervised adversarial domain adaptation——对抗生成跨域泛化"/></a><div class="content"><a class="title" href="/2025/09/20/research/Unsupervised-adversarial-domain-adaptation-By-han/" title="Unsupervised adversarial domain adaptation——对抗生成跨域泛化">Unsupervised adversarial domain adaptation——对抗生成跨域泛化</a><time datetime="2025-09-20T01:35:00.000Z" title="发表于 2025-09-20 09:35:00">2025-09-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/19/research/multiformer-By-wenhui-xiong/" title="MultiFormer——基于迭代的高准确率姿态估计"><img src="/img/rich_man_karina_1.jpg" onerror="this.onerror=null;this.src='/img/default.png'" alt="MultiFormer——基于迭代的高准确率姿态估计"/></a><div class="content"><a class="title" href="/2025/09/19/research/multiformer-By-wenhui-xiong/" title="MultiFormer——基于迭代的高准确率姿态估计">MultiFormer——基于迭代的高准确率姿态估计</a><time datetime="2025-09-19T12:35:00.000Z" title="发表于 2025-09-19 20:35:00">2025-09-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/19/research/leggiero-by-yuan-he/" title="Leggiero——反向散射标签"><img src="/img/rich_man_karina_2.jpg" onerror="this.onerror=null;this.src='/img/default.png'" alt="Leggiero——反向散射标签"/></a><div class="content"><a class="title" href="/2025/09/19/research/leggiero-by-yuan-he/" title="Leggiero——反向散射标签">Leggiero——反向散射标签</a><time datetime="2025-09-19T04:35:00.000Z" title="发表于 2025-09-19 12:35:00">2025-09-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/19/research/Densepose-from-wifi-By-jiaqi-gen/" title="Densepose——基于UV坐标的高精度姿态估计"><img src="/img/Dirty_work_Karina_2.jpg" onerror="this.onerror=null;this.src='/img/default.png'" alt="Densepose——基于UV坐标的高精度姿态估计"/></a><div class="content"><a class="title" href="/2025/09/19/research/Densepose-from-wifi-By-jiaqi-gen/" title="Densepose——基于UV坐标的高精度姿态估计">Densepose——基于UV坐标的高精度姿态估计</a><time datetime="2025-09-19T02:35:00.000Z" title="发表于 2025-09-19 10:35:00">2025-09-19</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Karina</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><a class="icon-V hidden" onclick="switchNightMode()" title="日间和夜间模式切换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script src="/js/jquery.js"></script><script src="/js/custom_footer.js"></script><canvas id="universe"></canvas><script src="/js/universe.js"></script><script src="/js/sun_moon.js"></script><script data-pjax type="text/javascript" src="/js/languages.js"></script><script data-pjax type="text/javascript" src="/js/calendar.js" ></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/09/20/research/Unsupervised-adversarial-domain-adaptation-By-han/" alt=""><img width="48" height="48" src="/img/Dirty_work_Karina_1.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-09-20</span><a class="blog-slider__title" href="2025/09/20/research/Unsupervised-adversarial-domain-adaptation-By-han/" alt="">Unsupervised adversarial domain adaptation——对抗生成跨域泛化</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/09/20/research/Unsupervised-adversarial-domain-adaptation-By-han/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/09/19/research/multiformer-By-wenhui-xiong/" alt=""><img width="48" height="48" src="/img/rich_man_karina_1.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-09-19</span><a class="blog-slider__title" href="2025/09/19/research/multiformer-By-wenhui-xiong/" alt="">MultiFormer——基于迭代的高准确率姿态估计</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/09/19/research/multiformer-By-wenhui-xiong/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/09/19/research/Densepose-from-wifi-By-jiaqi-gen/" alt=""><img width="48" height="48" src="/img/Dirty_work_Karina_2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-09-19</span><a class="blog-slider__title" href="2025/09/19/research/Densepose-from-wifi-By-jiaqi-gen/" alt="">Densepose——基于UV坐标的高精度姿态估计</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/09/19/research/Densepose-from-wifi-By-jiaqi-gen/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/09/18/research/Adapose-By-yunjiao-zhou/" alt=""><img width="48" height="48" src="/img/Dirty_work_Karina_1.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-09-18</span><a class="blog-slider__title" href="2025/09/18/research/Adapose-By-yunjiao-zhou/" alt="">Adapose——跨环境的人体关键点识别</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/09/18/research/Adapose-By-yunjiao-zhou/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/03/18/research/Wi-Fi Backscatter communication/" alt=""><img width="48" height="48" src="/img/scene.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-03-18</span><a class="blog-slider__title" href="2025/03/18/research/Wi-Fi Backscatter communication/" alt="">Wi-Fi Backscatter communication</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/03/18/research/Wi-Fi Backscatter communication/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/05/30/research/picoscenes_use_instruction/" alt=""><img width="48" height="48" src="/img/rich_man_karina_2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-30</span><a class="blog-slider__title" href="2025/05/30/research/picoscenes_use_instruction/" alt="">PicoScenes学习日志</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/05/30/research/picoscenes_use_instruction/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/04/02/research/Knowing_5G/" alt=""><img width="48" height="48" src="/img/Dirty_work_Karina_1.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-02</span><a class="blog-slider__title" href="2025/04/02/research/Knowing_5G/" alt="">初识无线通信——5G 信道估计</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/04/02/research/Knowing_5G/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/06/06/research/usrp_uhd_download/" alt=""><img width="48" height="48" src="/img/scene.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-06-06</span><a class="blog-slider__title" href="2025/06/06/research/usrp_uhd_download/" alt="">基于Ubuntu22.04的UHD安装指引</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/06/06/research/usrp_uhd_download/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/04/02/research/Channel-state-info/" alt=""><img width="48" height="48" src="/img/rich_man_karina_2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-02</span><a class="blog-slider__title" href="2025/04/02/research/Channel-state-info/" alt="">阅读札记——“5G信道的估计与均衡”</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/04/02/research/Channel-state-info/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/04/24/research/AOA_Positioning/" alt=""><img width="48" height="48" src="/img/rich_man_karina_1.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-24</span><a class="blog-slider__title" href="2025/04/24/research/AOA_Positioning/" alt="">基于5G通信的定位感知——AOA解算</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/04/24/research/AOA_Positioning/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2025/05/20/research/3D_Positioning_estimation/" alt=""><img width="48" height="48" src="/img/scene.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-20</span><a class="blog-slider__title" href="2025/05/20/research/3D_Positioning_estimation/" alt="">3D建模下的参数估计</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2025/05/20/research/3D_Positioning_estimation/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="/js/swiper.min.js"></script><script defer data-pjax src="/js/swiper_init.js"></script><!-- hexo injector body_end end --><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>